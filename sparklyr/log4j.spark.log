17/03/18 10:40:42 INFO SparkContext: Running Spark version 2.1.0
17/03/18 10:40:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 10:40:42 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 10:40:43 INFO SecurityManager: Changing view acls to: yannick
17/03/18 10:40:43 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 10:40:43 INFO SecurityManager: Changing view acls groups to: 
17/03/18 10:40:43 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 10:40:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 10:40:43 INFO Utils: Successfully started service 'sparkDriver' on port 46470.
17/03/18 10:40:43 INFO SparkEnv: Registering MapOutputTracker
17/03/18 10:40:43 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 10:40:43 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 10:40:43 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 10:40:43 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-637c3358-9dac-4c93-8e43-c4bb3eb9fb15
17/03/18 10:40:43 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 10:40:43 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 10:40:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/18 10:40:43 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/03/18 10:40:43 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:46470/jars/sparklyr-2.1-2.11.jar with timestamp 1489830043447
17/03/18 10:40:43 INFO Executor: Starting executor ID driver on host localhost
17/03/18 10:40:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55660.
17/03/18 10:40:43 INFO NettyBlockTransferService: Server created on 127.0.0.1:55660
17/03/18 10:40:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 10:40:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55660, None)
17/03/18 10:40:43 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55660 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 55660, None)
17/03/18 10:40:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55660, None)
17/03/18 10:40:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55660, None)
17/03/18 10:40:43 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 10:40:43 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 10:40:43 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 10:40:44 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 10:40:44 INFO ObjectStore: ObjectStore, initialize called
17/03/18 10:40:44 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 10:40:44 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 10:40:45 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 10:40:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:40:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:40:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:40:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:40:46 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 10:40:46 INFO ObjectStore: Initialized ObjectStore
17/03/18 10:40:46 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 10:40:47 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 10:40:47 INFO HiveMetaStore: Added admin role in metastore
17/03/18 10:40:47 INFO HiveMetaStore: Added public role in metastore
17/03/18 10:40:47 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 10:40:47 INFO HiveMetaStore: 0: get_all_databases
17/03/18 10:40:47 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 10:40:47 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 10:40:47 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 10:40:47 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:40:47 INFO SessionState: Created HDFS directory: /tmp/hive/yannick
17/03/18 10:40:47 INFO SessionState: Created local directory: /tmp/yannick
17/03/18 10:40:47 INFO SessionState: Created local directory: /tmp/35da16ba-befc-4bb7-9d05-c22763a4de50_resources
17/03/18 10:40:47 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/35da16ba-befc-4bb7-9d05-c22763a4de50
17/03/18 10:40:47 INFO SessionState: Created local directory: /tmp/yannick/35da16ba-befc-4bb7-9d05-c22763a4de50
17/03/18 10:40:47 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/35da16ba-befc-4bb7-9d05-c22763a4de50/_tmp_space.db
17/03/18 10:40:47 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 10:40:47 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:40:47 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:40:47 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 10:40:47 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 10:40:47 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 10:41:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:41:34 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:41:34 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:41:34 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:41:34 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:41:34 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:41:34 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:41:35 INFO CodeGenerator: Code generated in 182.863748 ms
17/03/18 10:41:35 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:41:35 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:41:35 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/03/18 10:41:35 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:41:35 INFO DAGScheduler: Missing parents: List()
17/03/18 10:41:35 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:41:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55660 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:41:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/18 10:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/18 10:41:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/03/18 10:41:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/18 10:41:35 INFO Executor: Fetching spark://127.0.0.1:46470/jars/sparklyr-2.1-2.11.jar with timestamp 1489830043447
17/03/18 10:41:35 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:46470 after 9 ms (0 ms spent in bootstraps)
17/03/18 10:41:35 INFO Utils: Fetching spark://127.0.0.1:46470/jars/sparklyr-2.1-2.11.jar to /home/yannick/tmp/sparklyr/spark-c927aecc-934b-465a-a41a-d9833ca9f3a8/userFiles-877bb98b-2d29-4691-bebd-c702818cc047/fetchFileTemp2577237119245160824.tmp
17/03/18 10:41:35 INFO Executor: Adding file:/home/yannick/tmp/sparklyr/spark-c927aecc-934b-465a-a41a-d9833ca9f3a8/userFiles-877bb98b-2d29-4691-bebd-c702818cc047/sparklyr-2.1-2.11.jar to class loader
17/03/18 10:41:35 INFO CodeGenerator: Code generated in 10.264194 ms
17/03/18 10:41:35 INFO CodeGenerator: Code generated in 9.757916 ms
17/03/18 10:41:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/03/18 10:41:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 186 ms on localhost (executor driver) (1/1)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/18 10:41:35 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0,200 s
17/03/18 10:41:35 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 0,315590 s
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:41:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55660 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:41:35 INFO SparkContext: Created broadcast 1 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:41:35 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:41:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:41:35 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:41:35 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:35 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:41:35 INFO DAGScheduler: Missing parents: List()
17/03/18 10:41:35 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:41:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55660 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:41:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/03/18 10:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/18 10:41:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:41:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/18 10:41:35 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:41:35 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/03/18 10:41:35 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/03/18 10:41:35 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/03/18 10:41:35 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/03/18 10:41:35 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/03/18 10:41:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1274 bytes result sent to driver
17/03/18 10:41:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 35 ms on localhost (executor driver) (1/1)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/18 10:41:35 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0,035 s
17/03/18 10:41:35 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0,044466 s
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:41:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55660 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:41:35 INFO SparkContext: Created broadcast 3 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:41:35 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:41:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:41:35 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:41:35 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:35 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:41:35 INFO DAGScheduler: Missing parents: List()
17/03/18 10:41:35 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:41:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55660 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:41:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/03/18 10:41:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/18 10:41:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:41:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/18 10:41:35 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:41:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1274 bytes result sent to driver
17/03/18 10:41:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 7 ms on localhost (executor driver) (1/1)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/18 10:41:35 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0,008 s
17/03/18 10:41:35 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0,013449 s
17/03/18 10:41:35 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:41:35 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
17/03/18 10:41:35 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:35 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:41:35 INFO DAGScheduler: Missing parents: List()
17/03/18 10:41:35 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.7 KB, free 6.2 GB)
17/03/18 10:41:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.0 KB, free 6.2 GB)
17/03/18 10:41:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55660 (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:41:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/03/18 10:41:35 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 3 (MapPartitionsRDD[12] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 2 tasks
17/03/18 10:41:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6046 bytes)
17/03/18 10:41:35 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 4, localhost, executor driver, partition 1, PROCESS_LOCAL, 6046 bytes)
17/03/18 10:41:35 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/18 10:41:35 INFO Executor: Running task 1.0 in stage 3.0 (TID 4)
17/03/18 10:41:35 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:41:35 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:779637+779637
17/03/18 10:41:36 INFO Executor: Finished task 1.0 in stage 3.0 (TID 4). 1824 bytes result sent to driver
17/03/18 10:41:36 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 4) in 119 ms on localhost (executor driver) (1/2)
17/03/18 10:41:36 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1737 bytes result sent to driver
17/03/18 10:41:36 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 126 ms on localhost (executor driver) (2/2)
17/03/18 10:41:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/18 10:41:36 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0,127 s
17/03/18 10:41:36 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0,132322 s
17/03/18 10:41:36 INFO SparkSqlParser: Parsing command: train10k
17/03/18 10:41:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz1`
WHERE (0 = 1)
17/03/18 10:41:36 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:41:36 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:41:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:41:36 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:41:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:41:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:41:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:41:36 INFO CodeGenerator: Code generated in 13.551512 ms
17/03/18 10:41:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:41:55 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:41:55 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:41:55 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:41:55 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:41:55 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:41:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:41:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:41:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:41:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:41:55 INFO CodeGenerator: Code generated in 4.874839 ms
17/03/18 10:41:55 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:41:55 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO SparkContext: Created broadcast 6 from parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:41:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:41:55 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:41:55 INFO DAGScheduler: Got job 4 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:41:55 INFO DAGScheduler: Final stage: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:55 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:41:55 INFO DAGScheduler: Missing parents: List()
17/03/18 10:41:55 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:41:55 INFO ContextCleaner: Cleaned accumulator 0
17/03/18 10:41:55 INFO ContextCleaner: Cleaned accumulator 1
17/03/18 10:41:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55660 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:55660 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55660 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55660 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55660 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55660 in memory (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 88.1 KB, free 6.2 GB)
17/03/18 10:41:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 33.9 KB, free 6.2 GB)
17/03/18 10:41:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55660 (size: 33.9 KB, free: 6.2 GB)
17/03/18 10:41:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/03/18 10:41:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:41:55 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/03/18 10:41:55 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6587 bytes)
17/03/18 10:41:55 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)
17/03/18 10:41:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:41:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:41:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:41:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:41:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:41:55 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:41:56 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:41:56 INFO CodeGenerator: Code generated in 22.841663 ms
17/03/18 10:41:56 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104155_0004_m_000000_0' to file:/home4/yannick4/tmp/train10k.parquet/_temporary/0/task_20170318104155_0004_m_000000
17/03/18 10:41:56 INFO SparkHadoopMapRedUtil: attempt_20170318104155_0004_m_000000_0: Committed
17/03/18 10:41:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 1786 bytes result sent to driver
17/03/18 10:41:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 698 ms on localhost (executor driver) (1/1)
17/03/18 10:41:56 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/18 10:41:56 INFO DAGScheduler: ResultStage 4 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,699 s
17/03/18 10:41:56 INFO DAGScheduler: Job 4 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,737980 s
17/03/18 10:41:56 INFO FileFormatWriter: Job null committed.
17/03/18 10:42:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:42:04 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:42:04 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:42:04 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:42:04 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:42:04 INFO CodeGenerator: Code generated in 8.668484 ms
17/03/18 10:42:04 INFO CodeGenerator: Code generated in 7.769355 ms
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:42:04 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:42:04 INFO SparkContext: Created broadcast 8 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:42:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:42:04 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:42:04 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:42:04 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/03/18 10:42:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/03/18 10:42:04 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 14.1 KB, free 6.2 GB)
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.9 KB, free 6.2 GB)
17/03/18 10:42:04 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55660 (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:42:04 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/03/18 10:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/18 10:42:04 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6568 bytes)
17/03/18 10:42:04 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
17/03/18 10:42:04 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:42:04 INFO CodeGenerator: Code generated in 5.445394 ms
17/03/18 10:42:04 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 2053 bytes result sent to driver
17/03/18 10:42:04 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 55 ms on localhost (executor driver) (1/1)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/18 10:42:04 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0,056 s
17/03/18 10:42:04 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:42:04 INFO DAGScheduler: running: Set()
17/03/18 10:42:04 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/03/18 10:42:04 INFO DAGScheduler: failed: Set()
17/03/18 10:42:04 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:42:04 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55660 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:42:04 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/03/18 10:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/03/18 10:42:04 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/03/18 10:42:04 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/03/18 10:42:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:42:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/03/18 10:42:04 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 2042 bytes result sent to driver
17/03/18 10:42:04 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 24 ms on localhost (executor driver) (1/1)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/18 10:42:04 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0,024 s
17/03/18 10:42:04 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0,106635 s
17/03/18 10:42:04 INFO CodeGenerator: Code generated in 5.971052 ms
17/03/18 10:42:04 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:42:04 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:42:04 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:42:04 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:42:04 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:42:04 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:42:04 INFO SparkContext: Created broadcast 11 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:42:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:42:04 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:42:04 INFO DAGScheduler: Registering RDD 26 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:42:04 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/03/18 10:42:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/03/18 10:42:04 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.1 KB, free 6.2 GB)
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 7.9 KB, free 6.2 GB)
17/03/18 10:42:04 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55660 (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:42:04 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/03/18 10:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/03/18 10:42:04 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6568 bytes)
17/03/18 10:42:04 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
17/03/18 10:42:04 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:42:04 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 1966 bytes result sent to driver
17/03/18 10:42:04 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 27 ms on localhost (executor driver) (1/1)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/18 10:42:04 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0,028 s
17/03/18 10:42:04 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:42:04 INFO DAGScheduler: running: Set()
17/03/18 10:42:04 INFO DAGScheduler: waiting: Set(ResultStage 8)
17/03/18 10:42:04 INFO DAGScheduler: failed: Set()
17/03/18 10:42:04 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:42:04 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:42:04 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55660 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:42:04 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/03/18 10:42:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/03/18 10:42:04 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/03/18 10:42:04 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
17/03/18 10:42:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:42:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:42:04 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 2042 bytes result sent to driver
17/03/18 10:42:04 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 6 ms on localhost (executor driver) (1/1)
17/03/18 10:42:04 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/18 10:42:04 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0,006 s
17/03/18 10:42:04 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0,043783 s
17/03/18 10:42:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
LIMIT 10
17/03/18 10:42:05 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:42:05 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:42:05 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:42:05 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:42:05 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:42:05 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:42:05 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:42:05 INFO SparkContext: Created broadcast 14 from collect at utils.scala:197
17/03/18 10:42:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:42:05 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:42:05 INFO DAGScheduler: Got job 7 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:42:05 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:197)
17/03/18 10:42:05 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:42:05 INFO DAGScheduler: Missing parents: List()
17/03/18 10:42:05 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[32] at collect at utils.scala:197), which has no missing parents
17/03/18 10:42:05 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 12.8 KB, free 6.2 GB)
17/03/18 10:42:05 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 7.1 KB, free 6.2 GB)
17/03/18 10:42:05 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:55660 (size: 7.1 KB, free: 6.2 GB)
17/03/18 10:42:05 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/03/18 10:42:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[32] at collect at utils.scala:197)
17/03/18 10:42:05 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/03/18 10:42:05 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 10, localhost, executor driver, partition 0, PROCESS_LOCAL, 6494 bytes)
17/03/18 10:42:05 INFO Executor: Running task 0.0 in stage 9.0 (TID 10)
17/03/18 10:42:05 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:42:05 INFO Executor: Finished task 0.0 in stage 9.0 (TID 10). 2292 bytes result sent to driver
17/03/18 10:42:05 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 10) in 11 ms on localhost (executor driver) (1/1)
17/03/18 10:42:05 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/18 10:42:05 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:197) finished in 0,012 s
17/03/18 10:42:05 INFO DAGScheduler: Job 7 finished: collect at utils.scala:197, took 0,016985 s
17/03/18 10:42:05 INFO CodeGenerator: Code generated in 29.462597 ms
17/03/18 10:42:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:42:13 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:42:13 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:42:13 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:42:13 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:42:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:42:13 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:42:13 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:42:13 INFO DAGScheduler: Got job 8 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:42:13 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:59)
17/03/18 10:42:13 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:42:13 INFO DAGScheduler: Missing parents: List()
17/03/18 10:42:13 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[38] at map at utils.scala:56), which has no missing parents
17/03/18 10:42:13 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:42:13 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:42:13 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:55660 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:42:13 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/03/18 10:42:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[38] at map at utils.scala:56)
17/03/18 10:42:13 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/03/18 10:42:13 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6357 bytes)
17/03/18 10:42:13 INFO Executor: Running task 0.0 in stage 10.0 (TID 11)
17/03/18 10:42:13 INFO Executor: Finished task 0.0 in stage 10.0 (TID 11). 1329 bytes result sent to driver
17/03/18 10:42:13 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 11) in 6 ms on localhost (executor driver) (1/1)
17/03/18 10:42:13 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/18 10:42:13 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:59) finished in 0,007 s
17/03/18 10:42:13 INFO DAGScheduler: Job 8 finished: collect at utils.scala:59, took 0,010847 s
17/03/18 10:43:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:43:57 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:43:57 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:43:57 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:43:57 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:43:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:43:57 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:43:58 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:43:58 INFO DAGScheduler: Got job 9 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:43:58 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:59)
17/03/18 10:43:58 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:43:58 INFO DAGScheduler: Missing parents: List()
17/03/18 10:43:58 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[44] at map at utils.scala:56), which has no missing parents
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:55660 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/03/18 10:43:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[44] at map at utils.scala:56)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/03/18 10:43:58 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:43:58 INFO Executor: Running task 0.0 in stage 11.0 (TID 12)
17/03/18 10:43:58 INFO Executor: Finished task 0.0 in stage 11.0 (TID 12). 1318 bytes result sent to driver
17/03/18 10:43:58 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 12) in 6 ms on localhost (executor driver) (1/1)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/03/18 10:43:58 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:59) finished in 0,007 s
17/03/18 10:43:58 INFO DAGScheduler: Job 9 finished: collect at utils.scala:59, took 0,012741 s
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:55660 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO SparkContext: Created broadcast 18 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:43:58 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:43:58 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:43:58 INFO DAGScheduler: Got job 10 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:43:58 INFO DAGScheduler: Final stage: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:43:58 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:43:58 INFO DAGScheduler: Missing parents: List()
17/03/18 10:43:58 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[47] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:55660 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/03/18 10:43:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[47] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/03/18 10:43:58 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6043 bytes)
17/03/18 10:43:58 INFO Executor: Running task 0.0 in stage 12.0 (TID 13)
17/03/18 10:43:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:43:58 INFO Executor: Finished task 0.0 in stage 12.0 (TID 13). 1361 bytes result sent to driver
17/03/18 10:43:58 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 13) in 7 ms on localhost (executor driver) (1/1)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/03/18 10:43:58 INFO DAGScheduler: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0) finished in 0,008 s
17/03/18 10:43:58 INFO DAGScheduler: Job 10 finished: csv at NativeMethodAccessorImpl.java:0, took 0,012283 s
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:55660 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO SparkContext: Created broadcast 20 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:43:58 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:43:58 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:43:58 INFO DAGScheduler: Got job 11 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:43:58 INFO DAGScheduler: Final stage: ResultStage 13 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:43:58 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:43:58 INFO DAGScheduler: Missing parents: List()
17/03/18 10:43:58 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:55660 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/03/18 10:43:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/03/18 10:43:58 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6043 bytes)
17/03/18 10:43:58 INFO Executor: Running task 0.0 in stage 13.0 (TID 14)
17/03/18 10:43:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:55660 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO Executor: Finished task 0.0 in stage 13.0 (TID 14). 1347 bytes result sent to driver
17/03/18 10:43:58 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 14) in 22 ms on localhost (executor driver) (1/1)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/03/18 10:43:58 INFO DAGScheduler: ResultStage 13 (csv at NativeMethodAccessorImpl.java:0) finished in 0,023 s
17/03/18 10:43:58 INFO DAGScheduler: Job 11 finished: csv at NativeMethodAccessorImpl.java:0, took 0,028041 s
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:55660 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:55660 in memory (size: 7.1 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 541
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 542
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:55660 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 591
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 592
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 389
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 390
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 391
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 392
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 393
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55660 in memory (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO ContextCleaner: Cleaned shuffle 1
17/03/18 10:43:58 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:43:58 INFO DAGScheduler: Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
17/03/18 10:43:58 INFO DAGScheduler: Final stage: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55660 in memory (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:43:58 INFO DAGScheduler: Missing parents: List()
17/03/18 10:43:58 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[51] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55660 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 7.7 KB, free 6.2 GB)
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 270
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 271
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 272
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 273
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 274
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 275
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 276
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 277
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 278
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 279
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 280
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 281
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 282
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 283
17/03/18 10:43:58 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.0 KB, free 6.2 GB)
17/03/18 10:43:58 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:55660 (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:55660 in memory (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[51] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Adding task set 14.0 with 2 tasks
17/03/18 10:43:58 INFO ContextCleaner: Cleaned shuffle 0
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55660 in memory (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6047 bytes)
17/03/18 10:43:58 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 6047 bytes)
17/03/18 10:43:58 INFO Executor: Running task 0.0 in stage 14.0 (TID 15)
17/03/18 10:43:58 INFO Executor: Running task 1.0 in stage 14.0 (TID 16)
17/03/18 10:43:58 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55660 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 380
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 381
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 382
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 383
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 384
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 385
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 386
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 387
17/03/18 10:43:58 INFO ContextCleaner: Cleaned accumulator 388
17/03/18 10:43:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:43:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:779637+779637
17/03/18 10:43:58 INFO Executor: Finished task 0.0 in stage 14.0 (TID 15). 1737 bytes result sent to driver
17/03/18 10:43:58 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 15) in 95 ms on localhost (executor driver) (1/2)
17/03/18 10:43:58 INFO Executor: Finished task 1.0 in stage 14.0 (TID 16). 1737 bytes result sent to driver
17/03/18 10:43:58 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 16) in 97 ms on localhost (executor driver) (2/2)
17/03/18 10:43:58 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/03/18 10:43:58 INFO DAGScheduler: ResultStage 14 (csv at NativeMethodAccessorImpl.java:0) finished in 0,100 s
17/03/18 10:43:58 INFO DAGScheduler: Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0,104589 s
17/03/18 10:43:58 INFO SparkSqlParser: Parsing command: train10k
17/03/18 10:43:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz2`
WHERE (0 = 1)
17/03/18 10:43:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:43:58 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:43:58 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:43:58 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:43:58 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:43:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:43:58 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:44:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:44:01 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:44:01 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:44:01 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:44:01 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:44:01 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:44:01 INFO SparkContext: Created broadcast 23 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:44:01 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:01 INFO DAGScheduler: Registering RDD 56 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:01 INFO DAGScheduler: Got job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:44:01 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:01 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/03/18 10:44:01 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
17/03/18 10:44:01 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 14.1 KB, free 6.2 GB)
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 7.9 KB, free 6.2 GB)
17/03/18 10:44:01 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:55660 (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:44:01 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:01 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[56] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:01 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/03/18 10:44:01 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6569 bytes)
17/03/18 10:44:01 INFO Executor: Running task 0.0 in stage 15.0 (TID 17)
17/03/18 10:44:01 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:44:01 INFO Executor: Finished task 0.0 in stage 15.0 (TID 17). 1966 bytes result sent to driver
17/03/18 10:44:01 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 17) in 37 ms on localhost (executor driver) (1/1)
17/03/18 10:44:01 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/03/18 10:44:01 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0,037 s
17/03/18 10:44:01 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:44:01 INFO DAGScheduler: running: Set()
17/03/18 10:44:01 INFO DAGScheduler: waiting: Set(ResultStage 16)
17/03/18 10:44:01 INFO DAGScheduler: failed: Set()
17/03/18 10:44:01 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:44:01 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:55660 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:44:01 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[59] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:01 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/03/18 10:44:01 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 18, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/03/18 10:44:01 INFO Executor: Running task 0.0 in stage 16.0 (TID 18)
17/03/18 10:44:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:44:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:44:01 INFO Executor: Finished task 0.0 in stage 16.0 (TID 18). 2042 bytes result sent to driver
17/03/18 10:44:01 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 18) in 5 ms on localhost (executor driver) (1/1)
17/03/18 10:44:01 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/03/18 10:44:01 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0,005 s
17/03/18 10:44:01 INFO DAGScheduler: Job 13 finished: count at NativeMethodAccessorImpl.java:0, took 0,052354 s
17/03/18 10:44:01 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:44:01 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:44:01 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:44:01 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:44:01 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:44:01 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:44:02 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:44:02 INFO SparkContext: Created broadcast 26 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:44:02 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:02 INFO DAGScheduler: Registering RDD 62 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:02 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:44:02 INFO DAGScheduler: Final stage: ResultStage 18 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/03/18 10:44:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
17/03/18 10:44:02 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 14.1 KB, free 6.2 GB)
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 7.9 KB, free 6.2 GB)
17/03/18 10:44:02 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:55660 (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:44:02 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:02 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[62] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:02 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/03/18 10:44:02 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 19, localhost, executor driver, partition 0, PROCESS_LOCAL, 6569 bytes)
17/03/18 10:44:02 INFO Executor: Running task 0.0 in stage 17.0 (TID 19)
17/03/18 10:44:02 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:44:02 INFO Executor: Finished task 0.0 in stage 17.0 (TID 19). 1966 bytes result sent to driver
17/03/18 10:44:02 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 19) in 30 ms on localhost (executor driver) (1/1)
17/03/18 10:44:02 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/03/18 10:44:02 INFO DAGScheduler: ShuffleMapStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0,031 s
17/03/18 10:44:02 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:44:02 INFO DAGScheduler: running: Set()
17/03/18 10:44:02 INFO DAGScheduler: waiting: Set(ResultStage 18)
17/03/18 10:44:02 INFO DAGScheduler: failed: Set()
17/03/18 10:44:02 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:44:02 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:55660 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:44:02 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[65] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:02 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/03/18 10:44:02 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 20, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/03/18 10:44:02 INFO Executor: Running task 0.0 in stage 18.0 (TID 20)
17/03/18 10:44:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:44:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:44:02 INFO Executor: Finished task 0.0 in stage 18.0 (TID 20). 2042 bytes result sent to driver
17/03/18 10:44:02 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 20) in 3 ms on localhost (executor driver) (1/1)
17/03/18 10:44:02 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/03/18 10:44:02 INFO DAGScheduler: ResultStage 18 (count at NativeMethodAccessorImpl.java:0) finished in 0,004 s
17/03/18 10:44:02 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0,041763 s
17/03/18 10:44:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
LIMIT 10
17/03/18 10:44:02 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:44:02 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:44:02 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:44:02 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:44:02 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:44:02 INFO SparkContext: Created broadcast 29 from collect at utils.scala:197
17/03/18 10:44:02 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:44:02 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:44:02 INFO DAGScheduler: Got job 15 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:44:02 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:197)
17/03/18 10:44:02 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:44:02 INFO DAGScheduler: Missing parents: List()
17/03/18 10:44:02 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:197), which has no missing parents
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.8 KB, free 6.2 GB)
17/03/18 10:44:02 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.1 KB, free 6.2 GB)
17/03/18 10:44:02 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:55660 (size: 7.1 KB, free: 6.2 GB)
17/03/18 10:44:02 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[68] at collect at utils.scala:197)
17/03/18 10:44:02 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/03/18 10:44:02 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 21, localhost, executor driver, partition 0, PROCESS_LOCAL, 6495 bytes)
17/03/18 10:44:02 INFO Executor: Running task 0.0 in stage 19.0 (TID 21)
17/03/18 10:44:02 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:44:02 INFO Executor: Finished task 0.0 in stage 19.0 (TID 21). 2292 bytes result sent to driver
17/03/18 10:44:02 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 21) in 9 ms on localhost (executor driver) (1/1)
17/03/18 10:44:02 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/03/18 10:44:02 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:197) finished in 0,009 s
17/03/18 10:44:02 INFO DAGScheduler: Job 15 finished: collect at utils.scala:197, took 0,012930 s
17/03/18 10:44:19 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `cnt`
FROM `train10k`
17/03/18 10:44:19 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:44:19 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:44:19 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:44:19 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:44:19 INFO CodeGenerator: Code generated in 19.27673 ms
17/03/18 10:44:19 INFO CodeGenerator: Code generated in 10.451617 ms
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 31 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:44:19 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:19 INFO DAGScheduler: Registering RDD 71 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:44:19 INFO DAGScheduler: Final stage: ResultStage 21 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
17/03/18 10:44:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 20)
17/03/18 10:44:19 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 12.7 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 7.3 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:55660 (size: 7.3 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/03/18 10:44:19 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6570 bytes)
17/03/18 10:44:19 INFO Executor: Running task 0.0 in stage 20.0 (TID 22)
17/03/18 10:44:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:44:19 INFO Executor: Finished task 0.0 in stage 20.0 (TID 22). 1966 bytes result sent to driver
17/03/18 10:44:19 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 22) in 29 ms on localhost (executor driver) (1/1)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/03/18 10:44:19 INFO DAGScheduler: ShuffleMapStage 20 (count at NativeMethodAccessorImpl.java:0) finished in 0,030 s
17/03/18 10:44:19 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:44:19 INFO DAGScheduler: running: Set()
17/03/18 10:44:19 INFO DAGScheduler: waiting: Set(ResultStage 21)
17/03/18 10:44:19 INFO DAGScheduler: failed: Set()
17/03/18 10:44:19 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[74] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 9.6 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 4.1 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:55660 (size: 4.1 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[74] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/03/18 10:44:19 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 23, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 10:44:19 INFO Executor: Running task 0.0 in stage 21.0 (TID 23)
17/03/18 10:44:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:44:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:44:19 INFO Executor: Finished task 0.0 in stage 21.0 (TID 23). 2445 bytes result sent to driver
17/03/18 10:44:19 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 23) in 5 ms on localhost (executor driver) (1/1)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/03/18 10:44:19 INFO DAGScheduler: ResultStage 21 (count at NativeMethodAccessorImpl.java:0) finished in 0,005 s
17/03/18 10:44:19 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0,043181 s
17/03/18 10:44:19 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `cnt`
FROM `train10k`
17/03/18 10:44:19 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:44:19 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:44:19 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:44:19 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 34 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:44:19 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:44:19 INFO DAGScheduler: Registering RDD 77 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO DAGScheduler: Got job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:44:19 INFO DAGScheduler: Final stage: ResultStage 23 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
17/03/18 10:44:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 22)
17/03/18 10:44:19 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 12.7 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 7.3 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:55660 (size: 7.3 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/03/18 10:44:19 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 24, localhost, executor driver, partition 0, PROCESS_LOCAL, 6570 bytes)
17/03/18 10:44:19 INFO Executor: Running task 0.0 in stage 22.0 (TID 24)
17/03/18 10:44:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:44:19 INFO Executor: Finished task 0.0 in stage 22.0 (TID 24). 1966 bytes result sent to driver
17/03/18 10:44:19 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 24) in 25 ms on localhost (executor driver) (1/1)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/03/18 10:44:19 INFO DAGScheduler: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0,025 s
17/03/18 10:44:19 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:44:19 INFO DAGScheduler: running: Set()
17/03/18 10:44:19 INFO DAGScheduler: waiting: Set(ResultStage 23)
17/03/18 10:44:19 INFO DAGScheduler: failed: Set()
17/03/18 10:44:19 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[80] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 9.6 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 4.1 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:55660 (size: 4.1 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[80] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/03/18 10:44:19 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 25, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 10:44:19 INFO Executor: Running task 0.0 in stage 23.0 (TID 25)
17/03/18 10:44:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:44:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:44:19 INFO Executor: Finished task 0.0 in stage 23.0 (TID 25). 2358 bytes result sent to driver
17/03/18 10:44:19 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 25) in 3 ms on localhost (executor driver) (1/1)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/03/18 10:44:19 INFO DAGScheduler: ResultStage 23 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 10:44:19 INFO DAGScheduler: Job 17 finished: count at NativeMethodAccessorImpl.java:0, took 0,035210 s
17/03/18 10:44:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT count(*) AS `cnt`
FROM `train10k`) `vtazobcsym`
LIMIT 1
17/03/18 10:44:19 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:44:19 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:44:19 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:44:19 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:55660 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 37 from collect at utils.scala:197
17/03/18 10:44:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:44:19 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:44:19 INFO DAGScheduler: Registering RDD 83 (collect at utils.scala:197)
17/03/18 10:44:19 INFO DAGScheduler: Got job 18 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:44:19 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:197)
17/03/18 10:44:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 24)
17/03/18 10:44:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 24)
17/03/18 10:44:19 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[83] at collect at utils.scala:197), which has no missing parents
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 14.1 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 7.9 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:55660 (size: 7.9 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:19 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[83] at collect at utils.scala:197)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/03/18 10:44:19 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 26, localhost, executor driver, partition 0, PROCESS_LOCAL, 6484 bytes)
17/03/18 10:44:19 INFO Executor: Running task 0.0 in stage 24.0 (TID 26)
17/03/18 10:44:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:44:19 INFO Executor: Finished task 0.0 in stage 24.0 (TID 26). 1966 bytes result sent to driver
17/03/18 10:44:19 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 26) in 25 ms on localhost (executor driver) (1/1)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/03/18 10:44:19 INFO DAGScheduler: ShuffleMapStage 24 (collect at utils.scala:197) finished in 0,025 s
17/03/18 10:44:19 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:44:19 INFO DAGScheduler: running: Set()
17/03/18 10:44:19 INFO DAGScheduler: waiting: Set(ResultStage 25)
17/03/18 10:44:19 INFO DAGScheduler: failed: Set()
17/03/18 10:44:19 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:197), which has no missing parents
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 6.9 KB, free 6.2 GB)
17/03/18 10:44:19 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:44:19 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:55660 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:44:19 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:996
17/03/18 10:44:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[86] at collect at utils.scala:197)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/03/18 10:44:19 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 27, localhost, executor driver, partition 0, ANY, 5861 bytes)
17/03/18 10:44:19 INFO Executor: Running task 0.0 in stage 25.0 (TID 27)
17/03/18 10:44:19 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 10:44:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:44:19 INFO Executor: Finished task 0.0 in stage 25.0 (TID 27). 1939 bytes result sent to driver
17/03/18 10:44:19 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 27) in 3 ms on localhost (executor driver) (1/1)
17/03/18 10:44:19 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/03/18 10:44:19 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:197) finished in 0,003 s
17/03/18 10:44:19 INFO DAGScheduler: Job 18 finished: collect at utils.scala:197, took 0,036655 s
17/03/18 10:45:03 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 10:45:03 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/03/18 10:45:03 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 10:45:03 INFO MemoryStore: MemoryStore cleared
17/03/18 10:45:03 INFO BlockManager: BlockManager stopped
17/03/18 10:45:03 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 10:45:03 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 10:45:03 INFO SparkContext: Successfully stopped SparkContext
17/03/18 10:45:03 INFO ShutdownHookManager: Shutdown hook called
17/03/18 10:45:03 INFO ShutdownHookManager: Deleting directory /home/yannick/tmp/sparklyr/spark-c927aecc-934b-465a-a41a-d9833ca9f3a8
17/03/18 10:45:12 INFO SparkContext: Running Spark version 2.1.0
17/03/18 10:45:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 10:45:12 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 10:45:12 INFO SecurityManager: Changing view acls to: yannick
17/03/18 10:45:12 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 10:45:12 INFO SecurityManager: Changing view acls groups to: 
17/03/18 10:45:12 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 10:45:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 10:45:12 INFO Utils: Successfully started service 'sparkDriver' on port 48038.
17/03/18 10:45:12 INFO SparkEnv: Registering MapOutputTracker
17/03/18 10:45:12 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 10:45:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 10:45:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 10:45:12 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-44377f2f-9dd9-4e50-8b2d-28a0b35d4cbb
17/03/18 10:45:12 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 10:45:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 10:45:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/18 10:45:12 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/03/18 10:45:13 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:48038/jars/sparklyr-2.1-2.11.jar with timestamp 1489830313004
17/03/18 10:45:13 INFO Executor: Starting executor ID driver on host localhost
17/03/18 10:45:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 55581.
17/03/18 10:45:13 INFO NettyBlockTransferService: Server created on 127.0.0.1:55581
17/03/18 10:45:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 10:45:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 55581, None)
17/03/18 10:45:13 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:55581 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 55581, None)
17/03/18 10:45:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 55581, None)
17/03/18 10:45:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 55581, None)
17/03/18 10:45:13 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 10:45:13 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 10:45:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 10:45:13 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 10:45:13 INFO ObjectStore: ObjectStore, initialize called
17/03/18 10:45:13 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 10:45:13 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 10:45:14 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 10:45:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:45:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:45:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:45:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:45:15 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 10:45:15 INFO ObjectStore: Initialized ObjectStore
17/03/18 10:45:15 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 10:45:16 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 10:45:16 INFO HiveMetaStore: Added admin role in metastore
17/03/18 10:45:16 INFO HiveMetaStore: Added public role in metastore
17/03/18 10:45:16 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 10:45:16 INFO HiveMetaStore: 0: get_all_databases
17/03/18 10:45:16 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 10:45:16 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 10:45:16 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 10:45:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:45:16 INFO SessionState: Created local directory: /tmp/41eba43b-7e7b-4ad5-a7fb-d9f1b1bb2990_resources
17/03/18 10:45:16 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/41eba43b-7e7b-4ad5-a7fb-d9f1b1bb2990
17/03/18 10:45:16 INFO SessionState: Created local directory: /tmp/yannick/41eba43b-7e7b-4ad5-a7fb-d9f1b1bb2990
17/03/18 10:45:16 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/41eba43b-7e7b-4ad5-a7fb-d9f1b1bb2990/_tmp_space.db
17/03/18 10:45:16 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 10:45:16 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:45:16 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:45:16 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 10:45:16 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 10:45:16 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 10:45:49 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:45:51 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:45:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:45:51 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:45:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:45:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:45:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:45:51 INFO CodeGenerator: Code generated in 182.58307 ms
17/03/18 10:45:51 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:45:51 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:45:51 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/03/18 10:45:51 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:45:51 INFO DAGScheduler: Missing parents: List()
17/03/18 10:45:51 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/03/18 10:45:51 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:45:51 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:45:51 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:55581 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:45:51 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/18 10:45:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/03/18 10:45:51 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/18 10:45:51 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/03/18 10:45:51 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/18 10:45:51 INFO Executor: Fetching spark://127.0.0.1:48038/jars/sparklyr-2.1-2.11.jar with timestamp 1489830313004
17/03/18 10:45:51 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:48038 after 9 ms (0 ms spent in bootstraps)
17/03/18 10:45:51 INFO Utils: Fetching spark://127.0.0.1:48038/jars/sparklyr-2.1-2.11.jar to /home/yannick/tmp/sparklyr/spark-cb6a98fb-4e31-4cba-aecd-049fcc2ced12/userFiles-55e13be5-e549-43f0-81ce-70f8ca233f7e/fetchFileTemp679455420649597319.tmp
17/03/18 10:45:51 INFO Executor: Adding file:/home/yannick/tmp/sparklyr/spark-cb6a98fb-4e31-4cba-aecd-049fcc2ced12/userFiles-55e13be5-e549-43f0-81ce-70f8ca233f7e/sparklyr-2.1-2.11.jar to class loader
17/03/18 10:45:51 INFO CodeGenerator: Code generated in 10.737938 ms
17/03/18 10:45:51 INFO CodeGenerator: Code generated in 10.446329 ms
17/03/18 10:45:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/03/18 10:45:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 182 ms on localhost (executor driver) (1/1)
17/03/18 10:45:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/18 10:45:51 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0,196 s
17/03/18 10:45:51 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 0,304398 s
17/03/18 10:46:12 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:46:12 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:46:12 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:46:12 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:46:12 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:46:12 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:46:12 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:46:12 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:46:12 INFO DAGScheduler: Got job 1 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:46:12 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:59)
17/03/18 10:46:12 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:46:12 INFO DAGScheduler: Missing parents: List()
17/03/18 10:46:12 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at map at utils.scala:56), which has no missing parents
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:55581 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/03/18 10:46:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at map at utils.scala:56)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/18 10:46:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:46:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/18 10:46:12 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1231 bytes result sent to driver
17/03/18 10:46:12 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 8 ms on localhost (executor driver) (1/1)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/18 10:46:12 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:59) finished in 0,009 s
17/03/18 10:46:12 INFO DAGScheduler: Job 1 finished: collect at utils.scala:59, took 0,015395 s
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:55581 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:46:12 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:46:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:46:12 INFO DAGScheduler: Got job 2 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:46:12 INFO DAGScheduler: Final stage: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:46:12 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:46:12 INFO DAGScheduler: Missing parents: List()
17/03/18 10:46:12 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:55581 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/03/18 10:46:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/18 10:46:12 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:46:12 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/18 10:46:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:46:12 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/03/18 10:46:12 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/03/18 10:46:12 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/03/18 10:46:12 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/03/18 10:46:12 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/03/18 10:46:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1274 bytes result sent to driver
17/03/18 10:46:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 29 ms on localhost (executor driver) (1/1)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/18 10:46:12 INFO DAGScheduler: ResultStage 2 (csv at NativeMethodAccessorImpl.java:0) finished in 0,030 s
17/03/18 10:46:12 INFO DAGScheduler: Job 2 finished: csv at NativeMethodAccessorImpl.java:0, took 0,037104 s
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:55581 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO SparkContext: Created broadcast 4 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:46:12 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:46:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:46:12 INFO DAGScheduler: Got job 3 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:46:12 INFO DAGScheduler: Final stage: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:46:12 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:46:12 INFO DAGScheduler: Missing parents: List()
17/03/18 10:46:12 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:55581 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/03/18 10:46:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/18 10:46:12 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:46:12 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/18 10:46:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:46:12 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1274 bytes result sent to driver
17/03/18 10:46:12 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 6 ms on localhost (executor driver) (1/1)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/18 10:46:12 INFO DAGScheduler: ResultStage 3 (csv at NativeMethodAccessorImpl.java:0) finished in 0,007 s
17/03/18 10:46:12 INFO DAGScheduler: Job 3 finished: csv at NativeMethodAccessorImpl.java:0, took 0,011659 s
17/03/18 10:46:12 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:46:12 INFO DAGScheduler: Got job 4 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
17/03/18 10:46:12 INFO DAGScheduler: Final stage: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:46:12 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:46:12 INFO DAGScheduler: Missing parents: List()
17/03/18 10:46:12 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[18] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.7 KB, free 6.2 GB)
17/03/18 10:46:12 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.0 KB, free 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:55581 (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/03/18 10:46:12 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[18] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 2 tasks
17/03/18 10:46:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6046 bytes)
17/03/18 10:46:12 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 6046 bytes)
17/03/18 10:46:12 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/03/18 10:46:12 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
17/03/18 10:46:12 INFO ContextCleaner: Cleaned accumulator 0
17/03/18 10:46:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:46:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:779637+779637
17/03/18 10:46:12 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:55581 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:55581 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO ContextCleaner: Cleaned accumulator 1
17/03/18 10:46:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:55581 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO ContextCleaner: Cleaned accumulator 50
17/03/18 10:46:12 INFO ContextCleaner: Cleaned accumulator 51
17/03/18 10:46:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:55581 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:46:12 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1824 bytes result sent to driver
17/03/18 10:46:12 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 121 ms on localhost (executor driver) (1/2)
17/03/18 10:46:12 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 1824 bytes result sent to driver
17/03/18 10:46:12 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 124 ms on localhost (executor driver) (2/2)
17/03/18 10:46:12 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/18 10:46:12 INFO DAGScheduler: ResultStage 4 (csv at NativeMethodAccessorImpl.java:0) finished in 0,127 s
17/03/18 10:46:12 INFO DAGScheduler: Job 4 finished: csv at NativeMethodAccessorImpl.java:0, took 0,159853 s
17/03/18 10:46:13 INFO SparkSqlParser: Parsing command: train10k
17/03/18 10:46:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz1`
WHERE (0 = 1)
17/03/18 10:46:13 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:46:13 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:46:13 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:46:13 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:46:13 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:46:13 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:46:13 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:46:13 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:46:13 INFO CodeGenerator: Code generated in 12.046171 ms
17/03/18 10:47:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:47:21 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:47:21 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:47:21 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:47:21 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:47:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:47:21 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:47:21 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:47:21 INFO DAGScheduler: Got job 5 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:47:21 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:59)
17/03/18 10:47:21 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:21 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:21 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at map at utils.scala:56), which has no missing parents
17/03/18 10:47:21 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:47:21 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:47:21 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:55581 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:47:21 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at map at utils.scala:56)
17/03/18 10:47:21 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/18 10:47:21 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6357 bytes)
17/03/18 10:47:21 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
17/03/18 10:47:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 1242 bytes result sent to driver
17/03/18 10:47:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 8 ms on localhost (executor driver) (1/1)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/18 10:47:22 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:59) finished in 0,009 s
17/03/18 10:47:22 INFO DAGScheduler: Job 5 finished: collect at utils.scala:59, took 0,014594 s
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:55581 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 8 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:47:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO DAGScheduler: Got job 6 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:47:22 INFO DAGScheduler: Final stage: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:22 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:22 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[29] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:55581 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[29] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/03/18 10:47:22 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:47:22 INFO Executor: Running task 0.0 in stage 6.0 (TID 7)
17/03/18 10:47:22 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:47:22 INFO Executor: Finished task 0.0 in stage 6.0 (TID 7). 1274 bytes result sent to driver
17/03/18 10:47:22 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 7) in 7 ms on localhost (executor driver) (1/1)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/18 10:47:22 INFO DAGScheduler: ResultStage 6 (csv at NativeMethodAccessorImpl.java:0) finished in 0,008 s
17/03/18 10:47:22 INFO DAGScheduler: Job 6 finished: csv at NativeMethodAccessorImpl.java:0, took 0,013788 s
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:55581 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 10 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:47:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO DAGScheduler: Got job 7 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:47:22 INFO DAGScheduler: Final stage: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:22 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:22 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[32] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:55581 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[32] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/03/18 10:47:22 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 10:47:22 INFO Executor: Running task 0.0 in stage 7.0 (TID 8)
17/03/18 10:47:22 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:47:22 INFO Executor: Finished task 0.0 in stage 7.0 (TID 8). 1274 bytes result sent to driver
17/03/18 10:47:22 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 7 ms on localhost (executor driver) (1/1)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/18 10:47:22 INFO DAGScheduler: ResultStage 7 (csv at NativeMethodAccessorImpl.java:0) finished in 0,008 s
17/03/18 10:47:22 INFO DAGScheduler: Job 7 finished: csv at NativeMethodAccessorImpl.java:0, took 0,013841 s
17/03/18 10:47:22 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO DAGScheduler: Got job 8 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
17/03/18 10:47:22 INFO DAGScheduler: Final stage: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:22 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:22 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[33] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.7 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.0 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:55581 (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:22 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[33] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Adding task set 8.0 with 2 tasks
17/03/18 10:47:22 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6046 bytes)
17/03/18 10:47:22 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 10, localhost, executor driver, partition 1, PROCESS_LOCAL, 6046 bytes)
17/03/18 10:47:22 INFO Executor: Running task 0.0 in stage 8.0 (TID 9)
17/03/18 10:47:22 INFO Executor: Running task 1.0 in stage 8.0 (TID 10)
17/03/18 10:47:22 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:0+779637
17/03/18 10:47:22 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train10k.csv:779637+779637
17/03/18 10:47:22 INFO Executor: Finished task 0.0 in stage 8.0 (TID 9). 1737 bytes result sent to driver
17/03/18 10:47:22 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 9) in 74 ms on localhost (executor driver) (1/2)
17/03/18 10:47:22 INFO Executor: Finished task 1.0 in stage 8.0 (TID 10). 1737 bytes result sent to driver
17/03/18 10:47:22 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 10) in 94 ms on localhost (executor driver) (2/2)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/18 10:47:22 INFO DAGScheduler: ResultStage 8 (csv at NativeMethodAccessorImpl.java:0) finished in 0,096 s
17/03/18 10:47:22 INFO DAGScheduler: Job 8 finished: csv at NativeMethodAccessorImpl.java:0, took 0,101558 s
17/03/18 10:47:22 INFO SparkSqlParser: Parsing command: train10k
17/03/18 10:47:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz2`
WHERE (0 = 1)
17/03/18 10:47:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 10:47:22 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:47:22 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:47:22 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:47:22 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:47:22 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:47:22 INFO CodeGenerator: Code generated in 4.887612 ms
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:55581 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 13 from parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:47:22 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:47:22 INFO DAGScheduler: Got job 9 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:47:22 INFO DAGScheduler: Final stage: ResultStage 9 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:22 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:22 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[36] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 88.1 KB, free 6.2 GB)
17/03/18 10:47:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 33.8 KB, free 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:55581 (size: 33.8 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[36] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:22 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/03/18 10:47:22 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6587 bytes)
17/03/18 10:47:22 INFO Executor: Running task 0.0 in stage 9.0 (TID 11)
17/03/18 10:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:47:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:47:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:47:22 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:47:22 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:47:22 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 10:47:22 INFO CodeGenerator: Code generated in 22.231727 ms
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:55581 in memory (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:55581 in memory (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO ContextCleaner: Cleaned accumulator 269
17/03/18 10:47:22 INFO ContextCleaner: Cleaned accumulator 270
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:55581 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:55581 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:55581 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:55581 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:22 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:55581 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:55581 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:55581 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:23 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104722_0009_m_000000_0' to file:/home4/yannick4/tmp/train10k.parquet/_temporary/0/task_20170318104722_0009_m_000000
17/03/18 10:47:23 INFO SparkHadoopMapRedUtil: attempt_20170318104722_0009_m_000000_0: Committed
17/03/18 10:47:23 INFO Executor: Finished task 0.0 in stage 9.0 (TID 11). 1786 bytes result sent to driver
17/03/18 10:47:23 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 11) in 647 ms on localhost (executor driver) (1/1)
17/03/18 10:47:23 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/18 10:47:23 INFO DAGScheduler: ResultStage 9 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,648 s
17/03/18 10:47:23 INFO DAGScheduler: Job 9 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,663167 s
17/03/18 10:47:23 INFO FileFormatWriter: Job null committed.
17/03/18 10:47:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:47:23 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:47:23 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:47:23 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:47:23 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:47:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:47:23 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:47:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:47:50 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:47:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:47:50 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:47:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:47:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:47:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:47:50 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:47:50 INFO DAGScheduler: Got job 10 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:47:50 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:59)
17/03/18 10:47:50 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:50 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:50 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[44] at map at utils.scala:56), which has no missing parents
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:55581 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[44] at map at utils.scala:56)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/03/18 10:47:50 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6357 bytes)
17/03/18 10:47:50 INFO Executor: Running task 0.0 in stage 10.0 (TID 12)
17/03/18 10:47:50 INFO Executor: Finished task 0.0 in stage 10.0 (TID 12). 1242 bytes result sent to driver
17/03/18 10:47:50 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 12) in 9 ms on localhost (executor driver) (1/1)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/18 10:47:50 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:59) finished in 0,009 s
17/03/18 10:47:50 INFO DAGScheduler: Job 10 finished: collect at utils.scala:59, took 0,015024 s
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:55581 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO SparkContext: Created broadcast 16 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:50 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:47:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:50 INFO DAGScheduler: Got job 11 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:47:50 INFO DAGScheduler: Final stage: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:50 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:50 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:50 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[47] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:55581 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[47] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/03/18 10:47:50 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6040 bytes)
17/03/18 10:47:50 INFO Executor: Running task 0.0 in stage 11.0 (TID 13)
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:0+33554432
17/03/18 10:47:50 INFO Executor: Finished task 0.0 in stage 11.0 (TID 13). 1274 bytes result sent to driver
17/03/18 10:47:50 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 13) in 8 ms on localhost (executor driver) (1/1)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/03/18 10:47:50 INFO DAGScheduler: ResultStage 11 (csv at NativeMethodAccessorImpl.java:0) finished in 0,008 s
17/03/18 10:47:50 INFO DAGScheduler: Job 11 finished: csv at NativeMethodAccessorImpl.java:0, took 0,012487 s
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 237.3 KB, free 6.2 GB)
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:55581 (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO SparkContext: Created broadcast 18 from csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:50 INFO FileInputFormat: Total input paths to process : 1
17/03/18 10:47:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:50 INFO DAGScheduler: Got job 12 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:47:50 INFO DAGScheduler: Final stage: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:50 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:50 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:50 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.5 KB, free 6.2 GB)
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.0 KB, free 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:55581 (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[50] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/03/18 10:47:50 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6040 bytes)
17/03/18 10:47:50 INFO Executor: Running task 0.0 in stage 12.0 (TID 14)
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:0+33554432
17/03/18 10:47:50 INFO Executor: Finished task 0.0 in stage 12.0 (TID 14). 1274 bytes result sent to driver
17/03/18 10:47:50 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 14) in 6 ms on localhost (executor driver) (1/1)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/03/18 10:47:50 INFO DAGScheduler: ResultStage 12 (csv at NativeMethodAccessorImpl.java:0) finished in 0,007 s
17/03/18 10:47:50 INFO DAGScheduler: Job 12 finished: csv at NativeMethodAccessorImpl.java:0, took 0,012138 s
17/03/18 10:47:50 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
17/03/18 10:47:50 INFO DAGScheduler: Got job 13 (csv at NativeMethodAccessorImpl.java:0) with 188 output partitions
17/03/18 10:47:50 INFO DAGScheduler: Final stage: ResultStage 13 (csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:50 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:47:50 INFO DAGScheduler: Missing parents: List()
17/03/18 10:47:50 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[51] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 7.7 KB, free 6.2 GB)
17/03/18 10:47:50 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 5.0 KB, free 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:55581 (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/03/18 10:47:50 INFO DAGScheduler: Submitting 188 missing tasks from ResultStage 13 (MapPartitionsRDD[51] at csv at NativeMethodAccessorImpl.java:0)
17/03/18 10:47:50 INFO TaskSchedulerImpl: Adding task set 13.0 with 188 tasks
17/03/18 10:47:50 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 17, localhost, executor driver, partition 2, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 18, localhost, executor driver, partition 3, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 19, localhost, executor driver, partition 4, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 20, localhost, executor driver, partition 5, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 21, localhost, executor driver, partition 6, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 22, localhost, executor driver, partition 7, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:50 INFO Executor: Running task 1.0 in stage 13.0 (TID 16)
17/03/18 10:47:50 INFO Executor: Running task 0.0 in stage 13.0 (TID 15)
17/03/18 10:47:50 INFO Executor: Running task 2.0 in stage 13.0 (TID 17)
17/03/18 10:47:50 INFO Executor: Running task 3.0 in stage 13.0 (TID 18)
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:67108864+33554432
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:33554432+33554432
17/03/18 10:47:50 INFO Executor: Running task 4.0 in stage 13.0 (TID 19)
17/03/18 10:47:50 INFO Executor: Running task 5.0 in stage 13.0 (TID 20)
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:134217728+33554432
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:0+33554432
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:100663296+33554432
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:167772160+33554432
17/03/18 10:47:50 INFO Executor: Running task 7.0 in stage 13.0 (TID 22)
17/03/18 10:47:50 INFO Executor: Running task 6.0 in stage 13.0 (TID 21)
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:201326592+33554432
17/03/18 10:47:50 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:234881024+33554432
17/03/18 10:47:50 INFO ContextCleaner: Cleaned accumulator 539
17/03/18 10:47:50 INFO ContextCleaner: Cleaned accumulator 540
17/03/18 10:47:50 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:55581 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:55581 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:50 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:55581 in memory (size: 2.0 KB, free: 6.2 GB)
17/03/18 10:47:51 INFO Executor: Finished task 5.0 in stage 13.0 (TID 20). 1897 bytes result sent to driver
17/03/18 10:47:51 INFO TaskSetManager: Starting task 8.0 in stage 13.0 (TID 23, localhost, executor driver, partition 8, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:51 INFO Executor: Running task 8.0 in stage 13.0 (TID 23)
17/03/18 10:47:51 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 20) in 1437 ms on localhost (executor driver) (1/188)
17/03/18 10:47:51 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:268435456+33554432
17/03/18 10:47:51 INFO Executor: Finished task 0.0 in stage 13.0 (TID 15). 1810 bytes result sent to driver
17/03/18 10:47:51 INFO TaskSetManager: Starting task 9.0 in stage 13.0 (TID 24, localhost, executor driver, partition 9, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:51 INFO Executor: Running task 9.0 in stage 13.0 (TID 24)
17/03/18 10:47:51 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 15) in 1550 ms on localhost (executor driver) (2/188)
17/03/18 10:47:51 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:301989888+33554432
17/03/18 10:47:51 INFO Executor: Finished task 6.0 in stage 13.0 (TID 21). 1897 bytes result sent to driver
17/03/18 10:47:51 INFO TaskSetManager: Starting task 10.0 in stage 13.0 (TID 25, localhost, executor driver, partition 10, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:51 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 21) in 1653 ms on localhost (executor driver) (3/188)
17/03/18 10:47:51 INFO Executor: Running task 10.0 in stage 13.0 (TID 25)
17/03/18 10:47:51 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:335544320+33554432
17/03/18 10:47:51 INFO Executor: Finished task 7.0 in stage 13.0 (TID 22). 1810 bytes result sent to driver
17/03/18 10:47:51 INFO TaskSetManager: Starting task 11.0 in stage 13.0 (TID 26, localhost, executor driver, partition 11, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:51 INFO Executor: Running task 11.0 in stage 13.0 (TID 26)
17/03/18 10:47:51 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 22) in 1704 ms on localhost (executor driver) (4/188)
17/03/18 10:47:51 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:369098752+33554432
17/03/18 10:47:51 INFO Executor: Finished task 2.0 in stage 13.0 (TID 17). 1897 bytes result sent to driver
17/03/18 10:47:51 INFO TaskSetManager: Starting task 12.0 in stage 13.0 (TID 27, localhost, executor driver, partition 12, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:51 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 17) in 1719 ms on localhost (executor driver) (5/188)
17/03/18 10:47:51 INFO Executor: Running task 12.0 in stage 13.0 (TID 27)
17/03/18 10:47:51 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:402653184+33554432
17/03/18 10:47:51 INFO Executor: Finished task 4.0 in stage 13.0 (TID 19). 1810 bytes result sent to driver
17/03/18 10:47:51 INFO TaskSetManager: Starting task 13.0 in stage 13.0 (TID 28, localhost, executor driver, partition 13, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:51 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 19) in 1768 ms on localhost (executor driver) (6/188)
17/03/18 10:47:51 INFO Executor: Running task 13.0 in stage 13.0 (TID 28)
17/03/18 10:47:51 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:436207616+33554432
17/03/18 10:47:52 INFO Executor: Finished task 1.0 in stage 13.0 (TID 16). 1897 bytes result sent to driver
17/03/18 10:47:52 INFO TaskSetManager: Starting task 14.0 in stage 13.0 (TID 29, localhost, executor driver, partition 14, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:52 INFO Executor: Running task 14.0 in stage 13.0 (TID 29)
17/03/18 10:47:52 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 16) in 1841 ms on localhost (executor driver) (7/188)
17/03/18 10:47:52 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:469762048+33554432
17/03/18 10:47:52 INFO Executor: Finished task 3.0 in stage 13.0 (TID 18). 1810 bytes result sent to driver
17/03/18 10:47:52 INFO TaskSetManager: Starting task 15.0 in stage 13.0 (TID 30, localhost, executor driver, partition 15, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:52 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 18) in 1854 ms on localhost (executor driver) (8/188)
17/03/18 10:47:52 INFO Executor: Running task 15.0 in stage 13.0 (TID 30)
17/03/18 10:47:52 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:503316480+33554432
17/03/18 10:47:53 INFO Executor: Finished task 8.0 in stage 13.0 (TID 23). 1810 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 16.0 in stage 13.0 (TID 31, localhost, executor driver, partition 16, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO Executor: Running task 16.0 in stage 13.0 (TID 31)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 8.0 in stage 13.0 (TID 23) in 1539 ms on localhost (executor driver) (9/188)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:536870912+33554432
17/03/18 10:47:53 INFO Executor: Finished task 9.0 in stage 13.0 (TID 24). 1810 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 17.0 in stage 13.0 (TID 32, localhost, executor driver, partition 17, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 9.0 in stage 13.0 (TID 24) in 1490 ms on localhost (executor driver) (10/188)
17/03/18 10:47:53 INFO Executor: Running task 17.0 in stage 13.0 (TID 32)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:570425344+33554432
17/03/18 10:47:53 INFO Executor: Finished task 12.0 in stage 13.0 (TID 27). 1897 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 18.0 in stage 13.0 (TID 33, localhost, executor driver, partition 18, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 12.0 in stage 13.0 (TID 27) in 1422 ms on localhost (executor driver) (11/188)
17/03/18 10:47:53 INFO Executor: Running task 18.0 in stage 13.0 (TID 33)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:603979776+33554432
17/03/18 10:47:53 INFO Executor: Finished task 10.0 in stage 13.0 (TID 25). 1810 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 19.0 in stage 13.0 (TID 34, localhost, executor driver, partition 19, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 10.0 in stage 13.0 (TID 25) in 1530 ms on localhost (executor driver) (12/188)
17/03/18 10:47:53 INFO Executor: Running task 19.0 in stage 13.0 (TID 34)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:637534208+33554432
17/03/18 10:47:53 INFO Executor: Finished task 13.0 in stage 13.0 (TID 28). 1810 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 20.0 in stage 13.0 (TID 35, localhost, executor driver, partition 20, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 13.0 in stage 13.0 (TID 28) in 1432 ms on localhost (executor driver) (13/188)
17/03/18 10:47:53 INFO Executor: Running task 20.0 in stage 13.0 (TID 35)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:671088640+33554432
17/03/18 10:47:53 INFO Executor: Finished task 11.0 in stage 13.0 (TID 26). 1897 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 21.0 in stage 13.0 (TID 36, localhost, executor driver, partition 21, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 11.0 in stage 13.0 (TID 26) in 1540 ms on localhost (executor driver) (14/188)
17/03/18 10:47:53 INFO Executor: Running task 21.0 in stage 13.0 (TID 36)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:704643072+33554432
17/03/18 10:47:53 INFO Executor: Finished task 14.0 in stage 13.0 (TID 29). 1810 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 22.0 in stage 13.0 (TID 37, localhost, executor driver, partition 22, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 14.0 in stage 13.0 (TID 29) in 1467 ms on localhost (executor driver) (15/188)
17/03/18 10:47:53 INFO Executor: Running task 22.0 in stage 13.0 (TID 37)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:738197504+33554432
17/03/18 10:47:53 INFO Executor: Finished task 15.0 in stage 13.0 (TID 30). 1810 bytes result sent to driver
17/03/18 10:47:53 INFO TaskSetManager: Starting task 23.0 in stage 13.0 (TID 38, localhost, executor driver, partition 23, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:53 INFO Executor: Running task 23.0 in stage 13.0 (TID 38)
17/03/18 10:47:53 INFO TaskSetManager: Finished task 15.0 in stage 13.0 (TID 30) in 1526 ms on localhost (executor driver) (16/188)
17/03/18 10:47:53 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:771751936+33554432
17/03/18 10:47:54 INFO Executor: Finished task 16.0 in stage 13.0 (TID 31). 1897 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 24.0 in stage 13.0 (TID 39, localhost, executor driver, partition 24, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO Executor: Running task 24.0 in stage 13.0 (TID 39)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 16.0 in stage 13.0 (TID 31) in 1419 ms on localhost (executor driver) (17/188)
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:805306368+33554432
17/03/18 10:47:54 INFO Executor: Finished task 17.0 in stage 13.0 (TID 32). 1810 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 25.0 in stage 13.0 (TID 40, localhost, executor driver, partition 25, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO Executor: Running task 25.0 in stage 13.0 (TID 40)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 17.0 in stage 13.0 (TID 32) in 1376 ms on localhost (executor driver) (18/188)
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:838860800+33554432
17/03/18 10:47:54 INFO Executor: Finished task 18.0 in stage 13.0 (TID 33). 1810 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 26.0 in stage 13.0 (TID 41, localhost, executor driver, partition 26, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO Executor: Running task 26.0 in stage 13.0 (TID 41)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 18.0 in stage 13.0 (TID 33) in 1347 ms on localhost (executor driver) (19/188)
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:872415232+33554432
17/03/18 10:47:54 INFO Executor: Finished task 20.0 in stage 13.0 (TID 35). 1897 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 27.0 in stage 13.0 (TID 42, localhost, executor driver, partition 27, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 20.0 in stage 13.0 (TID 35) in 1326 ms on localhost (executor driver) (20/188)
17/03/18 10:47:54 INFO Executor: Running task 27.0 in stage 13.0 (TID 42)
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:905969664+33554432
17/03/18 10:47:54 INFO Executor: Finished task 21.0 in stage 13.0 (TID 36). 1810 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 28.0 in stage 13.0 (TID 43, localhost, executor driver, partition 28, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 21.0 in stage 13.0 (TID 36) in 1442 ms on localhost (executor driver) (21/188)
17/03/18 10:47:54 INFO Executor: Running task 28.0 in stage 13.0 (TID 43)
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:939524096+33554432
17/03/18 10:47:54 INFO Executor: Finished task 23.0 in stage 13.0 (TID 38). 1810 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 29.0 in stage 13.0 (TID 44, localhost, executor driver, partition 29, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 23.0 in stage 13.0 (TID 38) in 1416 ms on localhost (executor driver) (22/188)
17/03/18 10:47:54 INFO Executor: Running task 29.0 in stage 13.0 (TID 44)
17/03/18 10:47:54 INFO Executor: Finished task 22.0 in stage 13.0 (TID 37). 1810 bytes result sent to driver
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:973078528+33554432
17/03/18 10:47:54 INFO TaskSetManager: Starting task 30.0 in stage 13.0 (TID 45, localhost, executor driver, partition 30, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO Executor: Running task 30.0 in stage 13.0 (TID 45)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 22.0 in stage 13.0 (TID 37) in 1492 ms on localhost (executor driver) (23/188)
17/03/18 10:47:54 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1006632960+33554432
17/03/18 10:47:54 INFO Executor: Finished task 19.0 in stage 13.0 (TID 34). 1810 bytes result sent to driver
17/03/18 10:47:54 INFO TaskSetManager: Starting task 31.0 in stage 13.0 (TID 46, localhost, executor driver, partition 31, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:54 INFO Executor: Running task 31.0 in stage 13.0 (TID 46)
17/03/18 10:47:54 INFO TaskSetManager: Finished task 19.0 in stage 13.0 (TID 34) in 1641 ms on localhost (executor driver) (24/188)
17/03/18 10:47:55 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1040187392+33554432
17/03/18 10:47:56 INFO Executor: Finished task 24.0 in stage 13.0 (TID 39). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 32.0 in stage 13.0 (TID 47, localhost, executor driver, partition 32, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO Executor: Running task 32.0 in stage 13.0 (TID 47)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 24.0 in stage 13.0 (TID 39) in 1461 ms on localhost (executor driver) (25/188)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1073741824+33554432
17/03/18 10:47:56 INFO Executor: Finished task 27.0 in stage 13.0 (TID 42). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 33.0 in stage 13.0 (TID 48, localhost, executor driver, partition 33, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO Executor: Running task 33.0 in stage 13.0 (TID 48)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 27.0 in stage 13.0 (TID 42) in 1338 ms on localhost (executor driver) (26/188)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1107296256+33554432
17/03/18 10:47:56 INFO Executor: Finished task 26.0 in stage 13.0 (TID 41). 1897 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 34.0 in stage 13.0 (TID 49, localhost, executor driver, partition 34, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 26.0 in stage 13.0 (TID 41) in 1408 ms on localhost (executor driver) (27/188)
17/03/18 10:47:56 INFO Executor: Running task 34.0 in stage 13.0 (TID 49)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1140850688+33554432
17/03/18 10:47:56 INFO Executor: Finished task 25.0 in stage 13.0 (TID 40). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 35.0 in stage 13.0 (TID 50, localhost, executor driver, partition 35, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 25.0 in stage 13.0 (TID 40) in 1538 ms on localhost (executor driver) (28/188)
17/03/18 10:47:56 INFO Executor: Running task 35.0 in stage 13.0 (TID 50)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1174405120+33554432
17/03/18 10:47:56 INFO Executor: Finished task 28.0 in stage 13.0 (TID 43). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 36.0 in stage 13.0 (TID 51, localhost, executor driver, partition 36, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 28.0 in stage 13.0 (TID 43) in 1319 ms on localhost (executor driver) (29/188)
17/03/18 10:47:56 INFO Executor: Running task 36.0 in stage 13.0 (TID 51)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1207959552+33554432
17/03/18 10:47:56 INFO Executor: Finished task 31.0 in stage 13.0 (TID 46). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 37.0 in stage 13.0 (TID 52, localhost, executor driver, partition 37, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 31.0 in stage 13.0 (TID 46) in 1324 ms on localhost (executor driver) (30/188)
17/03/18 10:47:56 INFO Executor: Running task 37.0 in stage 13.0 (TID 52)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1241513984+33554432
17/03/18 10:47:56 INFO Executor: Finished task 30.0 in stage 13.0 (TID 45). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 38.0 in stage 13.0 (TID 53, localhost, executor driver, partition 38, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO Executor: Running task 38.0 in stage 13.0 (TID 53)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 30.0 in stage 13.0 (TID 45) in 1396 ms on localhost (executor driver) (31/188)
17/03/18 10:47:56 INFO Executor: Finished task 29.0 in stage 13.0 (TID 44). 1810 bytes result sent to driver
17/03/18 10:47:56 INFO TaskSetManager: Starting task 39.0 in stage 13.0 (TID 54, localhost, executor driver, partition 39, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1275068416+33554432
17/03/18 10:47:56 INFO Executor: Running task 39.0 in stage 13.0 (TID 54)
17/03/18 10:47:56 INFO TaskSetManager: Finished task 29.0 in stage 13.0 (TID 44) in 1413 ms on localhost (executor driver) (32/188)
17/03/18 10:47:56 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1308622848+33554432
17/03/18 10:47:57 INFO Executor: Finished task 32.0 in stage 13.0 (TID 47). 1897 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 40.0 in stage 13.0 (TID 55, localhost, executor driver, partition 40, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO Executor: Running task 40.0 in stage 13.0 (TID 55)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 32.0 in stage 13.0 (TID 47) in 1332 ms on localhost (executor driver) (33/188)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1342177280+33554432
17/03/18 10:47:57 INFO Executor: Finished task 34.0 in stage 13.0 (TID 49). 1810 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 41.0 in stage 13.0 (TID 56, localhost, executor driver, partition 41, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO Executor: Running task 41.0 in stage 13.0 (TID 56)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 34.0 in stage 13.0 (TID 49) in 1377 ms on localhost (executor driver) (34/188)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1375731712+33554432
17/03/18 10:47:57 INFO Executor: Finished task 33.0 in stage 13.0 (TID 48). 1810 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 42.0 in stage 13.0 (TID 57, localhost, executor driver, partition 42, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 33.0 in stage 13.0 (TID 48) in 1428 ms on localhost (executor driver) (35/188)
17/03/18 10:47:57 INFO Executor: Running task 42.0 in stage 13.0 (TID 57)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1409286144+33554432
17/03/18 10:47:57 INFO Executor: Finished task 35.0 in stage 13.0 (TID 50). 1810 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 43.0 in stage 13.0 (TID 58, localhost, executor driver, partition 43, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 35.0 in stage 13.0 (TID 50) in 1377 ms on localhost (executor driver) (36/188)
17/03/18 10:47:57 INFO Executor: Running task 43.0 in stage 13.0 (TID 58)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1442840576+33554432
17/03/18 10:47:57 INFO Executor: Finished task 36.0 in stage 13.0 (TID 51). 1897 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 44.0 in stage 13.0 (TID 59, localhost, executor driver, partition 44, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO Executor: Running task 44.0 in stage 13.0 (TID 59)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 36.0 in stage 13.0 (TID 51) in 1379 ms on localhost (executor driver) (37/188)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1476395008+33554432
17/03/18 10:47:57 INFO Executor: Finished task 39.0 in stage 13.0 (TID 54). 1810 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 45.0 in stage 13.0 (TID 60, localhost, executor driver, partition 45, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO Executor: Running task 45.0 in stage 13.0 (TID 60)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 39.0 in stage 13.0 (TID 54) in 1358 ms on localhost (executor driver) (38/188)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1509949440+33554432
17/03/18 10:47:57 INFO Executor: Finished task 37.0 in stage 13.0 (TID 52). 1810 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 46.0 in stage 13.0 (TID 61, localhost, executor driver, partition 46, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO Executor: Running task 46.0 in stage 13.0 (TID 61)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 37.0 in stage 13.0 (TID 52) in 1446 ms on localhost (executor driver) (39/188)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1543503872+33554432
17/03/18 10:47:57 INFO Executor: Finished task 38.0 in stage 13.0 (TID 53). 1810 bytes result sent to driver
17/03/18 10:47:57 INFO TaskSetManager: Starting task 47.0 in stage 13.0 (TID 62, localhost, executor driver, partition 47, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:57 INFO TaskSetManager: Finished task 38.0 in stage 13.0 (TID 53) in 1461 ms on localhost (executor driver) (40/188)
17/03/18 10:47:57 INFO Executor: Running task 47.0 in stage 13.0 (TID 62)
17/03/18 10:47:57 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1577058304+33554432
17/03/18 10:47:58 INFO Executor: Finished task 40.0 in stage 13.0 (TID 55). 1810 bytes result sent to driver
17/03/18 10:47:58 INFO TaskSetManager: Starting task 48.0 in stage 13.0 (TID 63, localhost, executor driver, partition 48, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:58 INFO TaskSetManager: Finished task 40.0 in stage 13.0 (TID 55) in 1347 ms on localhost (executor driver) (41/188)
17/03/18 10:47:58 INFO Executor: Running task 48.0 in stage 13.0 (TID 63)
17/03/18 10:47:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1610612736+33554432
17/03/18 10:47:58 INFO Executor: Finished task 42.0 in stage 13.0 (TID 57). 1810 bytes result sent to driver
17/03/18 10:47:58 INFO Executor: Finished task 43.0 in stage 13.0 (TID 58). 1810 bytes result sent to driver
17/03/18 10:47:58 INFO TaskSetManager: Starting task 49.0 in stage 13.0 (TID 64, localhost, executor driver, partition 49, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:58 INFO Executor: Running task 49.0 in stage 13.0 (TID 64)
17/03/18 10:47:58 INFO TaskSetManager: Starting task 50.0 in stage 13.0 (TID 65, localhost, executor driver, partition 50, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:58 INFO Executor: Running task 50.0 in stage 13.0 (TID 65)
17/03/18 10:47:58 INFO TaskSetManager: Finished task 43.0 in stage 13.0 (TID 58) in 1369 ms on localhost (executor driver) (42/188)
17/03/18 10:47:58 INFO TaskSetManager: Finished task 42.0 in stage 13.0 (TID 57) in 1405 ms on localhost (executor driver) (43/188)
17/03/18 10:47:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1677721600+33554432
17/03/18 10:47:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1644167168+33554432
17/03/18 10:47:58 INFO Executor: Finished task 41.0 in stage 13.0 (TID 56). 1897 bytes result sent to driver
17/03/18 10:47:58 INFO TaskSetManager: Starting task 51.0 in stage 13.0 (TID 66, localhost, executor driver, partition 51, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:58 INFO TaskSetManager: Finished task 41.0 in stage 13.0 (TID 56) in 1444 ms on localhost (executor driver) (44/188)
17/03/18 10:47:58 INFO Executor: Running task 51.0 in stage 13.0 (TID 66)
17/03/18 10:47:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1711276032+33554432
17/03/18 10:47:58 INFO Executor: Finished task 44.0 in stage 13.0 (TID 59). 1810 bytes result sent to driver
17/03/18 10:47:58 INFO TaskSetManager: Starting task 52.0 in stage 13.0 (TID 67, localhost, executor driver, partition 52, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:58 INFO TaskSetManager: Finished task 44.0 in stage 13.0 (TID 59) in 1382 ms on localhost (executor driver) (45/188)
17/03/18 10:47:58 INFO Executor: Running task 52.0 in stage 13.0 (TID 67)
17/03/18 10:47:58 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1744830464+33554432
17/03/18 10:47:59 INFO Executor: Finished task 45.0 in stage 13.0 (TID 60). 1810 bytes result sent to driver
17/03/18 10:47:59 INFO TaskSetManager: Starting task 53.0 in stage 13.0 (TID 68, localhost, executor driver, partition 53, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:59 INFO Executor: Running task 53.0 in stage 13.0 (TID 68)
17/03/18 10:47:59 INFO TaskSetManager: Finished task 45.0 in stage 13.0 (TID 60) in 1325 ms on localhost (executor driver) (46/188)
17/03/18 10:47:59 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1778384896+33554432
17/03/18 10:47:59 INFO Executor: Finished task 46.0 in stage 13.0 (TID 61). 1810 bytes result sent to driver
17/03/18 10:47:59 INFO TaskSetManager: Starting task 54.0 in stage 13.0 (TID 69, localhost, executor driver, partition 54, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:59 INFO TaskSetManager: Finished task 46.0 in stage 13.0 (TID 61) in 1365 ms on localhost (executor driver) (47/188)
17/03/18 10:47:59 INFO Executor: Running task 54.0 in stage 13.0 (TID 69)
17/03/18 10:47:59 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1811939328+33554432
17/03/18 10:47:59 INFO Executor: Finished task 47.0 in stage 13.0 (TID 62). 1897 bytes result sent to driver
17/03/18 10:47:59 INFO TaskSetManager: Starting task 55.0 in stage 13.0 (TID 70, localhost, executor driver, partition 55, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:47:59 INFO Executor: Running task 55.0 in stage 13.0 (TID 70)
17/03/18 10:47:59 INFO TaskSetManager: Finished task 47.0 in stage 13.0 (TID 62) in 1330 ms on localhost (executor driver) (48/188)
17/03/18 10:47:59 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1845493760+33554432
17/03/18 10:48:00 INFO Executor: Finished task 48.0 in stage 13.0 (TID 63). 1810 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 56.0 in stage 13.0 (TID 71, localhost, executor driver, partition 56, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 48.0 in stage 13.0 (TID 63) in 1354 ms on localhost (executor driver) (49/188)
17/03/18 10:48:00 INFO Executor: Running task 56.0 in stage 13.0 (TID 71)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1879048192+33554432
17/03/18 10:48:00 INFO Executor: Finished task 50.0 in stage 13.0 (TID 65). 1897 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 57.0 in stage 13.0 (TID 72, localhost, executor driver, partition 57, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO Executor: Running task 57.0 in stage 13.0 (TID 72)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 50.0 in stage 13.0 (TID 65) in 1343 ms on localhost (executor driver) (50/188)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1912602624+33554432
17/03/18 10:48:00 INFO Executor: Finished task 51.0 in stage 13.0 (TID 66). 1897 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 58.0 in stage 13.0 (TID 73, localhost, executor driver, partition 58, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO Executor: Running task 58.0 in stage 13.0 (TID 73)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 51.0 in stage 13.0 (TID 66) in 1350 ms on localhost (executor driver) (51/188)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1946157056+33554432
17/03/18 10:48:00 INFO Executor: Finished task 49.0 in stage 13.0 (TID 64). 1810 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 59.0 in stage 13.0 (TID 74, localhost, executor driver, partition 59, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO Executor: Running task 59.0 in stage 13.0 (TID 74)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 49.0 in stage 13.0 (TID 64) in 1384 ms on localhost (executor driver) (52/188)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:1979711488+33554432
17/03/18 10:48:00 INFO Executor: Finished task 52.0 in stage 13.0 (TID 67). 1810 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 60.0 in stage 13.0 (TID 75, localhost, executor driver, partition 60, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO Executor: Running task 60.0 in stage 13.0 (TID 75)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 52.0 in stage 13.0 (TID 67) in 1407 ms on localhost (executor driver) (53/188)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2013265920+33554432
17/03/18 10:48:00 INFO Executor: Finished task 53.0 in stage 13.0 (TID 68). 1897 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 61.0 in stage 13.0 (TID 76, localhost, executor driver, partition 61, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 53.0 in stage 13.0 (TID 68) in 1347 ms on localhost (executor driver) (54/188)
17/03/18 10:48:00 INFO Executor: Running task 61.0 in stage 13.0 (TID 76)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2046820352+33554432
17/03/18 10:48:00 INFO Executor: Finished task 54.0 in stage 13.0 (TID 69). 1810 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 62.0 in stage 13.0 (TID 77, localhost, executor driver, partition 62, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 54.0 in stage 13.0 (TID 69) in 1305 ms on localhost (executor driver) (55/188)
17/03/18 10:48:00 INFO Executor: Running task 62.0 in stage 13.0 (TID 77)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2080374784+33554432
17/03/18 10:48:00 INFO Executor: Finished task 55.0 in stage 13.0 (TID 70). 1810 bytes result sent to driver
17/03/18 10:48:00 INFO TaskSetManager: Starting task 63.0 in stage 13.0 (TID 78, localhost, executor driver, partition 63, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:00 INFO TaskSetManager: Finished task 55.0 in stage 13.0 (TID 70) in 1319 ms on localhost (executor driver) (56/188)
17/03/18 10:48:00 INFO Executor: Running task 63.0 in stage 13.0 (TID 78)
17/03/18 10:48:00 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2113929216+33554432
17/03/18 10:48:01 INFO Executor: Finished task 57.0 in stage 13.0 (TID 72). 1810 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 64.0 in stage 13.0 (TID 79, localhost, executor driver, partition 64, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 64.0 in stage 13.0 (TID 79)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 57.0 in stage 13.0 (TID 72) in 1308 ms on localhost (executor driver) (57/188)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2147483648+33554432
17/03/18 10:48:01 INFO Executor: Finished task 56.0 in stage 13.0 (TID 71). 1810 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 65.0 in stage 13.0 (TID 80, localhost, executor driver, partition 65, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 65.0 in stage 13.0 (TID 80)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 56.0 in stage 13.0 (TID 71) in 1485 ms on localhost (executor driver) (58/188)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2181038080+33554432
17/03/18 10:48:01 INFO Executor: Finished task 58.0 in stage 13.0 (TID 73). 1897 bytes result sent to driver
17/03/18 10:48:01 INFO Executor: Finished task 59.0 in stage 13.0 (TID 74). 1897 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 66.0 in stage 13.0 (TID 81, localhost, executor driver, partition 66, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 66.0 in stage 13.0 (TID 81)
17/03/18 10:48:01 INFO TaskSetManager: Starting task 67.0 in stage 13.0 (TID 82, localhost, executor driver, partition 67, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 67.0 in stage 13.0 (TID 82)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 58.0 in stage 13.0 (TID 73) in 1323 ms on localhost (executor driver) (59/188)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 59.0 in stage 13.0 (TID 74) in 1308 ms on localhost (executor driver) (60/188)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2214592512+33554432
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2248146944+33554432
17/03/18 10:48:01 INFO Executor: Finished task 60.0 in stage 13.0 (TID 75). 1810 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 68.0 in stage 13.0 (TID 83, localhost, executor driver, partition 68, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 68.0 in stage 13.0 (TID 83)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 60.0 in stage 13.0 (TID 75) in 1373 ms on localhost (executor driver) (61/188)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2281701376+33554432
17/03/18 10:48:01 INFO Executor: Finished task 62.0 in stage 13.0 (TID 77). 1810 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 69.0 in stage 13.0 (TID 84, localhost, executor driver, partition 69, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 69.0 in stage 13.0 (TID 84)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 62.0 in stage 13.0 (TID 77) in 1344 ms on localhost (executor driver) (62/188)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2315255808+33554432
17/03/18 10:48:01 INFO Executor: Finished task 61.0 in stage 13.0 (TID 76). 1810 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 70.0 in stage 13.0 (TID 85, localhost, executor driver, partition 70, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 61.0 in stage 13.0 (TID 76) in 1388 ms on localhost (executor driver) (63/188)
17/03/18 10:48:01 INFO Executor: Running task 70.0 in stage 13.0 (TID 85)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2348810240+33554432
17/03/18 10:48:01 INFO Executor: Finished task 63.0 in stage 13.0 (TID 78). 1810 bytes result sent to driver
17/03/18 10:48:01 INFO TaskSetManager: Starting task 71.0 in stage 13.0 (TID 86, localhost, executor driver, partition 71, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:01 INFO Executor: Running task 71.0 in stage 13.0 (TID 86)
17/03/18 10:48:01 INFO TaskSetManager: Finished task 63.0 in stage 13.0 (TID 78) in 1340 ms on localhost (executor driver) (64/188)
17/03/18 10:48:01 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2382364672+33554432
17/03/18 10:48:02 INFO Executor: Finished task 64.0 in stage 13.0 (TID 79). 1810 bytes result sent to driver
17/03/18 10:48:02 INFO TaskSetManager: Starting task 72.0 in stage 13.0 (TID 87, localhost, executor driver, partition 72, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:02 INFO Executor: Running task 72.0 in stage 13.0 (TID 87)
17/03/18 10:48:02 INFO TaskSetManager: Finished task 64.0 in stage 13.0 (TID 79) in 1313 ms on localhost (executor driver) (65/188)
17/03/18 10:48:02 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2415919104+33554432
17/03/18 10:48:02 INFO Executor: Finished task 66.0 in stage 13.0 (TID 81). 1810 bytes result sent to driver
17/03/18 10:48:02 INFO TaskSetManager: Starting task 73.0 in stage 13.0 (TID 88, localhost, executor driver, partition 73, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:02 INFO Executor: Running task 73.0 in stage 13.0 (TID 88)
17/03/18 10:48:02 INFO TaskSetManager: Finished task 66.0 in stage 13.0 (TID 81) in 1311 ms on localhost (executor driver) (66/188)
17/03/18 10:48:02 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2449473536+33554432
17/03/18 10:48:02 INFO Executor: Finished task 67.0 in stage 13.0 (TID 82). 1810 bytes result sent to driver
17/03/18 10:48:02 INFO Executor: Finished task 65.0 in stage 13.0 (TID 80). 1810 bytes result sent to driver
17/03/18 10:48:02 INFO TaskSetManager: Starting task 74.0 in stage 13.0 (TID 89, localhost, executor driver, partition 74, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:02 INFO TaskSetManager: Finished task 67.0 in stage 13.0 (TID 82) in 1340 ms on localhost (executor driver) (67/188)
17/03/18 10:48:02 INFO TaskSetManager: Starting task 75.0 in stage 13.0 (TID 90, localhost, executor driver, partition 75, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:02 INFO TaskSetManager: Finished task 65.0 in stage 13.0 (TID 80) in 1365 ms on localhost (executor driver) (68/188)
17/03/18 10:48:02 INFO Executor: Running task 74.0 in stage 13.0 (TID 89)
17/03/18 10:48:02 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2483027968+33554432
17/03/18 10:48:02 INFO Executor: Running task 75.0 in stage 13.0 (TID 90)
17/03/18 10:48:02 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2516582400+33554432
17/03/18 10:48:03 INFO Executor: Finished task 68.0 in stage 13.0 (TID 83). 1810 bytes result sent to driver
17/03/18 10:48:03 INFO TaskSetManager: Starting task 76.0 in stage 13.0 (TID 91, localhost, executor driver, partition 76, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:03 INFO Executor: Running task 76.0 in stage 13.0 (TID 91)
17/03/18 10:48:03 INFO TaskSetManager: Finished task 68.0 in stage 13.0 (TID 83) in 1384 ms on localhost (executor driver) (69/188)
17/03/18 10:48:03 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2550136832+33554432
17/03/18 10:48:03 INFO Executor: Finished task 69.0 in stage 13.0 (TID 84). 1897 bytes result sent to driver
17/03/18 10:48:03 INFO TaskSetManager: Starting task 77.0 in stage 13.0 (TID 92, localhost, executor driver, partition 77, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:03 INFO TaskSetManager: Finished task 69.0 in stage 13.0 (TID 84) in 1330 ms on localhost (executor driver) (70/188)
17/03/18 10:48:03 INFO Executor: Running task 77.0 in stage 13.0 (TID 92)
17/03/18 10:48:03 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2583691264+33554432
17/03/18 10:48:03 INFO Executor: Finished task 70.0 in stage 13.0 (TID 85). 1810 bytes result sent to driver
17/03/18 10:48:03 INFO TaskSetManager: Starting task 78.0 in stage 13.0 (TID 93, localhost, executor driver, partition 78, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:03 INFO TaskSetManager: Finished task 70.0 in stage 13.0 (TID 85) in 1360 ms on localhost (executor driver) (71/188)
17/03/18 10:48:03 INFO Executor: Running task 78.0 in stage 13.0 (TID 93)
17/03/18 10:48:03 INFO Executor: Finished task 71.0 in stage 13.0 (TID 86). 1810 bytes result sent to driver
17/03/18 10:48:03 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2617245696+33554432
17/03/18 10:48:03 INFO TaskSetManager: Starting task 79.0 in stage 13.0 (TID 94, localhost, executor driver, partition 79, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:03 INFO Executor: Running task 79.0 in stage 13.0 (TID 94)
17/03/18 10:48:03 INFO TaskSetManager: Finished task 71.0 in stage 13.0 (TID 86) in 1371 ms on localhost (executor driver) (72/188)
17/03/18 10:48:03 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2650800128+33554432
17/03/18 10:48:04 INFO Executor: Finished task 72.0 in stage 13.0 (TID 87). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 80.0 in stage 13.0 (TID 95, localhost, executor driver, partition 80, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO Executor: Running task 80.0 in stage 13.0 (TID 95)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 72.0 in stage 13.0 (TID 87) in 1387 ms on localhost (executor driver) (73/188)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2684354560+33554432
17/03/18 10:48:04 INFO Executor: Finished task 73.0 in stage 13.0 (TID 88). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 81.0 in stage 13.0 (TID 96, localhost, executor driver, partition 81, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO Executor: Running task 81.0 in stage 13.0 (TID 96)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 73.0 in stage 13.0 (TID 88) in 1375 ms on localhost (executor driver) (74/188)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2717908992+33554432
17/03/18 10:48:04 INFO Executor: Finished task 75.0 in stage 13.0 (TID 90). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 82.0 in stage 13.0 (TID 97, localhost, executor driver, partition 82, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 75.0 in stage 13.0 (TID 90) in 1348 ms on localhost (executor driver) (75/188)
17/03/18 10:48:04 INFO Executor: Running task 82.0 in stage 13.0 (TID 97)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2751463424+33554432
17/03/18 10:48:04 INFO Executor: Finished task 74.0 in stage 13.0 (TID 89). 1897 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 83.0 in stage 13.0 (TID 98, localhost, executor driver, partition 83, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 74.0 in stage 13.0 (TID 89) in 1421 ms on localhost (executor driver) (76/188)
17/03/18 10:48:04 INFO Executor: Running task 83.0 in stage 13.0 (TID 98)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2785017856+33554432
17/03/18 10:48:04 INFO Executor: Finished task 77.0 in stage 13.0 (TID 92). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 84.0 in stage 13.0 (TID 99, localhost, executor driver, partition 84, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 77.0 in stage 13.0 (TID 92) in 1315 ms on localhost (executor driver) (77/188)
17/03/18 10:48:04 INFO Executor: Running task 84.0 in stage 13.0 (TID 99)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2818572288+33554432
17/03/18 10:48:04 INFO Executor: Finished task 76.0 in stage 13.0 (TID 91). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 85.0 in stage 13.0 (TID 100, localhost, executor driver, partition 85, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO Executor: Running task 85.0 in stage 13.0 (TID 100)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 76.0 in stage 13.0 (TID 91) in 1375 ms on localhost (executor driver) (78/188)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2852126720+33554432
17/03/18 10:48:04 INFO Executor: Finished task 79.0 in stage 13.0 (TID 94). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 86.0 in stage 13.0 (TID 101, localhost, executor driver, partition 86, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 79.0 in stage 13.0 (TID 94) in 1300 ms on localhost (executor driver) (79/188)
17/03/18 10:48:04 INFO Executor: Running task 86.0 in stage 13.0 (TID 101)
17/03/18 10:48:04 INFO Executor: Finished task 78.0 in stage 13.0 (TID 93). 1810 bytes result sent to driver
17/03/18 10:48:04 INFO TaskSetManager: Starting task 87.0 in stage 13.0 (TID 102, localhost, executor driver, partition 87, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:04 INFO Executor: Running task 87.0 in stage 13.0 (TID 102)
17/03/18 10:48:04 INFO TaskSetManager: Finished task 78.0 in stage 13.0 (TID 93) in 1334 ms on localhost (executor driver) (80/188)
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2919235584+33554432
17/03/18 10:48:04 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2885681152+33554432
17/03/18 10:48:05 INFO Executor: Finished task 80.0 in stage 13.0 (TID 95). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 88.0 in stage 13.0 (TID 103, localhost, executor driver, partition 88, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 80.0 in stage 13.0 (TID 95) in 1304 ms on localhost (executor driver) (81/188)
17/03/18 10:48:05 INFO Executor: Running task 88.0 in stage 13.0 (TID 103)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2952790016+33554432
17/03/18 10:48:05 INFO Executor: Finished task 81.0 in stage 13.0 (TID 96). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 89.0 in stage 13.0 (TID 104, localhost, executor driver, partition 89, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO Executor: Running task 89.0 in stage 13.0 (TID 104)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 81.0 in stage 13.0 (TID 96) in 1333 ms on localhost (executor driver) (82/188)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:2986344448+33554432
17/03/18 10:48:05 INFO Executor: Finished task 82.0 in stage 13.0 (TID 97). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 90.0 in stage 13.0 (TID 105, localhost, executor driver, partition 90, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO Executor: Running task 90.0 in stage 13.0 (TID 105)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 82.0 in stage 13.0 (TID 97) in 1365 ms on localhost (executor driver) (83/188)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3019898880+33554432
17/03/18 10:48:05 INFO Executor: Finished task 83.0 in stage 13.0 (TID 98). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 91.0 in stage 13.0 (TID 106, localhost, executor driver, partition 91, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO Executor: Running task 91.0 in stage 13.0 (TID 106)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 83.0 in stage 13.0 (TID 98) in 1339 ms on localhost (executor driver) (84/188)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3053453312+33554432
17/03/18 10:48:05 INFO Executor: Finished task 84.0 in stage 13.0 (TID 99). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 92.0 in stage 13.0 (TID 107, localhost, executor driver, partition 92, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO Executor: Running task 92.0 in stage 13.0 (TID 107)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 84.0 in stage 13.0 (TID 99) in 1346 ms on localhost (executor driver) (85/188)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3087007744+33554432
17/03/18 10:48:05 INFO Executor: Finished task 86.0 in stage 13.0 (TID 101). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 93.0 in stage 13.0 (TID 108, localhost, executor driver, partition 93, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO Executor: Running task 93.0 in stage 13.0 (TID 108)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 86.0 in stage 13.0 (TID 101) in 1325 ms on localhost (executor driver) (86/188)
17/03/18 10:48:05 INFO Executor: Finished task 85.0 in stage 13.0 (TID 100). 1810 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 94.0 in stage 13.0 (TID 109, localhost, executor driver, partition 94, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 85.0 in stage 13.0 (TID 100) in 1335 ms on localhost (executor driver) (87/188)
17/03/18 10:48:05 INFO Executor: Running task 94.0 in stage 13.0 (TID 109)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3120562176+33554432
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3154116608+33554432
17/03/18 10:48:05 INFO Executor: Finished task 87.0 in stage 13.0 (TID 102). 1897 bytes result sent to driver
17/03/18 10:48:05 INFO TaskSetManager: Starting task 95.0 in stage 13.0 (TID 110, localhost, executor driver, partition 95, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:05 INFO Executor: Running task 95.0 in stage 13.0 (TID 110)
17/03/18 10:48:05 INFO TaskSetManager: Finished task 87.0 in stage 13.0 (TID 102) in 1455 ms on localhost (executor driver) (88/188)
17/03/18 10:48:05 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3187671040+33554432
17/03/18 10:48:06 INFO Executor: Finished task 88.0 in stage 13.0 (TID 103). 1810 bytes result sent to driver
17/03/18 10:48:06 INFO TaskSetManager: Starting task 96.0 in stage 13.0 (TID 111, localhost, executor driver, partition 96, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:06 INFO TaskSetManager: Finished task 88.0 in stage 13.0 (TID 103) in 1301 ms on localhost (executor driver) (89/188)
17/03/18 10:48:06 INFO Executor: Running task 96.0 in stage 13.0 (TID 111)
17/03/18 10:48:06 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3221225472+33554432
17/03/18 10:48:06 INFO Executor: Finished task 89.0 in stage 13.0 (TID 104). 1810 bytes result sent to driver
17/03/18 10:48:06 INFO TaskSetManager: Starting task 97.0 in stage 13.0 (TID 112, localhost, executor driver, partition 97, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:06 INFO TaskSetManager: Finished task 89.0 in stage 13.0 (TID 104) in 1327 ms on localhost (executor driver) (90/188)
17/03/18 10:48:06 INFO Executor: Running task 97.0 in stage 13.0 (TID 112)
17/03/18 10:48:06 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3254779904+33554432
17/03/18 10:48:07 INFO Executor: Finished task 91.0 in stage 13.0 (TID 106). 1897 bytes result sent to driver
17/03/18 10:48:07 INFO TaskSetManager: Starting task 98.0 in stage 13.0 (TID 113, localhost, executor driver, partition 98, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:07 INFO Executor: Running task 98.0 in stage 13.0 (TID 113)
17/03/18 10:48:07 INFO TaskSetManager: Finished task 91.0 in stage 13.0 (TID 106) in 1364 ms on localhost (executor driver) (91/188)
17/03/18 10:48:07 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3288334336+33554432
17/03/18 10:48:07 INFO Executor: Finished task 92.0 in stage 13.0 (TID 107). 1810 bytes result sent to driver
17/03/18 10:48:07 INFO TaskSetManager: Starting task 99.0 in stage 13.0 (TID 114, localhost, executor driver, partition 99, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:07 INFO TaskSetManager: Finished task 92.0 in stage 13.0 (TID 107) in 1313 ms on localhost (executor driver) (92/188)
17/03/18 10:48:07 INFO Executor: Running task 99.0 in stage 13.0 (TID 114)
17/03/18 10:48:07 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3321888768+33554432
17/03/18 10:48:07 INFO Executor: Finished task 90.0 in stage 13.0 (TID 105). 1810 bytes result sent to driver
17/03/18 10:48:07 INFO TaskSetManager: Starting task 100.0 in stage 13.0 (TID 115, localhost, executor driver, partition 100, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:07 INFO Executor: Running task 100.0 in stage 13.0 (TID 115)
17/03/18 10:48:07 INFO TaskSetManager: Finished task 90.0 in stage 13.0 (TID 105) in 1491 ms on localhost (executor driver) (93/188)
17/03/18 10:48:07 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3355443200+33554432
17/03/18 10:48:07 INFO Executor: Finished task 94.0 in stage 13.0 (TID 109). 1810 bytes result sent to driver
17/03/18 10:48:07 INFO TaskSetManager: Starting task 101.0 in stage 13.0 (TID 116, localhost, executor driver, partition 101, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:07 INFO Executor: Running task 101.0 in stage 13.0 (TID 116)
17/03/18 10:48:07 INFO TaskSetManager: Finished task 94.0 in stage 13.0 (TID 109) in 1365 ms on localhost (executor driver) (94/188)
17/03/18 10:48:07 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3388997632+33554432
17/03/18 10:48:07 INFO Executor: Finished task 95.0 in stage 13.0 (TID 110). 1810 bytes result sent to driver
17/03/18 10:48:07 INFO TaskSetManager: Starting task 102.0 in stage 13.0 (TID 117, localhost, executor driver, partition 102, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:07 INFO Executor: Running task 102.0 in stage 13.0 (TID 117)
17/03/18 10:48:07 INFO TaskSetManager: Finished task 95.0 in stage 13.0 (TID 110) in 1300 ms on localhost (executor driver) (95/188)
17/03/18 10:48:07 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3422552064+33554432
17/03/18 10:48:07 INFO Executor: Finished task 93.0 in stage 13.0 (TID 108). 1810 bytes result sent to driver
17/03/18 10:48:07 INFO TaskSetManager: Starting task 103.0 in stage 13.0 (TID 118, localhost, executor driver, partition 103, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:07 INFO Executor: Running task 103.0 in stage 13.0 (TID 118)
17/03/18 10:48:07 INFO TaskSetManager: Finished task 93.0 in stage 13.0 (TID 108) in 1447 ms on localhost (executor driver) (96/188)
17/03/18 10:48:07 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3456106496+33554432
17/03/18 10:48:08 INFO Executor: Finished task 96.0 in stage 13.0 (TID 111). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 104.0 in stage 13.0 (TID 119, localhost, executor driver, partition 104, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO Executor: Running task 104.0 in stage 13.0 (TID 119)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 96.0 in stage 13.0 (TID 111) in 1340 ms on localhost (executor driver) (97/188)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3489660928+33554432
17/03/18 10:48:08 INFO Executor: Finished task 97.0 in stage 13.0 (TID 112). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 105.0 in stage 13.0 (TID 120, localhost, executor driver, partition 105, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 97.0 in stage 13.0 (TID 112) in 1363 ms on localhost (executor driver) (98/188)
17/03/18 10:48:08 INFO Executor: Running task 105.0 in stage 13.0 (TID 120)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3523215360+33554432
17/03/18 10:48:08 INFO Executor: Finished task 98.0 in stage 13.0 (TID 113). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 106.0 in stage 13.0 (TID 121, localhost, executor driver, partition 106, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO Executor: Running task 106.0 in stage 13.0 (TID 121)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 98.0 in stage 13.0 (TID 113) in 1324 ms on localhost (executor driver) (99/188)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3556769792+33554432
17/03/18 10:48:08 INFO Executor: Finished task 99.0 in stage 13.0 (TID 114). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 107.0 in stage 13.0 (TID 122, localhost, executor driver, partition 107, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO Executor: Running task 107.0 in stage 13.0 (TID 122)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 99.0 in stage 13.0 (TID 114) in 1327 ms on localhost (executor driver) (100/188)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3590324224+33554432
17/03/18 10:48:08 INFO Executor: Finished task 100.0 in stage 13.0 (TID 115). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 108.0 in stage 13.0 (TID 123, localhost, executor driver, partition 108, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 100.0 in stage 13.0 (TID 115) in 1354 ms on localhost (executor driver) (101/188)
17/03/18 10:48:08 INFO Executor: Running task 108.0 in stage 13.0 (TID 123)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3623878656+33554432
17/03/18 10:48:08 INFO Executor: Finished task 101.0 in stage 13.0 (TID 116). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 109.0 in stage 13.0 (TID 124, localhost, executor driver, partition 109, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 101.0 in stage 13.0 (TID 116) in 1377 ms on localhost (executor driver) (102/188)
17/03/18 10:48:08 INFO Executor: Running task 109.0 in stage 13.0 (TID 124)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3657433088+33554432
17/03/18 10:48:08 INFO Executor: Finished task 103.0 in stage 13.0 (TID 118). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 110.0 in stage 13.0 (TID 125, localhost, executor driver, partition 110, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 103.0 in stage 13.0 (TID 118) in 1302 ms on localhost (executor driver) (103/188)
17/03/18 10:48:08 INFO Executor: Running task 110.0 in stage 13.0 (TID 125)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3690987520+33554432
17/03/18 10:48:08 INFO Executor: Finished task 102.0 in stage 13.0 (TID 117). 1810 bytes result sent to driver
17/03/18 10:48:08 INFO TaskSetManager: Starting task 111.0 in stage 13.0 (TID 126, localhost, executor driver, partition 111, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:08 INFO TaskSetManager: Finished task 102.0 in stage 13.0 (TID 117) in 1326 ms on localhost (executor driver) (104/188)
17/03/18 10:48:08 INFO Executor: Running task 111.0 in stage 13.0 (TID 126)
17/03/18 10:48:08 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3724541952+33554432
17/03/18 10:48:09 INFO Executor: Finished task 104.0 in stage 13.0 (TID 119). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 112.0 in stage 13.0 (TID 127, localhost, executor driver, partition 112, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 104.0 in stage 13.0 (TID 119) in 1318 ms on localhost (executor driver) (105/188)
17/03/18 10:48:09 INFO Executor: Running task 112.0 in stage 13.0 (TID 127)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3758096384+33554432
17/03/18 10:48:09 INFO Executor: Finished task 105.0 in stage 13.0 (TID 120). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 113.0 in stage 13.0 (TID 128, localhost, executor driver, partition 113, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 105.0 in stage 13.0 (TID 120) in 1328 ms on localhost (executor driver) (106/188)
17/03/18 10:48:09 INFO Executor: Running task 113.0 in stage 13.0 (TID 128)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3791650816+33554432
17/03/18 10:48:09 INFO Executor: Finished task 106.0 in stage 13.0 (TID 121). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 114.0 in stage 13.0 (TID 129, localhost, executor driver, partition 114, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 106.0 in stage 13.0 (TID 121) in 1319 ms on localhost (executor driver) (107/188)
17/03/18 10:48:09 INFO Executor: Running task 114.0 in stage 13.0 (TID 129)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3825205248+33554432
17/03/18 10:48:09 INFO Executor: Finished task 107.0 in stage 13.0 (TID 122). 1897 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 115.0 in stage 13.0 (TID 130, localhost, executor driver, partition 115, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO Executor: Running task 115.0 in stage 13.0 (TID 130)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 107.0 in stage 13.0 (TID 122) in 1292 ms on localhost (executor driver) (108/188)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3858759680+33554432
17/03/18 10:48:09 INFO Executor: Finished task 108.0 in stage 13.0 (TID 123). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 116.0 in stage 13.0 (TID 131, localhost, executor driver, partition 116, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO Executor: Running task 116.0 in stage 13.0 (TID 131)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 108.0 in stage 13.0 (TID 123) in 1348 ms on localhost (executor driver) (109/188)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3892314112+33554432
17/03/18 10:48:09 INFO Executor: Finished task 109.0 in stage 13.0 (TID 124). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 117.0 in stage 13.0 (TID 132, localhost, executor driver, partition 117, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 109.0 in stage 13.0 (TID 124) in 1377 ms on localhost (executor driver) (110/188)
17/03/18 10:48:09 INFO Executor: Running task 117.0 in stage 13.0 (TID 132)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3925868544+33554432
17/03/18 10:48:09 INFO Executor: Finished task 111.0 in stage 13.0 (TID 126). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 118.0 in stage 13.0 (TID 133, localhost, executor driver, partition 118, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO Executor: Running task 118.0 in stage 13.0 (TID 133)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 111.0 in stage 13.0 (TID 126) in 1382 ms on localhost (executor driver) (111/188)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3959422976+33554432
17/03/18 10:48:09 INFO Executor: Finished task 110.0 in stage 13.0 (TID 125). 1810 bytes result sent to driver
17/03/18 10:48:09 INFO TaskSetManager: Starting task 119.0 in stage 13.0 (TID 134, localhost, executor driver, partition 119, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:09 INFO TaskSetManager: Finished task 110.0 in stage 13.0 (TID 125) in 1402 ms on localhost (executor driver) (112/188)
17/03/18 10:48:09 INFO Executor: Running task 119.0 in stage 13.0 (TID 134)
17/03/18 10:48:09 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:3992977408+33554432
17/03/18 10:48:10 INFO Executor: Finished task 112.0 in stage 13.0 (TID 127). 1810 bytes result sent to driver
17/03/18 10:48:10 INFO TaskSetManager: Starting task 120.0 in stage 13.0 (TID 135, localhost, executor driver, partition 120, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:10 INFO Executor: Running task 120.0 in stage 13.0 (TID 135)
17/03/18 10:48:10 INFO TaskSetManager: Finished task 112.0 in stage 13.0 (TID 127) in 1432 ms on localhost (executor driver) (113/188)
17/03/18 10:48:10 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4026531840+33554432
17/03/18 10:48:10 INFO Executor: Finished task 114.0 in stage 13.0 (TID 129). 1810 bytes result sent to driver
17/03/18 10:48:10 INFO TaskSetManager: Starting task 121.0 in stage 13.0 (TID 136, localhost, executor driver, partition 121, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:10 INFO TaskSetManager: Finished task 114.0 in stage 13.0 (TID 129) in 1319 ms on localhost (executor driver) (114/188)
17/03/18 10:48:10 INFO Executor: Running task 121.0 in stage 13.0 (TID 136)
17/03/18 10:48:10 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4060086272+33554432
17/03/18 10:48:10 INFO Executor: Finished task 113.0 in stage 13.0 (TID 128). 1810 bytes result sent to driver
17/03/18 10:48:10 INFO Executor: Finished task 115.0 in stage 13.0 (TID 130). 1810 bytes result sent to driver
17/03/18 10:48:10 INFO TaskSetManager: Starting task 122.0 in stage 13.0 (TID 137, localhost, executor driver, partition 122, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:10 INFO Executor: Running task 122.0 in stage 13.0 (TID 137)
17/03/18 10:48:10 INFO TaskSetManager: Starting task 123.0 in stage 13.0 (TID 138, localhost, executor driver, partition 123, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:10 INFO TaskSetManager: Finished task 113.0 in stage 13.0 (TID 128) in 1403 ms on localhost (executor driver) (115/188)
17/03/18 10:48:10 INFO Executor: Running task 123.0 in stage 13.0 (TID 138)
17/03/18 10:48:10 INFO TaskSetManager: Finished task 115.0 in stage 13.0 (TID 130) in 1295 ms on localhost (executor driver) (116/188)
17/03/18 10:48:10 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4127195136+33554432
17/03/18 10:48:10 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4093640704+33554432
17/03/18 10:48:11 INFO Executor: Finished task 117.0 in stage 13.0 (TID 132). 1810 bytes result sent to driver
17/03/18 10:48:11 INFO TaskSetManager: Starting task 124.0 in stage 13.0 (TID 139, localhost, executor driver, partition 124, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:11 INFO Executor: Running task 124.0 in stage 13.0 (TID 139)
17/03/18 10:48:11 INFO TaskSetManager: Finished task 117.0 in stage 13.0 (TID 132) in 1313 ms on localhost (executor driver) (117/188)
17/03/18 10:48:11 INFO Executor: Finished task 118.0 in stage 13.0 (TID 133). 1810 bytes result sent to driver
17/03/18 10:48:11 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4160749568+33554432
17/03/18 10:48:11 INFO TaskSetManager: Starting task 125.0 in stage 13.0 (TID 140, localhost, executor driver, partition 125, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:11 INFO Executor: Running task 125.0 in stage 13.0 (TID 140)
17/03/18 10:48:11 INFO TaskSetManager: Finished task 118.0 in stage 13.0 (TID 133) in 1293 ms on localhost (executor driver) (118/188)
17/03/18 10:48:11 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4194304000+33554432
17/03/18 10:48:11 INFO Executor: Finished task 116.0 in stage 13.0 (TID 131). 1810 bytes result sent to driver
17/03/18 10:48:11 INFO TaskSetManager: Starting task 126.0 in stage 13.0 (TID 141, localhost, executor driver, partition 126, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:11 INFO Executor: Running task 126.0 in stage 13.0 (TID 141)
17/03/18 10:48:11 INFO TaskSetManager: Finished task 116.0 in stage 13.0 (TID 131) in 1471 ms on localhost (executor driver) (119/188)
17/03/18 10:48:11 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4227858432+33554432
17/03/18 10:48:11 INFO Executor: Finished task 119.0 in stage 13.0 (TID 134). 1810 bytes result sent to driver
17/03/18 10:48:11 INFO TaskSetManager: Starting task 127.0 in stage 13.0 (TID 142, localhost, executor driver, partition 127, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:11 INFO Executor: Running task 127.0 in stage 13.0 (TID 142)
17/03/18 10:48:11 INFO TaskSetManager: Finished task 119.0 in stage 13.0 (TID 134) in 1321 ms on localhost (executor driver) (120/188)
17/03/18 10:48:11 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4261412864+33554432
17/03/18 10:48:12 INFO Executor: Finished task 120.0 in stage 13.0 (TID 135). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 128.0 in stage 13.0 (TID 143, localhost, executor driver, partition 128, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 120.0 in stage 13.0 (TID 135) in 1306 ms on localhost (executor driver) (121/188)
17/03/18 10:48:12 INFO Executor: Running task 128.0 in stage 13.0 (TID 143)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4294967296+33554432
17/03/18 10:48:12 INFO Executor: Finished task 121.0 in stage 13.0 (TID 136). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 129.0 in stage 13.0 (TID 144, localhost, executor driver, partition 129, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO Executor: Running task 129.0 in stage 13.0 (TID 144)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 121.0 in stage 13.0 (TID 136) in 1319 ms on localhost (executor driver) (122/188)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4328521728+33554432
17/03/18 10:48:12 INFO Executor: Finished task 123.0 in stage 13.0 (TID 138). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 130.0 in stage 13.0 (TID 145, localhost, executor driver, partition 130, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 123.0 in stage 13.0 (TID 138) in 1317 ms on localhost (executor driver) (123/188)
17/03/18 10:48:12 INFO Executor: Running task 130.0 in stage 13.0 (TID 145)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4362076160+33554432
17/03/18 10:48:12 INFO Executor: Finished task 122.0 in stage 13.0 (TID 137). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 131.0 in stage 13.0 (TID 146, localhost, executor driver, partition 131, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 122.0 in stage 13.0 (TID 137) in 1430 ms on localhost (executor driver) (124/188)
17/03/18 10:48:12 INFO Executor: Running task 131.0 in stage 13.0 (TID 146)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4395630592+33554432
17/03/18 10:48:12 INFO Executor: Finished task 126.0 in stage 13.0 (TID 141). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 132.0 in stage 13.0 (TID 147, localhost, executor driver, partition 132, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO Executor: Running task 132.0 in stage 13.0 (TID 147)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 126.0 in stage 13.0 (TID 141) in 1307 ms on localhost (executor driver) (125/188)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4429185024+33554432
17/03/18 10:48:12 INFO Executor: Finished task 127.0 in stage 13.0 (TID 142). 1723 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 133.0 in stage 13.0 (TID 148, localhost, executor driver, partition 133, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 127.0 in stage 13.0 (TID 142) in 1342 ms on localhost (executor driver) (126/188)
17/03/18 10:48:12 INFO Executor: Running task 133.0 in stage 13.0 (TID 148)
17/03/18 10:48:12 INFO Executor: Finished task 124.0 in stage 13.0 (TID 139). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Starting task 134.0 in stage 13.0 (TID 149, localhost, executor driver, partition 134, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO Executor: Finished task 125.0 in stage 13.0 (TID 140). 1810 bytes result sent to driver
17/03/18 10:48:12 INFO TaskSetManager: Finished task 124.0 in stage 13.0 (TID 139) in 1389 ms on localhost (executor driver) (127/188)
17/03/18 10:48:12 INFO Executor: Running task 134.0 in stage 13.0 (TID 149)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4462739456+33554432
17/03/18 10:48:12 INFO TaskSetManager: Starting task 135.0 in stage 13.0 (TID 150, localhost, executor driver, partition 135, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:12 INFO Executor: Running task 135.0 in stage 13.0 (TID 150)
17/03/18 10:48:12 INFO TaskSetManager: Finished task 125.0 in stage 13.0 (TID 140) in 1387 ms on localhost (executor driver) (128/188)
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4496293888+33554432
17/03/18 10:48:12 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4529848320+33554432
17/03/18 10:48:13 INFO Executor: Finished task 128.0 in stage 13.0 (TID 143). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 136.0 in stage 13.0 (TID 151, localhost, executor driver, partition 136, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 128.0 in stage 13.0 (TID 143) in 1293 ms on localhost (executor driver) (129/188)
17/03/18 10:48:13 INFO Executor: Running task 136.0 in stage 13.0 (TID 151)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4563402752+33554432
17/03/18 10:48:13 INFO Executor: Finished task 129.0 in stage 13.0 (TID 144). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 137.0 in stage 13.0 (TID 152, localhost, executor driver, partition 137, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO Executor: Running task 137.0 in stage 13.0 (TID 152)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 129.0 in stage 13.0 (TID 144) in 1270 ms on localhost (executor driver) (130/188)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4596957184+33554432
17/03/18 10:48:13 INFO Executor: Finished task 130.0 in stage 13.0 (TID 145). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 138.0 in stage 13.0 (TID 153, localhost, executor driver, partition 138, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 130.0 in stage 13.0 (TID 145) in 1368 ms on localhost (executor driver) (131/188)
17/03/18 10:48:13 INFO Executor: Running task 138.0 in stage 13.0 (TID 153)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4630511616+33554432
17/03/18 10:48:13 INFO Executor: Finished task 131.0 in stage 13.0 (TID 146). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 139.0 in stage 13.0 (TID 154, localhost, executor driver, partition 139, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 131.0 in stage 13.0 (TID 146) in 1341 ms on localhost (executor driver) (132/188)
17/03/18 10:48:13 INFO Executor: Running task 139.0 in stage 13.0 (TID 154)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4664066048+33554432
17/03/18 10:48:13 INFO Executor: Finished task 133.0 in stage 13.0 (TID 148). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 140.0 in stage 13.0 (TID 155, localhost, executor driver, partition 140, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO Executor: Running task 140.0 in stage 13.0 (TID 155)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 133.0 in stage 13.0 (TID 148) in 1350 ms on localhost (executor driver) (133/188)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4697620480+33554432
17/03/18 10:48:13 INFO Executor: Finished task 134.0 in stage 13.0 (TID 149). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 141.0 in stage 13.0 (TID 156, localhost, executor driver, partition 141, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 134.0 in stage 13.0 (TID 149) in 1352 ms on localhost (executor driver) (134/188)
17/03/18 10:48:13 INFO Executor: Running task 141.0 in stage 13.0 (TID 156)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4731174912+33554432
17/03/18 10:48:13 INFO Executor: Finished task 132.0 in stage 13.0 (TID 147). 1810 bytes result sent to driver
17/03/18 10:48:13 INFO TaskSetManager: Starting task 142.0 in stage 13.0 (TID 157, localhost, executor driver, partition 142, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:13 INFO Executor: Running task 142.0 in stage 13.0 (TID 157)
17/03/18 10:48:13 INFO TaskSetManager: Finished task 132.0 in stage 13.0 (TID 147) in 1413 ms on localhost (executor driver) (135/188)
17/03/18 10:48:13 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4764729344+33554432
17/03/18 10:48:14 INFO Executor: Finished task 135.0 in stage 13.0 (TID 150). 1810 bytes result sent to driver
17/03/18 10:48:14 INFO TaskSetManager: Starting task 143.0 in stage 13.0 (TID 158, localhost, executor driver, partition 143, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:14 INFO TaskSetManager: Finished task 135.0 in stage 13.0 (TID 150) in 1395 ms on localhost (executor driver) (136/188)
17/03/18 10:48:14 INFO Executor: Running task 143.0 in stage 13.0 (TID 158)
17/03/18 10:48:14 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4798283776+33554432
17/03/18 10:48:14 INFO Executor: Finished task 136.0 in stage 13.0 (TID 151). 1810 bytes result sent to driver
17/03/18 10:48:14 INFO TaskSetManager: Starting task 144.0 in stage 13.0 (TID 159, localhost, executor driver, partition 144, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:14 INFO Executor: Running task 144.0 in stage 13.0 (TID 159)
17/03/18 10:48:14 INFO TaskSetManager: Finished task 136.0 in stage 13.0 (TID 151) in 1369 ms on localhost (executor driver) (137/188)
17/03/18 10:48:14 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4831838208+33554432
17/03/18 10:48:14 INFO Executor: Finished task 137.0 in stage 13.0 (TID 152). 1810 bytes result sent to driver
17/03/18 10:48:14 INFO TaskSetManager: Starting task 145.0 in stage 13.0 (TID 160, localhost, executor driver, partition 145, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:14 INFO TaskSetManager: Finished task 137.0 in stage 13.0 (TID 152) in 1375 ms on localhost (executor driver) (138/188)
17/03/18 10:48:14 INFO Executor: Running task 145.0 in stage 13.0 (TID 160)
17/03/18 10:48:14 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4865392640+33554432
17/03/18 10:48:15 INFO Executor: Finished task 138.0 in stage 13.0 (TID 153). 1810 bytes result sent to driver
17/03/18 10:48:15 INFO TaskSetManager: Starting task 146.0 in stage 13.0 (TID 161, localhost, executor driver, partition 146, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:15 INFO TaskSetManager: Finished task 138.0 in stage 13.0 (TID 153) in 1337 ms on localhost (executor driver) (139/188)
17/03/18 10:48:15 INFO Executor: Running task 146.0 in stage 13.0 (TID 161)
17/03/18 10:48:15 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4898947072+33554432
17/03/18 10:48:15 INFO Executor: Finished task 139.0 in stage 13.0 (TID 154). 1810 bytes result sent to driver
17/03/18 10:48:15 INFO TaskSetManager: Starting task 147.0 in stage 13.0 (TID 162, localhost, executor driver, partition 147, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:15 INFO TaskSetManager: Finished task 139.0 in stage 13.0 (TID 154) in 1307 ms on localhost (executor driver) (140/188)
17/03/18 10:48:15 INFO Executor: Running task 147.0 in stage 13.0 (TID 162)
17/03/18 10:48:15 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4932501504+33554432
17/03/18 10:48:15 INFO Executor: Finished task 140.0 in stage 13.0 (TID 155). 1810 bytes result sent to driver
17/03/18 10:48:15 INFO TaskSetManager: Starting task 148.0 in stage 13.0 (TID 163, localhost, executor driver, partition 148, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:15 INFO TaskSetManager: Finished task 140.0 in stage 13.0 (TID 155) in 1311 ms on localhost (executor driver) (141/188)
17/03/18 10:48:15 INFO Executor: Running task 148.0 in stage 13.0 (TID 163)
17/03/18 10:48:15 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4966055936+33554432
17/03/18 10:48:15 INFO Executor: Finished task 142.0 in stage 13.0 (TID 157). 1810 bytes result sent to driver
17/03/18 10:48:15 INFO TaskSetManager: Starting task 149.0 in stage 13.0 (TID 164, localhost, executor driver, partition 149, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:15 INFO Executor: Running task 149.0 in stage 13.0 (TID 164)
17/03/18 10:48:15 INFO TaskSetManager: Finished task 142.0 in stage 13.0 (TID 157) in 1307 ms on localhost (executor driver) (142/188)
17/03/18 10:48:15 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:4999610368+33554432
17/03/18 10:48:15 INFO Executor: Finished task 141.0 in stage 13.0 (TID 156). 1810 bytes result sent to driver
17/03/18 10:48:15 INFO TaskSetManager: Starting task 150.0 in stage 13.0 (TID 165, localhost, executor driver, partition 150, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:15 INFO Executor: Running task 150.0 in stage 13.0 (TID 165)
17/03/18 10:48:15 INFO TaskSetManager: Finished task 141.0 in stage 13.0 (TID 156) in 1337 ms on localhost (executor driver) (143/188)
17/03/18 10:48:15 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5033164800+33554432
17/03/18 10:48:15 INFO Executor: Finished task 143.0 in stage 13.0 (TID 158). 1810 bytes result sent to driver
17/03/18 10:48:15 INFO TaskSetManager: Starting task 151.0 in stage 13.0 (TID 166, localhost, executor driver, partition 151, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:15 INFO TaskSetManager: Finished task 143.0 in stage 13.0 (TID 158) in 1404 ms on localhost (executor driver) (144/188)
17/03/18 10:48:15 INFO Executor: Running task 151.0 in stage 13.0 (TID 166)
17/03/18 10:48:15 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5066719232+33554432
17/03/18 10:48:16 INFO Executor: Finished task 144.0 in stage 13.0 (TID 159). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 152.0 in stage 13.0 (TID 167, localhost, executor driver, partition 152, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 144.0 in stage 13.0 (TID 159) in 1282 ms on localhost (executor driver) (145/188)
17/03/18 10:48:16 INFO Executor: Running task 152.0 in stage 13.0 (TID 167)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5100273664+33554432
17/03/18 10:48:16 INFO Executor: Finished task 145.0 in stage 13.0 (TID 160). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 153.0 in stage 13.0 (TID 168, localhost, executor driver, partition 153, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO Executor: Running task 153.0 in stage 13.0 (TID 168)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 145.0 in stage 13.0 (TID 160) in 1361 ms on localhost (executor driver) (146/188)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5133828096+33554432
17/03/18 10:48:16 INFO Executor: Finished task 146.0 in stage 13.0 (TID 161). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 154.0 in stage 13.0 (TID 169, localhost, executor driver, partition 154, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO Executor: Running task 154.0 in stage 13.0 (TID 169)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 146.0 in stage 13.0 (TID 161) in 1352 ms on localhost (executor driver) (147/188)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5167382528+33554432
17/03/18 10:48:16 INFO Executor: Finished task 147.0 in stage 13.0 (TID 162). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 155.0 in stage 13.0 (TID 170, localhost, executor driver, partition 155, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 147.0 in stage 13.0 (TID 162) in 1328 ms on localhost (executor driver) (148/188)
17/03/18 10:48:16 INFO Executor: Running task 155.0 in stage 13.0 (TID 170)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5200936960+33554432
17/03/18 10:48:16 INFO Executor: Finished task 148.0 in stage 13.0 (TID 163). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 156.0 in stage 13.0 (TID 171, localhost, executor driver, partition 156, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO Executor: Running task 156.0 in stage 13.0 (TID 171)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 148.0 in stage 13.0 (TID 163) in 1317 ms on localhost (executor driver) (149/188)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5234491392+33554432
17/03/18 10:48:16 INFO Executor: Finished task 149.0 in stage 13.0 (TID 164). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 157.0 in stage 13.0 (TID 172, localhost, executor driver, partition 157, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 149.0 in stage 13.0 (TID 164) in 1318 ms on localhost (executor driver) (150/188)
17/03/18 10:48:16 INFO Executor: Running task 157.0 in stage 13.0 (TID 172)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5268045824+33554432
17/03/18 10:48:16 INFO Executor: Finished task 150.0 in stage 13.0 (TID 165). 1897 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 158.0 in stage 13.0 (TID 173, localhost, executor driver, partition 158, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 150.0 in stage 13.0 (TID 165) in 1347 ms on localhost (executor driver) (151/188)
17/03/18 10:48:16 INFO Executor: Running task 158.0 in stage 13.0 (TID 173)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5301600256+33554432
17/03/18 10:48:16 INFO Executor: Finished task 151.0 in stage 13.0 (TID 166). 1810 bytes result sent to driver
17/03/18 10:48:16 INFO TaskSetManager: Starting task 159.0 in stage 13.0 (TID 174, localhost, executor driver, partition 159, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:16 INFO Executor: Running task 159.0 in stage 13.0 (TID 174)
17/03/18 10:48:16 INFO TaskSetManager: Finished task 151.0 in stage 13.0 (TID 166) in 1349 ms on localhost (executor driver) (152/188)
17/03/18 10:48:16 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5335154688+33554432
17/03/18 10:48:17 INFO Executor: Finished task 152.0 in stage 13.0 (TID 167). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 160.0 in stage 13.0 (TID 175, localhost, executor driver, partition 160, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO Executor: Running task 160.0 in stage 13.0 (TID 175)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 152.0 in stage 13.0 (TID 167) in 1471 ms on localhost (executor driver) (153/188)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5368709120+33554432
17/03/18 10:48:17 INFO Executor: Finished task 153.0 in stage 13.0 (TID 168). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 161.0 in stage 13.0 (TID 176, localhost, executor driver, partition 161, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO Executor: Running task 161.0 in stage 13.0 (TID 176)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 153.0 in stage 13.0 (TID 168) in 1359 ms on localhost (executor driver) (154/188)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5402263552+33554432
17/03/18 10:48:17 INFO Executor: Finished task 154.0 in stage 13.0 (TID 169). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 162.0 in stage 13.0 (TID 177, localhost, executor driver, partition 162, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO Executor: Running task 162.0 in stage 13.0 (TID 177)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 154.0 in stage 13.0 (TID 169) in 1337 ms on localhost (executor driver) (155/188)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5435817984+33554432
17/03/18 10:48:17 INFO Executor: Finished task 155.0 in stage 13.0 (TID 170). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 163.0 in stage 13.0 (TID 178, localhost, executor driver, partition 163, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO Executor: Running task 163.0 in stage 13.0 (TID 178)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 155.0 in stage 13.0 (TID 170) in 1353 ms on localhost (executor driver) (156/188)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5469372416+33554432
17/03/18 10:48:17 INFO Executor: Finished task 157.0 in stage 13.0 (TID 172). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 164.0 in stage 13.0 (TID 179, localhost, executor driver, partition 164, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 157.0 in stage 13.0 (TID 172) in 1307 ms on localhost (executor driver) (157/188)
17/03/18 10:48:17 INFO Executor: Running task 164.0 in stage 13.0 (TID 179)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5502926848+33554432
17/03/18 10:48:17 INFO Executor: Finished task 156.0 in stage 13.0 (TID 171). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 165.0 in stage 13.0 (TID 180, localhost, executor driver, partition 165, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO Executor: Running task 165.0 in stage 13.0 (TID 180)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 156.0 in stage 13.0 (TID 171) in 1339 ms on localhost (executor driver) (158/188)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5536481280+33554432
17/03/18 10:48:17 INFO Executor: Finished task 158.0 in stage 13.0 (TID 173). 1810 bytes result sent to driver
17/03/18 10:48:17 INFO TaskSetManager: Starting task 166.0 in stage 13.0 (TID 181, localhost, executor driver, partition 166, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:17 INFO Executor: Running task 166.0 in stage 13.0 (TID 181)
17/03/18 10:48:17 INFO TaskSetManager: Finished task 158.0 in stage 13.0 (TID 173) in 1295 ms on localhost (executor driver) (159/188)
17/03/18 10:48:17 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5570035712+33554432
17/03/18 10:48:18 INFO Executor: Finished task 159.0 in stage 13.0 (TID 174). 1810 bytes result sent to driver
17/03/18 10:48:18 INFO TaskSetManager: Starting task 167.0 in stage 13.0 (TID 182, localhost, executor driver, partition 167, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:18 INFO Executor: Running task 167.0 in stage 13.0 (TID 182)
17/03/18 10:48:18 INFO TaskSetManager: Finished task 159.0 in stage 13.0 (TID 174) in 1333 ms on localhost (executor driver) (160/188)
17/03/18 10:48:18 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5603590144+33554432
17/03/18 10:48:18 INFO Executor: Finished task 160.0 in stage 13.0 (TID 175). 1810 bytes result sent to driver
17/03/18 10:48:18 INFO TaskSetManager: Starting task 168.0 in stage 13.0 (TID 183, localhost, executor driver, partition 168, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:18 INFO TaskSetManager: Finished task 160.0 in stage 13.0 (TID 175) in 1334 ms on localhost (executor driver) (161/188)
17/03/18 10:48:18 INFO Executor: Running task 168.0 in stage 13.0 (TID 183)
17/03/18 10:48:18 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5637144576+33554432
17/03/18 10:48:19 INFO Executor: Finished task 162.0 in stage 13.0 (TID 177). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 169.0 in stage 13.0 (TID 184, localhost, executor driver, partition 169, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO Executor: Running task 169.0 in stage 13.0 (TID 184)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 162.0 in stage 13.0 (TID 177) in 1318 ms on localhost (executor driver) (162/188)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5670699008+33554432
17/03/18 10:48:19 INFO Executor: Finished task 161.0 in stage 13.0 (TID 176). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 170.0 in stage 13.0 (TID 185, localhost, executor driver, partition 170, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 161.0 in stage 13.0 (TID 176) in 1363 ms on localhost (executor driver) (163/188)
17/03/18 10:48:19 INFO Executor: Running task 170.0 in stage 13.0 (TID 185)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5704253440+33554432
17/03/18 10:48:19 INFO Executor: Finished task 164.0 in stage 13.0 (TID 179). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 171.0 in stage 13.0 (TID 186, localhost, executor driver, partition 171, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO Executor: Running task 171.0 in stage 13.0 (TID 186)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 164.0 in stage 13.0 (TID 179) in 1351 ms on localhost (executor driver) (164/188)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5737807872+33554432
17/03/18 10:48:19 INFO Executor: Finished task 165.0 in stage 13.0 (TID 180). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 172.0 in stage 13.0 (TID 187, localhost, executor driver, partition 172, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO Executor: Running task 172.0 in stage 13.0 (TID 187)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 165.0 in stage 13.0 (TID 180) in 1372 ms on localhost (executor driver) (165/188)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5771362304+33554432
17/03/18 10:48:19 INFO Executor: Finished task 163.0 in stage 13.0 (TID 178). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 173.0 in stage 13.0 (TID 188, localhost, executor driver, partition 173, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 163.0 in stage 13.0 (TID 178) in 1568 ms on localhost (executor driver) (166/188)
17/03/18 10:48:19 INFO Executor: Running task 173.0 in stage 13.0 (TID 188)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5804916736+33554432
17/03/18 10:48:19 INFO Executor: Finished task 166.0 in stage 13.0 (TID 181). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 174.0 in stage 13.0 (TID 189, localhost, executor driver, partition 174, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO Executor: Running task 174.0 in stage 13.0 (TID 189)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 166.0 in stage 13.0 (TID 181) in 1373 ms on localhost (executor driver) (167/188)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5838471168+33554432
17/03/18 10:48:19 INFO Executor: Finished task 167.0 in stage 13.0 (TID 182). 1810 bytes result sent to driver
17/03/18 10:48:19 INFO TaskSetManager: Starting task 175.0 in stage 13.0 (TID 190, localhost, executor driver, partition 175, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:19 INFO Executor: Running task 175.0 in stage 13.0 (TID 190)
17/03/18 10:48:19 INFO TaskSetManager: Finished task 167.0 in stage 13.0 (TID 182) in 1323 ms on localhost (executor driver) (168/188)
17/03/18 10:48:19 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5872025600+33554432
17/03/18 10:48:20 INFO Executor: Finished task 169.0 in stage 13.0 (TID 184). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 176.0 in stage 13.0 (TID 191, localhost, executor driver, partition 176, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 176.0 in stage 13.0 (TID 191)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 169.0 in stage 13.0 (TID 184) in 1353 ms on localhost (executor driver) (169/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5905580032+33554432
17/03/18 10:48:20 INFO Executor: Finished task 170.0 in stage 13.0 (TID 185). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 177.0 in stage 13.0 (TID 192, localhost, executor driver, partition 177, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 177.0 in stage 13.0 (TID 192)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 170.0 in stage 13.0 (TID 185) in 1466 ms on localhost (executor driver) (170/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5939134464+33554432
17/03/18 10:48:20 INFO Executor: Finished task 168.0 in stage 13.0 (TID 183). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 178.0 in stage 13.0 (TID 193, localhost, executor driver, partition 178, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 178.0 in stage 13.0 (TID 193)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 168.0 in stage 13.0 (TID 183) in 1545 ms on localhost (executor driver) (171/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:5972688896+33554432
17/03/18 10:48:20 INFO Executor: Finished task 171.0 in stage 13.0 (TID 186). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 179.0 in stage 13.0 (TID 194, localhost, executor driver, partition 179, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 179.0 in stage 13.0 (TID 194)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 171.0 in stage 13.0 (TID 186) in 1303 ms on localhost (executor driver) (172/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6006243328+33554432
17/03/18 10:48:20 INFO Executor: Finished task 172.0 in stage 13.0 (TID 187). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 180.0 in stage 13.0 (TID 195, localhost, executor driver, partition 180, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 172.0 in stage 13.0 (TID 187) in 1312 ms on localhost (executor driver) (173/188)
17/03/18 10:48:20 INFO Executor: Running task 180.0 in stage 13.0 (TID 195)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6039797760+33554432
17/03/18 10:48:20 INFO Executor: Finished task 174.0 in stage 13.0 (TID 189). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 181.0 in stage 13.0 (TID 196, localhost, executor driver, partition 181, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 181.0 in stage 13.0 (TID 196)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 174.0 in stage 13.0 (TID 189) in 1323 ms on localhost (executor driver) (174/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6073352192+33554432
17/03/18 10:48:20 INFO Executor: Finished task 173.0 in stage 13.0 (TID 188). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 182.0 in stage 13.0 (TID 197, localhost, executor driver, partition 182, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 182.0 in stage 13.0 (TID 197)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 173.0 in stage 13.0 (TID 188) in 1397 ms on localhost (executor driver) (175/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6106906624+33554432
17/03/18 10:48:20 INFO Executor: Finished task 175.0 in stage 13.0 (TID 190). 1810 bytes result sent to driver
17/03/18 10:48:20 INFO TaskSetManager: Starting task 183.0 in stage 13.0 (TID 198, localhost, executor driver, partition 183, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:20 INFO Executor: Running task 183.0 in stage 13.0 (TID 198)
17/03/18 10:48:20 INFO TaskSetManager: Finished task 175.0 in stage 13.0 (TID 190) in 1319 ms on localhost (executor driver) (176/188)
17/03/18 10:48:20 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6140461056+33554432
17/03/18 10:48:21 INFO Executor: Finished task 176.0 in stage 13.0 (TID 191). 1810 bytes result sent to driver
17/03/18 10:48:21 INFO TaskSetManager: Starting task 184.0 in stage 13.0 (TID 199, localhost, executor driver, partition 184, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:21 INFO Executor: Running task 184.0 in stage 13.0 (TID 199)
17/03/18 10:48:21 INFO TaskSetManager: Finished task 176.0 in stage 13.0 (TID 191) in 1269 ms on localhost (executor driver) (177/188)
17/03/18 10:48:21 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6174015488+33554432
17/03/18 10:48:21 INFO Executor: Finished task 178.0 in stage 13.0 (TID 193). 1810 bytes result sent to driver
17/03/18 10:48:21 INFO TaskSetManager: Starting task 185.0 in stage 13.0 (TID 200, localhost, executor driver, partition 185, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:21 INFO TaskSetManager: Finished task 178.0 in stage 13.0 (TID 193) in 1332 ms on localhost (executor driver) (178/188)
17/03/18 10:48:21 INFO Executor: Running task 185.0 in stage 13.0 (TID 200)
17/03/18 10:48:21 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6207569920+33554432
17/03/18 10:48:21 INFO Executor: Finished task 179.0 in stage 13.0 (TID 194). 1810 bytes result sent to driver
17/03/18 10:48:21 INFO TaskSetManager: Starting task 186.0 in stage 13.0 (TID 201, localhost, executor driver, partition 186, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:21 INFO Executor: Running task 186.0 in stage 13.0 (TID 201)
17/03/18 10:48:21 INFO TaskSetManager: Finished task 179.0 in stage 13.0 (TID 194) in 1272 ms on localhost (executor driver) (179/188)
17/03/18 10:48:21 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6241124352+33554432
17/03/18 10:48:21 INFO Executor: Finished task 180.0 in stage 13.0 (TID 195). 1810 bytes result sent to driver
17/03/18 10:48:21 INFO TaskSetManager: Starting task 187.0 in stage 13.0 (TID 202, localhost, executor driver, partition 187, PROCESS_LOCAL, 6044 bytes)
17/03/18 10:48:21 INFO Executor: Running task 187.0 in stage 13.0 (TID 202)
17/03/18 10:48:21 INFO TaskSetManager: Finished task 180.0 in stage 13.0 (TID 195) in 1362 ms on localhost (executor driver) (180/188)
17/03/18 10:48:21 INFO HadoopRDD: Input split: file:/home/yannick/tmp/train.csv:6274678784+36468994
17/03/18 10:48:22 INFO Executor: Finished task 183.0 in stage 13.0 (TID 198). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 183.0 in stage 13.0 (TID 198) in 1290 ms on localhost (executor driver) (181/188)
17/03/18 10:48:22 INFO Executor: Finished task 182.0 in stage 13.0 (TID 197). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 182.0 in stage 13.0 (TID 197) in 1354 ms on localhost (executor driver) (182/188)
17/03/18 10:48:22 INFO Executor: Finished task 181.0 in stage 13.0 (TID 196). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 181.0 in stage 13.0 (TID 196) in 1421 ms on localhost (executor driver) (183/188)
17/03/18 10:48:22 INFO Executor: Finished task 177.0 in stage 13.0 (TID 192). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 177.0 in stage 13.0 (TID 192) in 1595 ms on localhost (executor driver) (184/188)
17/03/18 10:48:22 INFO Executor: Finished task 185.0 in stage 13.0 (TID 200). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 185.0 in stage 13.0 (TID 200) in 802 ms on localhost (executor driver) (185/188)
17/03/18 10:48:22 INFO Executor: Finished task 187.0 in stage 13.0 (TID 202). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 187.0 in stage 13.0 (TID 202) in 729 ms on localhost (executor driver) (186/188)
17/03/18 10:48:22 INFO Executor: Finished task 184.0 in stage 13.0 (TID 199). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 184.0 in stage 13.0 (TID 199) in 1125 ms on localhost (executor driver) (187/188)
17/03/18 10:48:22 INFO Executor: Finished task 186.0 in stage 13.0 (TID 201). 1810 bytes result sent to driver
17/03/18 10:48:22 INFO TaskSetManager: Finished task 186.0 in stage 13.0 (TID 201) in 961 ms on localhost (executor driver) (188/188)
17/03/18 10:48:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/03/18 10:48:22 INFO DAGScheduler: ResultStage 13 (csv at NativeMethodAccessorImpl.java:0) finished in 32,627 s
17/03/18 10:48:22 INFO DAGScheduler: Job 13 finished: csv at NativeMethodAccessorImpl.java:0, took 32,643966 s
17/03/18 10:48:22 INFO SparkSqlParser: Parsing command: train
17/03/18 10:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz3`
WHERE (0 = 1)
17/03/18 10:48:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 10:48:22 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:22 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:48:22 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:48:22 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:48:22 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:22 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 282.5 KB, free 6.2 GB)
17/03/18 10:48:22 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 10:48:22 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:55581 (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:48:22 INFO SparkContext: Created broadcast 21 from parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:48:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:48:22 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:48:22 INFO DAGScheduler: Got job 14 (parquet at NativeMethodAccessorImpl.java:0) with 48 output partitions
17/03/18 10:48:22 INFO DAGScheduler: Final stage: ResultStage 14 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:48:22 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:48:22 INFO DAGScheduler: Missing parents: List()
17/03/18 10:48:22 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[54] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:48:22 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 88.1 KB, free 6.2 GB)
17/03/18 10:48:22 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 33.8 KB, free 6.2 GB)
17/03/18 10:48:22 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:55581 (size: 33.8 KB, free: 6.2 GB)
17/03/18 10:48:22 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/03/18 10:48:22 INFO DAGScheduler: Submitting 48 missing tasks from ResultStage 14 (MapPartitionsRDD[54] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:48:22 INFO TaskSchedulerImpl: Adding task set 14.0 with 48 tasks
17/03/18 10:48:22 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 203, localhost, executor driver, partition 0, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 204, localhost, executor driver, partition 1, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 205, localhost, executor driver, partition 2, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 206, localhost, executor driver, partition 3, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 207, localhost, executor driver, partition 4, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 208, localhost, executor driver, partition 5, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 6.0 in stage 14.0 (TID 209, localhost, executor driver, partition 6, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO TaskSetManager: Starting task 7.0 in stage 14.0 (TID 210, localhost, executor driver, partition 7, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:22 INFO Executor: Running task 0.0 in stage 14.0 (TID 203)
17/03/18 10:48:22 INFO Executor: Running task 1.0 in stage 14.0 (TID 204)
17/03/18 10:48:22 INFO Executor: Running task 4.0 in stage 14.0 (TID 207)
17/03/18 10:48:22 INFO Executor: Running task 3.0 in stage 14.0 (TID 206)
17/03/18 10:48:22 INFO Executor: Running task 5.0 in stage 14.0 (TID 208)
17/03/18 10:48:22 INFO Executor: Running task 6.0 in stage 14.0 (TID 209)
17/03/18 10:48:22 INFO Executor: Running task 2.0 in stage 14.0 (TID 205)
17/03/18 10:48:22 INFO Executor: Running task 7.0 in stage 14.0 (TID 210)
17/03/18 10:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:22 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:22 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 939524096-1073741824, partition values: [empty row]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 134217728-268435456, partition values: [empty row]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 536870912-671088640, partition values: [empty row]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 0-134217728, partition values: [empty row]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 805306368-939524096, partition values: [empty row]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 268435456-402653184, partition values: [empty row]
17/03/18 10:48:23 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 671088640-805306368, partition values: [empty row]
17/03/18 10:48:23 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 402653184-536870912, partition values: [empty row]
17/03/18 10:48:25 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:55581 in memory (size: 33.8 KB, free: 6.2 GB)
17/03/18 10:48:25 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:55581 in memory (size: 24.0 KB, free: 6.2 GB)
17/03/18 10:48:25 INFO ContextCleaner: Cleaned accumulator 490
17/03/18 10:48:25 INFO ContextCleaner: Cleaned accumulator 489
17/03/18 10:48:25 INFO ContextCleaner: Cleaned accumulator 488
17/03/18 10:48:25 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:55581 in memory (size: 5.0 KB, free: 6.2 GB)
17/03/18 10:48:25 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:55581 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:48:25 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:55581 in memory (size: 23.1 KB, free: 6.2 GB)
17/03/18 10:48:36 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104822_0014_m_000002_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104822_0014_m_000002
17/03/18 10:48:36 INFO SparkHadoopMapRedUtil: attempt_20170318104822_0014_m_000002_0: Committed
17/03/18 10:48:36 INFO Executor: Finished task 2.0 in stage 14.0 (TID 205). 1699 bytes result sent to driver
17/03/18 10:48:36 INFO TaskSetManager: Starting task 8.0 in stage 14.0 (TID 211, localhost, executor driver, partition 8, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:36 INFO Executor: Running task 8.0 in stage 14.0 (TID 211)
17/03/18 10:48:36 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 205) in 13735 ms on localhost (executor driver) (1/48)
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:36 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104823_0014_m_000006_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104823_0014_m_000006
17/03/18 10:48:36 INFO SparkHadoopMapRedUtil: attempt_20170318104823_0014_m_000006_0: Committed
17/03/18 10:48:36 INFO Executor: Finished task 6.0 in stage 14.0 (TID 209). 1699 bytes result sent to driver
17/03/18 10:48:36 INFO TaskSetManager: Starting task 9.0 in stage 14.0 (TID 212, localhost, executor driver, partition 9, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:36 INFO Executor: Running task 9.0 in stage 14.0 (TID 212)
17/03/18 10:48:36 INFO TaskSetManager: Finished task 6.0 in stage 14.0 (TID 209) in 13789 ms on localhost (executor driver) (2/48)
17/03/18 10:48:36 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104823_0014_m_000001_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104823_0014_m_000001
17/03/18 10:48:36 INFO SparkHadoopMapRedUtil: attempt_20170318104823_0014_m_000001_0: Committed
17/03/18 10:48:36 INFO Executor: Finished task 1.0 in stage 14.0 (TID 204). 1699 bytes result sent to driver
17/03/18 10:48:36 INFO TaskSetManager: Starting task 10.0 in stage 14.0 (TID 213, localhost, executor driver, partition 10, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:36 INFO Executor: Running task 10.0 in stage 14.0 (TID 213)
17/03/18 10:48:36 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 204) in 13796 ms on localhost (executor driver) (3/48)
17/03/18 10:48:36 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:36 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1073741824-1207959552, partition values: [empty row]
17/03/18 10:48:36 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104823_0014_m_000004_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104823_0014_m_000004
17/03/18 10:48:36 INFO SparkHadoopMapRedUtil: attempt_20170318104823_0014_m_000004_0: Committed
17/03/18 10:48:36 INFO Executor: Finished task 4.0 in stage 14.0 (TID 207). 1699 bytes result sent to driver
17/03/18 10:48:36 INFO TaskSetManager: Starting task 11.0 in stage 14.0 (TID 214, localhost, executor driver, partition 11, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:36 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 207) in 13807 ms on localhost (executor driver) (4/48)
17/03/18 10:48:36 INFO Executor: Running task 11.0 in stage 14.0 (TID 214)
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:36 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:36 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1342177280-1476395008, partition values: [empty row]
17/03/18 10:48:36 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:36 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1476395008-1610612736, partition values: [empty row]
17/03/18 10:48:36 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:36 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1207959552-1342177280, partition values: [empty row]
17/03/18 10:48:36 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104822_0014_m_000003_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104822_0014_m_000003
17/03/18 10:48:36 INFO SparkHadoopMapRedUtil: attempt_20170318104822_0014_m_000003_0: Committed
17/03/18 10:48:36 INFO Executor: Finished task 3.0 in stage 14.0 (TID 206). 1699 bytes result sent to driver
17/03/18 10:48:36 INFO TaskSetManager: Starting task 12.0 in stage 14.0 (TID 215, localhost, executor driver, partition 12, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:36 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 206) in 13935 ms on localhost (executor driver) (5/48)
17/03/18 10:48:36 INFO Executor: Running task 12.0 in stage 14.0 (TID 215)
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:36 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:36 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:36 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:36 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1610612736-1744830464, partition values: [empty row]
17/03/18 10:48:37 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104823_0014_m_000007_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104823_0014_m_000007
17/03/18 10:48:37 INFO SparkHadoopMapRedUtil: attempt_20170318104823_0014_m_000007_0: Committed
17/03/18 10:48:37 INFO Executor: Finished task 7.0 in stage 14.0 (TID 210). 1699 bytes result sent to driver
17/03/18 10:48:37 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104822_0014_m_000000_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104822_0014_m_000000
17/03/18 10:48:37 INFO SparkHadoopMapRedUtil: attempt_20170318104822_0014_m_000000_0: Committed
17/03/18 10:48:37 INFO TaskSetManager: Starting task 13.0 in stage 14.0 (TID 216, localhost, executor driver, partition 13, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:37 INFO TaskSetManager: Finished task 7.0 in stage 14.0 (TID 210) in 14028 ms on localhost (executor driver) (6/48)
17/03/18 10:48:37 INFO Executor: Finished task 0.0 in stage 14.0 (TID 203). 1699 bytes result sent to driver
17/03/18 10:48:37 INFO Executor: Running task 13.0 in stage 14.0 (TID 216)
17/03/18 10:48:37 INFO TaskSetManager: Starting task 14.0 in stage 14.0 (TID 217, localhost, executor driver, partition 14, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:37 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 203) in 14032 ms on localhost (executor driver) (7/48)
17/03/18 10:48:37 INFO Executor: Running task 14.0 in stage 14.0 (TID 217)
17/03/18 10:48:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:37 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104823_0014_m_000005_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104823_0014_m_000005
17/03/18 10:48:37 INFO SparkHadoopMapRedUtil: attempt_20170318104823_0014_m_000005_0: Committed
17/03/18 10:48:37 INFO Executor: Finished task 5.0 in stage 14.0 (TID 208). 1699 bytes result sent to driver
17/03/18 10:48:37 INFO TaskSetManager: Starting task 15.0 in stage 14.0 (TID 218, localhost, executor driver, partition 15, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:37 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:37 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1744830464-1879048192, partition values: [empty row]
17/03/18 10:48:37 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 208) in 14084 ms on localhost (executor driver) (8/48)
17/03/18 10:48:37 INFO Executor: Running task 15.0 in stage 14.0 (TID 218)
17/03/18 10:48:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:37 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:37 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:37 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:37 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:37 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:37 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1879048192-2013265920, partition values: [empty row]
17/03/18 10:48:37 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:37 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2013265920-2147483648, partition values: [empty row]
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104837_0014_m_000014_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104837_0014_m_000014
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104837_0014_m_000014_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 14.0 in stage 14.0 (TID 217). 1786 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 16.0 in stage 14.0 (TID 219, localhost, executor driver, partition 16, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 14.0 in stage 14.0 (TID 217) in 13130 ms on localhost (executor driver) (9/48)
17/03/18 10:48:50 INFO Executor: Running task 16.0 in stage 14.0 (TID 219)
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104836_0014_m_000009_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104836_0014_m_000009
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104836_0014_m_000009_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 9.0 in stage 14.0 (TID 212). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 17.0 in stage 14.0 (TID 220, localhost, executor driver, partition 17, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 9.0 in stage 14.0 (TID 212) in 13403 ms on localhost (executor driver) (10/48)
17/03/18 10:48:50 INFO Executor: Running task 17.0 in stage 14.0 (TID 220)
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2147483648-2281701376, partition values: [empty row]
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104836_0014_m_000010_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104836_0014_m_000010
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104836_0014_m_000010_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 10.0 in stage 14.0 (TID 213). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 18.0 in stage 14.0 (TID 221, localhost, executor driver, partition 18, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO Executor: Running task 18.0 in stage 14.0 (TID 221)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 10.0 in stage 14.0 (TID 213) in 13485 ms on localhost (executor driver) (11/48)
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2281701376-2415919104, partition values: [empty row]
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104837_0014_m_000015_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104837_0014_m_000015
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104837_0014_m_000015_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 15.0 in stage 14.0 (TID 218). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 19.0 in stage 14.0 (TID 222, localhost, executor driver, partition 19, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 15.0 in stage 14.0 (TID 218) in 13230 ms on localhost (executor driver) (12/48)
17/03/18 10:48:50 INFO Executor: Running task 19.0 in stage 14.0 (TID 222)
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2550136832-2684354560, partition values: [empty row]
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104836_0014_m_000011_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104836_0014_m_000011
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104836_0014_m_000011_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 11.0 in stage 14.0 (TID 214). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 20.0 in stage 14.0 (TID 223, localhost, executor driver, partition 20, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO Executor: Running task 20.0 in stage 14.0 (TID 223)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 11.0 in stage 14.0 (TID 214) in 13555 ms on localhost (executor driver) (13/48)
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2415919104-2550136832, partition values: [empty row]
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2684354560-2818572288, partition values: [empty row]
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104836_0014_m_000008_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104836_0014_m_000008
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104836_0014_m_000008_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 8.0 in stage 14.0 (TID 211). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 21.0 in stage 14.0 (TID 224, localhost, executor driver, partition 21, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 8.0 in stage 14.0 (TID 211) in 13781 ms on localhost (executor driver) (14/48)
17/03/18 10:48:50 INFO Executor: Running task 21.0 in stage 14.0 (TID 224)
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104836_0014_m_000012_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104836_0014_m_000012
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104836_0014_m_000012_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 12.0 in stage 14.0 (TID 215). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 22.0 in stage 14.0 (TID 225, localhost, executor driver, partition 22, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 12.0 in stage 14.0 (TID 215) in 13601 ms on localhost (executor driver) (15/48)
17/03/18 10:48:50 INFO Executor: Running task 22.0 in stage 14.0 (TID 225)
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2818572288-2952790016, partition values: [empty row]
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2952790016-3087007744, partition values: [empty row]
17/03/18 10:48:50 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104837_0014_m_000013_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104837_0014_m_000013
17/03/18 10:48:50 INFO SparkHadoopMapRedUtil: attempt_20170318104837_0014_m_000013_0: Committed
17/03/18 10:48:50 INFO Executor: Finished task 13.0 in stage 14.0 (TID 216). 1699 bytes result sent to driver
17/03/18 10:48:50 INFO TaskSetManager: Starting task 23.0 in stage 14.0 (TID 226, localhost, executor driver, partition 23, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:48:50 INFO Executor: Running task 23.0 in stage 14.0 (TID 226)
17/03/18 10:48:50 INFO TaskSetManager: Finished task 13.0 in stage 14.0 (TID 216) in 13590 ms on localhost (executor driver) (16/48)
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:48:50 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:48:50 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:48:50 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:48:50 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3087007744-3221225472, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000016_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000016
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000016_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 16.0 in stage 14.0 (TID 219). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 24.0 in stage 14.0 (TID 227, localhost, executor driver, partition 24, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 16.0 in stage 14.0 (TID 219) in 12997 ms on localhost (executor driver) (17/48)
17/03/18 10:49:03 INFO Executor: Running task 24.0 in stage 14.0 (TID 227)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3221225472-3355443200, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000017_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000017
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000017_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 17.0 in stage 14.0 (TID 220). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 25.0 in stage 14.0 (TID 228, localhost, executor driver, partition 25, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO Executor: Running task 25.0 in stage 14.0 (TID 228)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 17.0 in stage 14.0 (TID 220) in 13058 ms on localhost (executor driver) (18/48)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3355443200-3489660928, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000020_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000020
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000020_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 20.0 in stage 14.0 (TID 223). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 26.0 in stage 14.0 (TID 229, localhost, executor driver, partition 26, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 20.0 in stage 14.0 (TID 223) in 12935 ms on localhost (executor driver) (19/48)
17/03/18 10:49:03 INFO Executor: Running task 26.0 in stage 14.0 (TID 229)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3489660928-3623878656, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000021_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000021
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000021_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 21.0 in stage 14.0 (TID 224). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 27.0 in stage 14.0 (TID 230, localhost, executor driver, partition 27, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO Executor: Running task 27.0 in stage 14.0 (TID 230)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 21.0 in stage 14.0 (TID 224) in 12854 ms on localhost (executor driver) (20/48)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3623878656-3758096384, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000018_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000018
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000018_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 18.0 in stage 14.0 (TID 221). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 28.0 in stage 14.0 (TID 231, localhost, executor driver, partition 28, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO Executor: Running task 28.0 in stage 14.0 (TID 231)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 18.0 in stage 14.0 (TID 221) in 13199 ms on localhost (executor driver) (21/48)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3758096384-3892314112, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000019_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000019
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000019_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 19.0 in stage 14.0 (TID 222). 1786 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 29.0 in stage 14.0 (TID 232, localhost, executor driver, partition 29, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO Executor: Running task 29.0 in stage 14.0 (TID 232)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 19.0 in stage 14.0 (TID 222) in 13210 ms on localhost (executor driver) (22/48)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3892314112-4026531840, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000022_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000022
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000022_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 22.0 in stage 14.0 (TID 225). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 30.0 in stage 14.0 (TID 233, localhost, executor driver, partition 30, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 22.0 in stage 14.0 (TID 225) in 13106 ms on localhost (executor driver) (23/48)
17/03/18 10:49:03 INFO Executor: Running task 30.0 in stage 14.0 (TID 233)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4026531840-4160749568, partition values: [empty row]
17/03/18 10:49:03 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104850_0014_m_000023_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104850_0014_m_000023
17/03/18 10:49:03 INFO SparkHadoopMapRedUtil: attempt_20170318104850_0014_m_000023_0: Committed
17/03/18 10:49:03 INFO Executor: Finished task 23.0 in stage 14.0 (TID 226). 1699 bytes result sent to driver
17/03/18 10:49:03 INFO TaskSetManager: Starting task 31.0 in stage 14.0 (TID 234, localhost, executor driver, partition 31, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:03 INFO TaskSetManager: Finished task 23.0 in stage 14.0 (TID 226) in 13155 ms on localhost (executor driver) (24/48)
17/03/18 10:49:03 INFO Executor: Running task 31.0 in stage 14.0 (TID 234)
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:03 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:03 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:03 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:03 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4160749568-4294967296, partition values: [empty row]
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000025_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000025
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000025_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 25.0 in stage 14.0 (TID 228). 1699 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 32.0 in stage 14.0 (TID 235, localhost, executor driver, partition 32, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO Executor: Running task 32.0 in stage 14.0 (TID 235)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 25.0 in stage 14.0 (TID 228) in 13067 ms on localhost (executor driver) (25/48)
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000024_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000024
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000024_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 24.0 in stage 14.0 (TID 227). 1699 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 33.0 in stage 14.0 (TID 236, localhost, executor driver, partition 33, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 24.0 in stage 14.0 (TID 227) in 13180 ms on localhost (executor driver) (26/48)
17/03/18 10:49:16 INFO Executor: Running task 33.0 in stage 14.0 (TID 236)
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:16 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:16 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4294967296-4429185024, partition values: [empty row]
17/03/18 10:49:16 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:16 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4429185024-4563402752, partition values: [empty row]
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000028_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000028
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000028_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 28.0 in stage 14.0 (TID 231). 1699 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 34.0 in stage 14.0 (TID 237, localhost, executor driver, partition 34, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 28.0 in stage 14.0 (TID 231) in 13072 ms on localhost (executor driver) (27/48)
17/03/18 10:49:16 INFO Executor: Running task 34.0 in stage 14.0 (TID 237)
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000026_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000026
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000026_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 26.0 in stage 14.0 (TID 229). 1699 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 35.0 in stage 14.0 (TID 238, localhost, executor driver, partition 35, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 26.0 in stage 14.0 (TID 229) in 13278 ms on localhost (executor driver) (28/48)
17/03/18 10:49:16 INFO Executor: Running task 35.0 in stage 14.0 (TID 238)
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:16 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:16 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4697620480-4831838208, partition values: [empty row]
17/03/18 10:49:16 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:16 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4563402752-4697620480, partition values: [empty row]
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000027_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000027
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000027_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 27.0 in stage 14.0 (TID 230). 1699 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 36.0 in stage 14.0 (TID 239, localhost, executor driver, partition 36, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO Executor: Running task 36.0 in stage 14.0 (TID 239)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 27.0 in stage 14.0 (TID 230) in 13384 ms on localhost (executor driver) (29/48)
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:16 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:16 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4831838208-4966055936, partition values: [empty row]
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000030_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000030
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000030_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 30.0 in stage 14.0 (TID 233). 1786 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 37.0 in stage 14.0 (TID 240, localhost, executor driver, partition 37, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 30.0 in stage 14.0 (TID 233) in 13163 ms on localhost (executor driver) (30/48)
17/03/18 10:49:16 INFO Executor: Running task 37.0 in stage 14.0 (TID 240)
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:16 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:16 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:16 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:16 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4966055936-5100273664, partition values: [empty row]
17/03/18 10:49:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000031_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000031
17/03/18 10:49:16 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000031_0: Committed
17/03/18 10:49:16 INFO Executor: Finished task 31.0 in stage 14.0 (TID 234). 1699 bytes result sent to driver
17/03/18 10:49:16 INFO TaskSetManager: Starting task 38.0 in stage 14.0 (TID 241, localhost, executor driver, partition 38, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:16 INFO Executor: Running task 38.0 in stage 14.0 (TID 241)
17/03/18 10:49:16 INFO TaskSetManager: Finished task 31.0 in stage 14.0 (TID 234) in 13239 ms on localhost (executor driver) (31/48)
17/03/18 10:49:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:17 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:17 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5100273664-5234491392, partition values: [empty row]
17/03/18 10:49:17 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104903_0014_m_000029_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104903_0014_m_000029
17/03/18 10:49:17 INFO SparkHadoopMapRedUtil: attempt_20170318104903_0014_m_000029_0: Committed
17/03/18 10:49:17 INFO Executor: Finished task 29.0 in stage 14.0 (TID 232). 1699 bytes result sent to driver
17/03/18 10:49:17 INFO TaskSetManager: Starting task 39.0 in stage 14.0 (TID 242, localhost, executor driver, partition 39, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:17 INFO Executor: Running task 39.0 in stage 14.0 (TID 242)
17/03/18 10:49:17 INFO TaskSetManager: Finished task 29.0 in stage 14.0 (TID 232) in 13735 ms on localhost (executor driver) (32/48)
17/03/18 10:49:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:17 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:17 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:17 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:17 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:17 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:17 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5234491392-5368709120, partition values: [empty row]
17/03/18 10:49:28 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104916_0014_m_000033_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104916_0014_m_000033
17/03/18 10:49:28 INFO SparkHadoopMapRedUtil: attempt_20170318104916_0014_m_000033_0: Committed
17/03/18 10:49:28 INFO Executor: Finished task 33.0 in stage 14.0 (TID 236). 1699 bytes result sent to driver
17/03/18 10:49:28 INFO TaskSetManager: Starting task 40.0 in stage 14.0 (TID 243, localhost, executor driver, partition 40, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:28 INFO Executor: Running task 40.0 in stage 14.0 (TID 243)
17/03/18 10:49:28 INFO TaskSetManager: Finished task 33.0 in stage 14.0 (TID 236) in 12653 ms on localhost (executor driver) (33/48)
17/03/18 10:49:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:28 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:28 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:28 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:28 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:29 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104916_0014_m_000032_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104916_0014_m_000032
17/03/18 10:49:29 INFO SparkHadoopMapRedUtil: attempt_20170318104916_0014_m_000032_0: Committed
17/03/18 10:49:29 INFO Executor: Finished task 32.0 in stage 14.0 (TID 235). 1699 bytes result sent to driver
17/03/18 10:49:29 INFO TaskSetManager: Starting task 41.0 in stage 14.0 (TID 244, localhost, executor driver, partition 41, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:29 INFO TaskSetManager: Finished task 32.0 in stage 14.0 (TID 235) in 12711 ms on localhost (executor driver) (34/48)
17/03/18 10:49:29 INFO Executor: Running task 41.0 in stage 14.0 (TID 244)
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:29 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5368709120-5502926848, partition values: [empty row]
17/03/18 10:49:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:29 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:29 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5502926848-5637144576, partition values: [empty row]
17/03/18 10:49:29 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104916_0014_m_000034_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104916_0014_m_000034
17/03/18 10:49:29 INFO SparkHadoopMapRedUtil: attempt_20170318104916_0014_m_000034_0: Committed
17/03/18 10:49:29 INFO Executor: Finished task 34.0 in stage 14.0 (TID 237). 1699 bytes result sent to driver
17/03/18 10:49:29 INFO TaskSetManager: Starting task 42.0 in stage 14.0 (TID 245, localhost, executor driver, partition 42, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:29 INFO TaskSetManager: Finished task 34.0 in stage 14.0 (TID 237) in 12784 ms on localhost (executor driver) (35/48)
17/03/18 10:49:29 INFO Executor: Running task 42.0 in stage 14.0 (TID 245)
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:29 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104916_0014_m_000036_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104916_0014_m_000036
17/03/18 10:49:29 INFO SparkHadoopMapRedUtil: attempt_20170318104916_0014_m_000036_0: Committed
17/03/18 10:49:29 INFO Executor: Finished task 36.0 in stage 14.0 (TID 239). 1699 bytes result sent to driver
17/03/18 10:49:29 INFO TaskSetManager: Starting task 43.0 in stage 14.0 (TID 246, localhost, executor driver, partition 43, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:29 INFO TaskSetManager: Finished task 36.0 in stage 14.0 (TID 239) in 12607 ms on localhost (executor driver) (36/48)
17/03/18 10:49:29 INFO Executor: Running task 43.0 in stage 14.0 (TID 246)
17/03/18 10:49:29 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:29 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5637144576-5771362304, partition values: [empty row]
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:29 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:29 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5771362304-5905580032, partition values: [empty row]
17/03/18 10:49:29 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104916_0014_m_000035_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104916_0014_m_000035
17/03/18 10:49:29 INFO SparkHadoopMapRedUtil: attempt_20170318104916_0014_m_000035_0: Committed
17/03/18 10:49:29 INFO Executor: Finished task 35.0 in stage 14.0 (TID 238). 1699 bytes result sent to driver
17/03/18 10:49:29 INFO TaskSetManager: Starting task 44.0 in stage 14.0 (TID 247, localhost, executor driver, partition 44, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:29 INFO TaskSetManager: Finished task 35.0 in stage 14.0 (TID 238) in 12961 ms on localhost (executor driver) (37/48)
17/03/18 10:49:29 INFO Executor: Running task 44.0 in stage 14.0 (TID 247)
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:29 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:29 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5905580032-6039797760, partition values: [empty row]
17/03/18 10:49:29 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104916_0014_m_000037_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104916_0014_m_000037
17/03/18 10:49:29 INFO SparkHadoopMapRedUtil: attempt_20170318104916_0014_m_000037_0: Committed
17/03/18 10:49:29 INFO Executor: Finished task 37.0 in stage 14.0 (TID 240). 1699 bytes result sent to driver
17/03/18 10:49:29 INFO TaskSetManager: Starting task 45.0 in stage 14.0 (TID 248, localhost, executor driver, partition 45, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:29 INFO TaskSetManager: Finished task 37.0 in stage 14.0 (TID 240) in 12968 ms on localhost (executor driver) (38/48)
17/03/18 10:49:29 INFO Executor: Running task 45.0 in stage 14.0 (TID 248)
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:29 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:29 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:29 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:29 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 6039797760-6174015488, partition values: [empty row]
17/03/18 10:49:30 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104917_0014_m_000039_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104917_0014_m_000039
17/03/18 10:49:30 INFO SparkHadoopMapRedUtil: attempt_20170318104917_0014_m_000039_0: Committed
17/03/18 10:49:30 INFO Executor: Finished task 39.0 in stage 14.0 (TID 242). 1699 bytes result sent to driver
17/03/18 10:49:30 INFO TaskSetManager: Starting task 46.0 in stage 14.0 (TID 249, localhost, executor driver, partition 46, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:30 INFO TaskSetManager: Finished task 39.0 in stage 14.0 (TID 242) in 12924 ms on localhost (executor driver) (39/48)
17/03/18 10:49:30 INFO Executor: Running task 46.0 in stage 14.0 (TID 249)
17/03/18 10:49:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:30 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:30 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 6174015488-6308233216, partition values: [empty row]
17/03/18 10:49:30 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104917_0014_m_000038_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104917_0014_m_000038
17/03/18 10:49:30 INFO SparkHadoopMapRedUtil: attempt_20170318104917_0014_m_000038_0: Committed
17/03/18 10:49:30 INFO Executor: Finished task 38.0 in stage 14.0 (TID 241). 1699 bytes result sent to driver
17/03/18 10:49:30 INFO TaskSetManager: Starting task 47.0 in stage 14.0 (TID 250, localhost, executor driver, partition 47, PROCESS_LOCAL, 6585 bytes)
17/03/18 10:49:30 INFO TaskSetManager: Finished task 38.0 in stage 14.0 (TID 241) in 13353 ms on localhost (executor driver) (40/48)
17/03/18 10:49:30 INFO Executor: Running task 47.0 in stage 14.0 (TID 250)
17/03/18 10:49:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:30 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:30 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 10:49:30 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 10:49:30 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "decimal(20,0)",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional fixed_len_byte_array(9) id (DECIMAL(20,0));
  optional int32 click;
  optional int32 hour;
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 10:49:30 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 10:49:30 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 6308233216-6311147778, partition values: [empty row]
17/03/18 10:49:30 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104930_0014_m_000047_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104930_0014_m_000047
17/03/18 10:49:30 INFO SparkHadoopMapRedUtil: attempt_20170318104930_0014_m_000047_0: Committed
17/03/18 10:49:30 INFO Executor: Finished task 47.0 in stage 14.0 (TID 250). 1626 bytes result sent to driver
17/03/18 10:49:30 INFO TaskSetManager: Finished task 47.0 in stage 14.0 (TID 250) in 463 ms on localhost (executor driver) (41/48)
17/03/18 10:49:39 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104928_0014_m_000040_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104928_0014_m_000040
17/03/18 10:49:39 INFO SparkHadoopMapRedUtil: attempt_20170318104928_0014_m_000040_0: Committed
17/03/18 10:49:39 INFO Executor: Finished task 40.0 in stage 14.0 (TID 243). 1699 bytes result sent to driver
17/03/18 10:49:39 INFO TaskSetManager: Finished task 40.0 in stage 14.0 (TID 243) in 10897 ms on localhost (executor driver) (42/48)
17/03/18 10:49:40 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104930_0014_m_000046_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104930_0014_m_000046
17/03/18 10:49:40 INFO SparkHadoopMapRedUtil: attempt_20170318104930_0014_m_000046_0: Committed
17/03/18 10:49:40 INFO Executor: Finished task 46.0 in stage 14.0 (TID 249). 1699 bytes result sent to driver
17/03/18 10:49:40 INFO TaskSetManager: Finished task 46.0 in stage 14.0 (TID 249) in 10189 ms on localhost (executor driver) (43/48)
17/03/18 10:49:40 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104929_0014_m_000041_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104929_0014_m_000041
17/03/18 10:49:40 INFO SparkHadoopMapRedUtil: attempt_20170318104929_0014_m_000041_0: Committed
17/03/18 10:49:40 INFO Executor: Finished task 41.0 in stage 14.0 (TID 244). 1699 bytes result sent to driver
17/03/18 10:49:40 INFO TaskSetManager: Finished task 41.0 in stage 14.0 (TID 244) in 11742 ms on localhost (executor driver) (44/48)
17/03/18 10:49:41 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104929_0014_m_000045_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104929_0014_m_000045
17/03/18 10:49:41 INFO SparkHadoopMapRedUtil: attempt_20170318104929_0014_m_000045_0: Committed
17/03/18 10:49:41 INFO Executor: Finished task 45.0 in stage 14.0 (TID 248). 1699 bytes result sent to driver
17/03/18 10:49:41 INFO TaskSetManager: Finished task 45.0 in stage 14.0 (TID 248) in 11519 ms on localhost (executor driver) (45/48)
17/03/18 10:49:41 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104929_0014_m_000042_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104929_0014_m_000042
17/03/18 10:49:41 INFO SparkHadoopMapRedUtil: attempt_20170318104929_0014_m_000042_0: Committed
17/03/18 10:49:41 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104929_0014_m_000043_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104929_0014_m_000043
17/03/18 10:49:41 INFO FileOutputCommitter: Saved output of task 'attempt_20170318104929_0014_m_000044_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318104929_0014_m_000044
17/03/18 10:49:41 INFO SparkHadoopMapRedUtil: attempt_20170318104929_0014_m_000044_0: Committed
17/03/18 10:49:41 INFO SparkHadoopMapRedUtil: attempt_20170318104929_0014_m_000043_0: Committed
17/03/18 10:49:41 INFO Executor: Finished task 44.0 in stage 14.0 (TID 247). 1699 bytes result sent to driver
17/03/18 10:49:41 INFO Executor: Finished task 42.0 in stage 14.0 (TID 245). 1699 bytes result sent to driver
17/03/18 10:49:41 INFO Executor: Finished task 43.0 in stage 14.0 (TID 246). 1699 bytes result sent to driver
17/03/18 10:49:41 INFO TaskSetManager: Finished task 44.0 in stage 14.0 (TID 247) in 12472 ms on localhost (executor driver) (46/48)
17/03/18 10:49:41 INFO TaskSetManager: Finished task 43.0 in stage 14.0 (TID 246) in 12646 ms on localhost (executor driver) (47/48)
17/03/18 10:49:41 INFO TaskSetManager: Finished task 42.0 in stage 14.0 (TID 245) in 12677 ms on localhost (executor driver) (48/48)
17/03/18 10:49:41 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/03/18 10:49:41 INFO DAGScheduler: ResultStage 14 (parquet at NativeMethodAccessorImpl.java:0) finished in 79,007 s
17/03/18 10:49:41 INFO DAGScheduler: Job 14 finished: parquet at NativeMethodAccessorImpl.java:0, took 79,019158 s
17/03/18 10:49:42 INFO FileFormatWriter: Job null committed.
17/03/18 10:49:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:49:42 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:49:42 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:49:42 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:49:42 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:49:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:49:42 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:50:51 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 10:50:51 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/03/18 10:50:51 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 10:50:51 INFO MemoryStore: MemoryStore cleared
17/03/18 10:50:51 INFO BlockManager: BlockManager stopped
17/03/18 10:50:51 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 10:50:51 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 10:50:51 INFO SparkContext: Successfully stopped SparkContext
17/03/18 10:50:51 INFO ShutdownHookManager: Shutdown hook called
17/03/18 10:50:51 INFO ShutdownHookManager: Deleting directory /home/yannick/tmp/sparklyr/spark-cb6a98fb-4e31-4cba-aecd-049fcc2ced12
17/03/18 10:53:36 INFO SparkContext: Running Spark version 2.1.0
17/03/18 10:53:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 10:53:36 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 10:53:36 INFO SecurityManager: Changing view acls to: yannick
17/03/18 10:53:36 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 10:53:36 INFO SecurityManager: Changing view acls groups to: 
17/03/18 10:53:36 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 10:53:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 10:53:36 INFO Utils: Successfully started service 'sparkDriver' on port 40245.
17/03/18 10:53:36 INFO SparkEnv: Registering MapOutputTracker
17/03/18 10:53:36 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 10:53:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 10:53:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 10:53:36 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-468de8b6-a3fd-46cb-bb2f-98d3ffe62f86
17/03/18 10:53:36 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 10:53:36 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 10:53:36 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/18 10:53:36 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/03/18 10:53:36 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:40245/jars/sparklyr-2.1-2.11.jar with timestamp 1489830816889
17/03/18 10:53:36 INFO Executor: Starting executor ID driver on host localhost
17/03/18 10:53:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 38568.
17/03/18 10:53:36 INFO NettyBlockTransferService: Server created on 127.0.0.1:38568
17/03/18 10:53:36 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 10:53:36 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 38568, None)
17/03/18 10:53:36 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:38568 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 38568, None)
17/03/18 10:53:36 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 38568, None)
17/03/18 10:53:36 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 38568, None)
17/03/18 10:53:37 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 10:53:37 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 10:53:37 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 10:53:37 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 10:53:37 INFO ObjectStore: ObjectStore, initialize called
17/03/18 10:53:38 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 10:53:38 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 10:53:38 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 10:53:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:53:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:53:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:53:39 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:53:40 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 10:53:40 INFO ObjectStore: Initialized ObjectStore
17/03/18 10:53:40 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 10:53:40 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 10:53:40 INFO HiveMetaStore: Added admin role in metastore
17/03/18 10:53:40 INFO HiveMetaStore: Added public role in metastore
17/03/18 10:53:40 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 10:53:40 INFO HiveMetaStore: 0: get_all_databases
17/03/18 10:53:40 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 10:53:40 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 10:53:40 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 10:53:40 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 10:53:40 INFO SessionState: Created local directory: /tmp/5708eecc-8652-4b0e-94c5-bade3ce66f3e_resources
17/03/18 10:53:40 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/5708eecc-8652-4b0e-94c5-bade3ce66f3e
17/03/18 10:53:40 INFO SessionState: Created local directory: /tmp/yannick/5708eecc-8652-4b0e-94c5-bade3ce66f3e
17/03/18 10:53:40 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/5708eecc-8652-4b0e-94c5-bade3ce66f3e/_tmp_space.db
17/03/18 10:53:40 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 10:53:40 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:53:40 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:53:40 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 10:53:40 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 10:53:40 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 10:53:53 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:53:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:53:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:53:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:53:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:53:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:53:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:53:55 INFO CodeGenerator: Code generated in 200.992128 ms
17/03/18 10:53:55 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 10:53:55 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/03/18 10:53:55 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/03/18 10:53:55 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:53:55 INFO DAGScheduler: Missing parents: List()
17/03/18 10:53:55 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/03/18 10:53:55 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 10:53:55 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 10:53:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:38568 (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:53:55 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/18 10:53:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/03/18 10:53:55 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/18 10:53:55 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/03/18 10:53:55 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/18 10:53:55 INFO Executor: Fetching spark://127.0.0.1:40245/jars/sparklyr-2.1-2.11.jar with timestamp 1489830816889
17/03/18 10:53:55 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:40245 after 9 ms (0 ms spent in bootstraps)
17/03/18 10:53:55 INFO Utils: Fetching spark://127.0.0.1:40245/jars/sparklyr-2.1-2.11.jar to /home/yannick/tmp/sparklyr/spark-4dd36f89-34ae-4f00-b390-cc46d2ca5d45/userFiles-4926ecbf-ab4e-45bc-8ebc-a0657133fb1a/fetchFileTemp7638726583455671311.tmp
17/03/18 10:53:55 INFO Executor: Adding file:/home/yannick/tmp/sparklyr/spark-4dd36f89-34ae-4f00-b390-cc46d2ca5d45/userFiles-4926ecbf-ab4e-45bc-8ebc-a0657133fb1a/sparklyr-2.1-2.11.jar to class loader
17/03/18 10:53:55 INFO CodeGenerator: Code generated in 10.998299 ms
17/03/18 10:53:55 INFO CodeGenerator: Code generated in 10.733785 ms
17/03/18 10:53:55 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/03/18 10:53:55 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 193 ms on localhost (executor driver) (1/1)
17/03/18 10:53:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/18 10:53:55 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0,211 s
17/03/18 10:53:55 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 0,320146 s
17/03/18 10:53:56 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 10:53:56 INFO DAGScheduler: Got job 1 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:53:56 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:53:56 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:53:56 INFO DAGScheduler: Missing parents: List()
17/03/18 10:53:56 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:53:56 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 10:53:56 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 6.2 GB)
17/03/18 10:53:56 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:38568 (size: 25.4 KB, free: 6.2 GB)
17/03/18 10:53:56 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/03/18 10:53:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 10:53:56 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/18 10:53:56 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6217 bytes)
17/03/18 10:53:56 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/18 10:53:56 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 3101 bytes result sent to driver
17/03/18 10:53:56 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 154 ms on localhost (executor driver) (1/1)
17/03/18 10:53:56 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/18 10:53:56 INFO DAGScheduler: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,155 s
17/03/18 10:53:56 INFO DAGScheduler: Job 1 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,186629 s
17/03/18 10:53:56 INFO SparkSqlParser: Parsing command: train
17/03/18 10:53:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz1`
WHERE (0 = 1)
17/03/18 10:53:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 10:53:56 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:53:56 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:53:56 INFO HiveMetaStore: 0: get_database: default
17/03/18 10:53:56 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 10:53:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 10:53:56 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 10:53:56 INFO CodeGenerator: Code generated in 9.152973 ms
17/03/18 10:54:03 INFO ContextCleaner: Cleaned accumulator 0
17/03/18 10:54:03 INFO ContextCleaner: Cleaned accumulator 1
17/03/18 10:54:03 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:38568 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 10:54:03 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:38568 in memory (size: 25.4 KB, free: 6.2 GB)
17/03/18 10:54:04 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM (SELECT *
FROM (SELECT `device_id`, `device_ip`, `int_day`, `int_hour`, `int_hour` - LAG(`int_hour`, 1, NULL) OVER (PARTITION BY `device_id`, `device_ip`, `int_day` ORDER BY "int_hour") AS `dt_hour`
FROM (SELECT `device_id` AS `device_id`, `device_ip` AS `device_ip`, `int_day` AS `int_day`, `int_hour` AS `int_hour`
FROM (SELECT *
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, `int_day`, SUBSTR(`hour`, 7.0, 2.0) AS `int_hour`
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, SUBSTR(`hour`, 5.0, 2.0) AS `int_day`
FROM `train`) `adkpzicfgv`) `wtjtvyygws`
ORDER BY `int_hour`) `glaopneles`) `rplepxcmjb`) `pfflfmseyi`
WHERE ((`dt_hour`) IS NULL)) `hsmrssuywz`
17/03/18 10:54:05 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:54:05 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:54:05 INFO FileSourceStrategy: Output Data Schema: struct<hour: int, device_id: string, device_ip: string ... 1 more fields>
17/03/18 10:54:05 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:54:05 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/03/18 10:54:05 INFO CodeGenerator: Code generated in 14.384983 ms
17/03/18 10:54:05 INFO CodeGenerator: Code generated in 19.020561 ms
17/03/18 10:54:05 INFO CodeGenerator: Code generated in 15.084329 ms
17/03/18 10:54:05 INFO CodeGenerator: Code generated in 26.143274 ms
17/03/18 10:54:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 297.7 KB, free 6.2 GB)
17/03/18 10:54:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 24.3 KB, free 6.2 GB)
17/03/18 10:54:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:38568 (size: 24.3 KB, free: 6.2 GB)
17/03/18 10:54:05 INFO SparkContext: Created broadcast 2 from collect at utils.scala:197
17/03/18 10:54:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:54:05 INFO CodeGenerator: Code generated in 11.181905 ms
17/03/18 10:54:05 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:54:05 INFO DAGScheduler: Got job 2 (collect at utils.scala:197) with 12 output partitions
17/03/18 10:54:05 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:197)
17/03/18 10:54:05 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:54:05 INFO DAGScheduler: Missing parents: List()
17/03/18 10:54:05 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:197), which has no missing parents
17/03/18 10:54:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.0 KB, free 6.2 GB)
17/03/18 10:54:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.1 KB, free 6.2 GB)
17/03/18 10:54:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:38568 (size: 5.1 KB, free: 6.2 GB)
17/03/18 10:54:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/03/18 10:54:05 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at collect at utils.scala:197)
17/03/18 10:54:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 12 tasks
17/03/18 10:54:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 3, localhost, executor driver, partition 1, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 4, localhost, executor driver, partition 2, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 5, localhost, executor driver, partition 3, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 6, localhost, executor driver, partition 4, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 5.0 in stage 2.0 (TID 7, localhost, executor driver, partition 5, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 6.0 in stage 2.0 (TID 8, localhost, executor driver, partition 6, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO TaskSetManager: Starting task 7.0 in stage 2.0 (TID 9, localhost, executor driver, partition 7, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/18 10:54:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 3)
17/03/18 10:54:05 INFO Executor: Running task 2.0 in stage 2.0 (TID 4)
17/03/18 10:54:05 INFO Executor: Running task 3.0 in stage 2.0 (TID 5)
17/03/18 10:54:05 INFO Executor: Running task 4.0 in stage 2.0 (TID 6)
17/03/18 10:54:05 INFO Executor: Running task 5.0 in stage 2.0 (TID 7)
17/03/18 10:54:05 INFO Executor: Running task 7.0 in stage 2.0 (TID 9)
17/03/18 10:54:05 INFO Executor: Running task 6.0 in stage 2.0 (TID 8)
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:54:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:05 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 10:54:06 INFO ContextCleaner: Cleaned accumulator 101
17/03/18 10:54:06 INFO ContextCleaner: Cleaned accumulator 100
17/03/18 10:54:06 INFO ContextCleaner: Cleaned accumulator 99
17/03/18 10:54:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:54:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:54:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:54:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:54:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:54:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:54:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:54:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:54:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:54:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:54:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:54:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:54:11 INFO Executor: Finished task 4.0 in stage 2.0 (TID 6). 5602 bytes result sent to driver
17/03/18 10:54:11 INFO TaskSetManager: Starting task 8.0 in stage 2.0 (TID 10, localhost, executor driver, partition 8, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:11 INFO Executor: Running task 8.0 in stage 2.0 (TID 10)
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:54:11 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 6) in 5529 ms on localhost (executor driver) (1/12)
17/03/18 10:54:11 INFO Executor: Finished task 2.0 in stage 2.0 (TID 4). 5515 bytes result sent to driver
17/03/18 10:54:11 INFO TaskSetManager: Starting task 9.0 in stage 2.0 (TID 11, localhost, executor driver, partition 9, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:11 INFO Executor: Running task 9.0 in stage 2.0 (TID 11)
17/03/18 10:54:11 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 4) in 5571 ms on localhost (executor driver) (2/12)
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:54:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 3). 5515 bytes result sent to driver
17/03/18 10:54:11 INFO TaskSetManager: Starting task 10.0 in stage 2.0 (TID 12, localhost, executor driver, partition 10, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 3) in 5636 ms on localhost (executor driver) (3/12)
17/03/18 10:54:11 INFO Executor: Running task 10.0 in stage 2.0 (TID 12)
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:54:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:54:12 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 5515 bytes result sent to driver
17/03/18 10:54:12 INFO TaskSetManager: Starting task 11.0 in stage 2.0 (TID 13, localhost, executor driver, partition 11, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:54:12 INFO Executor: Running task 11.0 in stage 2.0 (TID 13)
17/03/18 10:54:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 6660 ms on localhost (executor driver) (4/12)
17/03/18 10:54:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:54:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:54:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:54:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:54:12 INFO Executor: Finished task 6.0 in stage 2.0 (TID 8). 5602 bytes result sent to driver
17/03/18 10:54:12 INFO TaskSetManager: Finished task 6.0 in stage 2.0 (TID 8) in 7024 ms on localhost (executor driver) (5/12)
17/03/18 10:54:12 INFO Executor: Finished task 3.0 in stage 2.0 (TID 5). 5515 bytes result sent to driver
17/03/18 10:54:12 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 5) in 7034 ms on localhost (executor driver) (6/12)
17/03/18 10:54:12 INFO Executor: Finished task 7.0 in stage 2.0 (TID 9). 5515 bytes result sent to driver
17/03/18 10:54:12 INFO TaskSetManager: Finished task 7.0 in stage 2.0 (TID 9) in 7130 ms on localhost (executor driver) (7/12)
17/03/18 10:54:12 INFO Executor: Finished task 5.0 in stage 2.0 (TID 7). 5602 bytes result sent to driver
17/03/18 10:54:12 INFO TaskSetManager: Finished task 5.0 in stage 2.0 (TID 7) in 7167 ms on localhost (executor driver) (8/12)
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:54:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:54:14 INFO Executor: Finished task 9.0 in stage 2.0 (TID 11). 5515 bytes result sent to driver
17/03/18 10:54:14 INFO TaskSetManager: Finished task 9.0 in stage 2.0 (TID 11) in 2797 ms on localhost (executor driver) (9/12)
17/03/18 10:54:14 INFO Executor: Finished task 8.0 in stage 2.0 (TID 10). 5515 bytes result sent to driver
17/03/18 10:54:14 INFO TaskSetManager: Finished task 8.0 in stage 2.0 (TID 10) in 2991 ms on localhost (executor driver) (10/12)
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:54:14 INFO Executor: Finished task 11.0 in stage 2.0 (TID 13). 5515 bytes result sent to driver
17/03/18 10:54:14 INFO TaskSetManager: Finished task 11.0 in stage 2.0 (TID 13) in 2123 ms on localhost (executor driver) (11/12)
17/03/18 10:54:14 INFO Executor: Finished task 10.0 in stage 2.0 (TID 12). 5602 bytes result sent to driver
17/03/18 10:54:14 INFO TaskSetManager: Finished task 10.0 in stage 2.0 (TID 12) in 3236 ms on localhost (executor driver) (12/12)
17/03/18 10:54:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/18 10:54:14 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:197) finished in 8,873 s
17/03/18 10:54:14 INFO DAGScheduler: Job 2 finished: collect at utils.scala:197, took 8,881665 s
17/03/18 10:54:14 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:54:14 INFO DAGScheduler: Registering RDD 15 (collect at utils.scala:197)
17/03/18 10:54:14 INFO DAGScheduler: Registering RDD 18 (collect at utils.scala:197)
17/03/18 10:54:14 INFO DAGScheduler: Registering RDD 23 (collect at utils.scala:197)
17/03/18 10:54:14 INFO DAGScheduler: Got job 3 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:54:14 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:197)
17/03/18 10:54:14 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
17/03/18 10:54:14 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5)
17/03/18 10:54:14 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at collect at utils.scala:197), which has no missing parents
17/03/18 10:54:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.2 KB, free 6.2 GB)
17/03/18 10:54:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.6 KB, free 6.2 GB)
17/03/18 10:54:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:38568 (size: 6.6 KB, free: 6.2 GB)
17/03/18 10:54:14 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/03/18 10:54:14 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at collect at utils.scala:197)
17/03/18 10:54:14 INFO TaskSchedulerImpl: Adding task set 3.0 with 12 tasks
17/03/18 10:54:14 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 18, localhost, executor driver, partition 4, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 19, localhost, executor driver, partition 5, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 20, localhost, executor driver, partition 6, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 21, localhost, executor driver, partition 7, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:14 INFO Executor: Running task 0.0 in stage 3.0 (TID 14)
17/03/18 10:54:14 INFO Executor: Running task 1.0 in stage 3.0 (TID 15)
17/03/18 10:54:14 INFO Executor: Running task 2.0 in stage 3.0 (TID 16)
17/03/18 10:54:14 INFO Executor: Running task 3.0 in stage 3.0 (TID 17)
17/03/18 10:54:14 INFO Executor: Running task 5.0 in stage 3.0 (TID 19)
17/03/18 10:54:14 INFO Executor: Running task 7.0 in stage 3.0 (TID 21)
17/03/18 10:54:14 INFO Executor: Running task 6.0 in stage 3.0 (TID 20)
17/03/18 10:54:14 INFO Executor: Running task 4.0 in stage 3.0 (TID 18)
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:54:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:54:15 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:38568 in memory (size: 5.1 KB, free: 6.2 GB)
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:54:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:54:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:54:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:54:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:54:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:54:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:54:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:54:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:54:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:54:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:54:19 INFO Executor: Finished task 2.0 in stage 3.0 (TID 16). 2066 bytes result sent to driver
17/03/18 10:54:19 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 22, localhost, executor driver, partition 8, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:19 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 16) in 5143 ms on localhost (executor driver) (1/12)
17/03/18 10:54:19 INFO Executor: Running task 8.0 in stage 3.0 (TID 22)
17/03/18 10:54:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:54:20 INFO Executor: Finished task 4.0 in stage 3.0 (TID 18). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 23, localhost, executor driver, partition 9, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:20 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 18) in 5523 ms on localhost (executor driver) (2/12)
17/03/18 10:54:20 INFO Executor: Running task 9.0 in stage 3.0 (TID 23)
17/03/18 10:54:20 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:54:20 INFO Executor: Finished task 5.0 in stage 3.0 (TID 19). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Starting task 10.0 in stage 3.0 (TID 24, localhost, executor driver, partition 10, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:20 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 19) in 5651 ms on localhost (executor driver) (3/12)
17/03/18 10:54:20 INFO Executor: Running task 10.0 in stage 3.0 (TID 24)
17/03/18 10:54:20 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:54:20 INFO Executor: Finished task 7.0 in stage 3.0 (TID 21). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Starting task 11.0 in stage 3.0 (TID 25, localhost, executor driver, partition 11, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:54:20 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 21) in 5777 ms on localhost (executor driver) (4/12)
17/03/18 10:54:20 INFO Executor: Running task 11.0 in stage 3.0 (TID 25)
17/03/18 10:54:20 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:54:20 INFO Executor: Finished task 3.0 in stage 3.0 (TID 17). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 17) in 5791 ms on localhost (executor driver) (5/12)
17/03/18 10:54:20 INFO Executor: Finished task 1.0 in stage 3.0 (TID 15). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 15) in 5897 ms on localhost (executor driver) (6/12)
17/03/18 10:54:20 INFO Executor: Finished task 6.0 in stage 3.0 (TID 20). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 20) in 5961 ms on localhost (executor driver) (7/12)
17/03/18 10:54:20 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:54:20 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:54:20 INFO Executor: Finished task 0.0 in stage 3.0 (TID 14). 1979 bytes result sent to driver
17/03/18 10:54:20 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 14) in 6271 ms on localhost (executor driver) (8/12)
17/03/18 10:54:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:54:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:54:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:54:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:54:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:54:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:54:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:54:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:54:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:54:22 INFO Executor: Finished task 11.0 in stage 3.0 (TID 25). 1979 bytes result sent to driver
17/03/18 10:54:22 INFO TaskSetManager: Finished task 11.0 in stage 3.0 (TID 25) in 2180 ms on localhost (executor driver) (9/12)
17/03/18 10:54:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:54:22 INFO Executor: Finished task 8.0 in stage 3.0 (TID 22). 1979 bytes result sent to driver
17/03/18 10:54:22 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 22) in 3193 ms on localhost (executor driver) (10/12)
17/03/18 10:54:23 INFO Executor: Finished task 9.0 in stage 3.0 (TID 23). 1979 bytes result sent to driver
17/03/18 10:54:23 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 23) in 2878 ms on localhost (executor driver) (11/12)
17/03/18 10:54:23 INFO Executor: Finished task 10.0 in stage 3.0 (TID 24). 1979 bytes result sent to driver
17/03/18 10:54:23 INFO TaskSetManager: Finished task 10.0 in stage 3.0 (TID 24) in 3149 ms on localhost (executor driver) (12/12)
17/03/18 10:54:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/18 10:54:23 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:197) finished in 8,806 s
17/03/18 10:54:23 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:54:23 INFO DAGScheduler: running: Set()
17/03/18 10:54:23 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/18 10:54:23 INFO DAGScheduler: failed: Set()
17/03/18 10:54:23 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at collect at utils.scala:197), which has no missing parents
17/03/18 10:54:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.9 KB, free 6.2 GB)
17/03/18 10:54:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.5 KB, free 6.2 GB)
17/03/18 10:54:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:38568 (size: 7.5 KB, free: 6.2 GB)
17/03/18 10:54:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/03/18 10:54:23 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at collect at utils.scala:197)
17/03/18 10:54:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 8 tasks
17/03/18 10:54:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 26, localhost, executor driver, partition 0, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 27, localhost, executor driver, partition 1, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 28, localhost, executor driver, partition 2, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 29, localhost, executor driver, partition 3, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 30, localhost, executor driver, partition 4, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 31, localhost, executor driver, partition 5, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 32, localhost, executor driver, partition 6, ANY, 5934 bytes)
17/03/18 10:54:23 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 33, localhost, executor driver, partition 7, ANY, 5934 bytes)
17/03/18 10:54:23 INFO Executor: Running task 1.0 in stage 4.0 (TID 27)
17/03/18 10:54:23 INFO Executor: Running task 4.0 in stage 4.0 (TID 30)
17/03/18 10:54:23 INFO Executor: Running task 3.0 in stage 4.0 (TID 29)
17/03/18 10:54:23 INFO Executor: Running task 2.0 in stage 4.0 (TID 28)
17/03/18 10:54:23 INFO Executor: Running task 5.0 in stage 4.0 (TID 31)
17/03/18 10:54:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 26)
17/03/18 10:54:23 INFO Executor: Running task 7.0 in stage 4.0 (TID 33)
17/03/18 10:54:23 INFO Executor: Running task 6.0 in stage 4.0 (TID 32)
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 9 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 9 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 9 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 12 blocks
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/03/18 10:54:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 10:54:23 INFO CodeGenerator: Code generated in 13.335893 ms
17/03/18 10:54:23 INFO CodeGenerator: Code generated in 8.590979 ms
17/03/18 10:54:24 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:38568 in memory (size: 6.6 KB, free: 6.2 GB)
17/03/18 10:54:26 INFO UnsafeExternalSorter: Thread 111 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 10:54:26 INFO UnsafeExternalSorter: Thread 110 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 10:54:26 INFO UnsafeExternalSorter: Thread 114 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 10:54:30 INFO Executor: Finished task 1.0 in stage 4.0 (TID 27). 2911 bytes result sent to driver
17/03/18 10:54:30 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 27) in 7163 ms on localhost (executor driver) (1/8)
17/03/18 10:54:30 INFO Executor: Finished task 3.0 in stage 4.0 (TID 29). 2911 bytes result sent to driver
17/03/18 10:54:30 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 29) in 7231 ms on localhost (executor driver) (2/8)
17/03/18 10:54:30 INFO Executor: Finished task 7.0 in stage 4.0 (TID 33). 2911 bytes result sent to driver
17/03/18 10:54:30 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 33) in 7334 ms on localhost (executor driver) (3/8)
17/03/18 10:54:32 INFO Executor: Finished task 6.0 in stage 4.0 (TID 32). 2911 bytes result sent to driver
17/03/18 10:54:32 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 32) in 8659 ms on localhost (executor driver) (4/8)
17/03/18 10:54:32 INFO Executor: Finished task 4.0 in stage 4.0 (TID 30). 2998 bytes result sent to driver
17/03/18 10:54:32 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 30) in 8683 ms on localhost (executor driver) (5/8)
17/03/18 10:54:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 26). 2993 bytes result sent to driver
17/03/18 10:54:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 26) in 11493 ms on localhost (executor driver) (6/8)
17/03/18 10:54:35 INFO Executor: Finished task 2.0 in stage 4.0 (TID 28). 2993 bytes result sent to driver
17/03/18 10:54:35 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 28) in 11996 ms on localhost (executor driver) (7/8)
17/03/18 10:54:36 INFO Executor: Finished task 5.0 in stage 4.0 (TID 31). 2993 bytes result sent to driver
17/03/18 10:54:36 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 31) in 12912 ms on localhost (executor driver) (8/8)
17/03/18 10:54:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/18 10:54:36 INFO DAGScheduler: ShuffleMapStage 4 (collect at utils.scala:197) finished in 12,916 s
17/03/18 10:54:36 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:54:36 INFO DAGScheduler: running: Set()
17/03/18 10:54:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/18 10:54:36 INFO DAGScheduler: failed: Set()
17/03/18 10:54:36 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at collect at utils.scala:197), which has no missing parents
17/03/18 10:54:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:54:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 10.2 KB, free 6.2 GB)
17/03/18 10:54:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:38568 (size: 10.2 KB, free: 6.2 GB)
17/03/18 10:54:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/03/18 10:54:36 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at collect at utils.scala:197)
17/03/18 10:54:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 8 tasks
17/03/18 10:54:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 34, localhost, executor driver, partition 0, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 35, localhost, executor driver, partition 1, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 36, localhost, executor driver, partition 2, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 37, localhost, executor driver, partition 3, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 38, localhost, executor driver, partition 4, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 39, localhost, executor driver, partition 5, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 40, localhost, executor driver, partition 6, ANY, 5934 bytes)
17/03/18 10:54:36 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 41, localhost, executor driver, partition 7, ANY, 5934 bytes)
17/03/18 10:54:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 34)
17/03/18 10:54:36 INFO Executor: Running task 1.0 in stage 5.0 (TID 35)
17/03/18 10:54:36 INFO Executor: Running task 2.0 in stage 5.0 (TID 36)
17/03/18 10:54:36 INFO Executor: Running task 3.0 in stage 5.0 (TID 37)
17/03/18 10:54:36 INFO Executor: Running task 5.0 in stage 5.0 (TID 39)
17/03/18 10:54:36 INFO Executor: Running task 6.0 in stage 5.0 (TID 40)
17/03/18 10:54:36 INFO Executor: Running task 4.0 in stage 5.0 (TID 38)
17/03/18 10:54:36 INFO Executor: Running task 7.0 in stage 5.0 (TID 41)
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:54:36 INFO CodeGenerator: Code generated in 9.97235 ms
17/03/18 10:54:36 INFO CodeGenerator: Code generated in 7.95347 ms
17/03/18 10:54:36 INFO CodeGenerator: Code generated in 7.499146 ms
17/03/18 10:54:36 INFO CodeGenerator: Code generated in 8.163478 ms
17/03/18 10:54:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:38568 in memory (size: 7.5 KB, free: 6.2 GB)
17/03/18 10:54:50 INFO CodeGenerator: Code generated in 7.460037 ms
17/03/18 10:54:50 INFO CodeGenerator: Code generated in 18.431152 ms
17/03/18 10:54:56 INFO Executor: Finished task 7.0 in stage 5.0 (TID 41). 3671 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 41) in 20359 ms on localhost (executor driver) (1/8)
17/03/18 10:54:56 INFO Executor: Finished task 5.0 in stage 5.0 (TID 39). 3671 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 39) in 20387 ms on localhost (executor driver) (2/8)
17/03/18 10:54:56 INFO Executor: Finished task 3.0 in stage 5.0 (TID 37). 3671 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 37) in 20447 ms on localhost (executor driver) (3/8)
17/03/18 10:54:56 INFO Executor: Finished task 2.0 in stage 5.0 (TID 36). 3671 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 36) in 20458 ms on localhost (executor driver) (4/8)
17/03/18 10:54:56 INFO Executor: Finished task 4.0 in stage 5.0 (TID 38). 3758 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 38) in 20521 ms on localhost (executor driver) (5/8)
17/03/18 10:54:56 INFO Executor: Finished task 6.0 in stage 5.0 (TID 40). 3671 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 40) in 20543 ms on localhost (executor driver) (6/8)
17/03/18 10:54:56 INFO Executor: Finished task 0.0 in stage 5.0 (TID 34). 3671 bytes result sent to driver
17/03/18 10:54:56 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 34) in 20584 ms on localhost (executor driver) (7/8)
17/03/18 10:54:57 INFO Executor: Finished task 1.0 in stage 5.0 (TID 35). 3671 bytes result sent to driver
17/03/18 10:54:57 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 35) in 20608 ms on localhost (executor driver) (8/8)
17/03/18 10:54:57 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/18 10:54:57 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:197) finished in 20,610 s
17/03/18 10:54:57 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:54:57 INFO DAGScheduler: running: Set()
17/03/18 10:54:57 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/03/18 10:54:57 INFO DAGScheduler: failed: Set()
17/03/18 10:54:57 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:197), which has no missing parents
17/03/18 10:54:57 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:54:57 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:54:57 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:54:57 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/03/18 10:54:57 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[26] at collect at utils.scala:197)
17/03/18 10:54:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/03/18 10:54:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 42, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/03/18 10:54:57 INFO Executor: Running task 0.0 in stage 6.0 (TID 42)
17/03/18 10:54:57 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:54:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:54:57 INFO Executor: Finished task 0.0 in stage 6.0 (TID 42). 2042 bytes result sent to driver
17/03/18 10:54:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 42) in 4 ms on localhost (executor driver) (1/1)
17/03/18 10:54:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/18 10:54:57 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:197) finished in 0,005 s
17/03/18 10:54:57 INFO DAGScheduler: Job 3 finished: collect at utils.scala:197, took 42,387343 s
17/03/18 10:54:57 INFO CodeGenerator: Code generated in 4.889213 ms
17/03/18 10:55:06 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM (SELECT *
FROM (SELECT `device_id`, `device_ip`, `int_day`, `int_hour`, `int_hour` - LAG(`int_hour`, 1, NULL) OVER (PARTITION BY `device_id`, `device_ip`, `int_day` ORDER BY "int_hour") AS `dt_hour`
FROM (SELECT `device_id` AS `device_id`, `device_ip` AS `device_ip`, `int_day` AS `int_day`, `int_hour` AS `int_hour`
FROM (SELECT *
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, `int_day`, SUBSTR(`hour`, 7.0, 2.0) AS `int_hour`
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, SUBSTR(`hour`, 5.0, 2.0) AS `int_day`
FROM `train`) `loshlhmqzg`) `uhpjtwxyzb`
ORDER BY `int_hour`) `szlmmydeej`) `howjvqpzot`) `ohfvyhfhbz`
WHERE ((`dt_hour`) IS NULL)) `umrlegxsun`
17/03/18 10:55:06 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:55:06 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:55:06 INFO FileSourceStrategy: Output Data Schema: struct<hour: int, device_id: string, device_ip: string ... 1 more fields>
17/03/18 10:55:06 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:55:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 297.7 KB, free 6.2 GB)
17/03/18 10:55:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.3 KB, free 6.2 GB)
17/03/18 10:55:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:38568 (size: 24.3 KB, free: 6.2 GB)
17/03/18 10:55:06 INFO SparkContext: Created broadcast 8 from collect at utils.scala:197
17/03/18 10:55:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:55:06 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:55:06 INFO DAGScheduler: Got job 4 (collect at utils.scala:197) with 12 output partitions
17/03/18 10:55:06 INFO DAGScheduler: Final stage: ResultStage 7 (collect at utils.scala:197)
17/03/18 10:55:06 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:55:06 INFO DAGScheduler: Missing parents: List()
17/03/18 10:55:06 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[31] at collect at utils.scala:197), which has no missing parents
17/03/18 10:55:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.0 KB, free 6.2 GB)
17/03/18 10:55:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.1 KB, free 6.2 GB)
17/03/18 10:55:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:38568 (size: 5.1 KB, free: 6.2 GB)
17/03/18 10:55:06 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/03/18 10:55:06 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 7 (MapPartitionsRDD[31] at collect at utils.scala:197)
17/03/18 10:55:06 INFO TaskSchedulerImpl: Adding task set 7.0 with 12 tasks
17/03/18 10:55:06 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 44, localhost, executor driver, partition 1, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 45, localhost, executor driver, partition 2, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 46, localhost, executor driver, partition 3, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 47, localhost, executor driver, partition 4, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 48, localhost, executor driver, partition 5, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 49, localhost, executor driver, partition 6, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 50, localhost, executor driver, partition 7, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:06 INFO Executor: Running task 0.0 in stage 7.0 (TID 43)
17/03/18 10:55:06 INFO Executor: Running task 3.0 in stage 7.0 (TID 46)
17/03/18 10:55:06 INFO Executor: Running task 1.0 in stage 7.0 (TID 44)
17/03/18 10:55:06 INFO Executor: Running task 2.0 in stage 7.0 (TID 45)
17/03/18 10:55:06 INFO Executor: Running task 7.0 in stage 7.0 (TID 50)
17/03/18 10:55:06 INFO Executor: Running task 4.0 in stage 7.0 (TID 47)
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:55:06 INFO Executor: Running task 5.0 in stage 7.0 (TID 48)
17/03/18 10:55:06 INFO Executor: Running task 6.0 in stage 7.0 (TID 49)
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:55:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:55:07 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:55:07 INFO ContextCleaner: Cleaned accumulator 1231
17/03/18 10:55:07 INFO ContextCleaner: Cleaned accumulator 1232
17/03/18 10:55:07 INFO ContextCleaner: Cleaned accumulator 1233
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:55:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:55:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:55:09 INFO Executor: Finished task 4.0 in stage 7.0 (TID 47). 5515 bytes result sent to driver
17/03/18 10:55:09 INFO TaskSetManager: Starting task 8.0 in stage 7.0 (TID 51, localhost, executor driver, partition 8, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:09 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 47) in 3268 ms on localhost (executor driver) (1/12)
17/03/18 10:55:09 INFO Executor: Running task 8.0 in stage 7.0 (TID 51)
17/03/18 10:55:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:55:10 INFO Executor: Finished task 3.0 in stage 7.0 (TID 46). 5515 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Starting task 9.0 in stage 7.0 (TID 52, localhost, executor driver, partition 9, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:10 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 46) in 3357 ms on localhost (executor driver) (2/12)
17/03/18 10:55:10 INFO Executor: Running task 9.0 in stage 7.0 (TID 52)
17/03/18 10:55:10 INFO Executor: Finished task 2.0 in stage 7.0 (TID 45). 5602 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Starting task 10.0 in stage 7.0 (TID 53, localhost, executor driver, partition 10, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:10 INFO Executor: Running task 10.0 in stage 7.0 (TID 53)
17/03/18 10:55:10 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 45) in 3363 ms on localhost (executor driver) (3/12)
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:55:10 INFO Executor: Finished task 1.0 in stage 7.0 (TID 44). 5515 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Starting task 11.0 in stage 7.0 (TID 54, localhost, executor driver, partition 11, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:55:10 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 44) in 3389 ms on localhost (executor driver) (4/12)
17/03/18 10:55:10 INFO Executor: Running task 11.0 in stage 7.0 (TID 54)
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:55:10 INFO Executor: Finished task 7.0 in stage 7.0 (TID 50). 5515 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 50) in 3403 ms on localhost (executor driver) (5/12)
17/03/18 10:55:10 INFO Executor: Finished task 5.0 in stage 7.0 (TID 48). 5602 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 48) in 3406 ms on localhost (executor driver) (6/12)
17/03/18 10:55:10 INFO Executor: Finished task 0.0 in stage 7.0 (TID 43). 5515 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 43) in 3437 ms on localhost (executor driver) (7/12)
17/03/18 10:55:10 INFO Executor: Finished task 6.0 in stage 7.0 (TID 49). 5515 bytes result sent to driver
17/03/18 10:55:10 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 49) in 3590 ms on localhost (executor driver) (8/12)
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:55:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:55:11 INFO Executor: Finished task 11.0 in stage 7.0 (TID 54). 5515 bytes result sent to driver
17/03/18 10:55:11 INFO TaskSetManager: Finished task 11.0 in stage 7.0 (TID 54) in 1512 ms on localhost (executor driver) (9/12)
17/03/18 10:55:11 INFO Executor: Finished task 9.0 in stage 7.0 (TID 52). 5515 bytes result sent to driver
17/03/18 10:55:11 INFO TaskSetManager: Finished task 9.0 in stage 7.0 (TID 52) in 1803 ms on localhost (executor driver) (10/12)
17/03/18 10:55:11 INFO Executor: Finished task 10.0 in stage 7.0 (TID 53). 5515 bytes result sent to driver
17/03/18 10:55:11 INFO TaskSetManager: Finished task 10.0 in stage 7.0 (TID 53) in 1811 ms on localhost (executor driver) (11/12)
17/03/18 10:55:11 INFO Executor: Finished task 8.0 in stage 7.0 (TID 51). 5602 bytes result sent to driver
17/03/18 10:55:11 INFO TaskSetManager: Finished task 8.0 in stage 7.0 (TID 51) in 1993 ms on localhost (executor driver) (12/12)
17/03/18 10:55:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/18 10:55:11 INFO DAGScheduler: ResultStage 7 (collect at utils.scala:197) finished in 5,262 s
17/03/18 10:55:11 INFO DAGScheduler: Job 4 finished: collect at utils.scala:197, took 5,267214 s
17/03/18 10:55:11 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:55:11 INFO DAGScheduler: Registering RDD 32 (collect at utils.scala:197)
17/03/18 10:55:11 INFO DAGScheduler: Registering RDD 35 (collect at utils.scala:197)
17/03/18 10:55:11 INFO DAGScheduler: Registering RDD 40 (collect at utils.scala:197)
17/03/18 10:55:11 INFO DAGScheduler: Got job 5 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:55:11 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:197)
17/03/18 10:55:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
17/03/18 10:55:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 10)
17/03/18 10:55:11 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[32] at collect at utils.scala:197), which has no missing parents
17/03/18 10:55:11 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 14.2 KB, free 6.2 GB)
17/03/18 10:55:11 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 6.6 KB, free 6.2 GB)
17/03/18 10:55:11 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:38568 (size: 6.6 KB, free: 6.2 GB)
17/03/18 10:55:11 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/03/18 10:55:11 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[32] at collect at utils.scala:197)
17/03/18 10:55:11 INFO TaskSchedulerImpl: Adding task set 8.0 with 12 tasks
17/03/18 10:55:11 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 55, localhost, executor driver, partition 0, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 56, localhost, executor driver, partition 1, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 57, localhost, executor driver, partition 2, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 58, localhost, executor driver, partition 3, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 59, localhost, executor driver, partition 4, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 60, localhost, executor driver, partition 5, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 61, localhost, executor driver, partition 6, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 62, localhost, executor driver, partition 7, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:11 INFO Executor: Running task 2.0 in stage 8.0 (TID 57)
17/03/18 10:55:11 INFO Executor: Running task 4.0 in stage 8.0 (TID 59)
17/03/18 10:55:11 INFO Executor: Running task 1.0 in stage 8.0 (TID 56)
17/03/18 10:55:11 INFO Executor: Running task 3.0 in stage 8.0 (TID 58)
17/03/18 10:55:11 INFO Executor: Running task 6.0 in stage 8.0 (TID 61)
17/03/18 10:55:11 INFO Executor: Running task 5.0 in stage 8.0 (TID 60)
17/03/18 10:55:11 INFO Executor: Running task 7.0 in stage 8.0 (TID 62)
17/03/18 10:55:11 INFO Executor: Running task 0.0 in stage 8.0 (TID 55)
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:55:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:55:12 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:38568 in memory (size: 5.1 KB, free: 6.2 GB)
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:55:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:55:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:55:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:55:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:55:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:55:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:55:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:55:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:55:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:55:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:55:16 INFO Executor: Finished task 2.0 in stage 8.0 (TID 57). 1979 bytes result sent to driver
17/03/18 10:55:16 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 63, localhost, executor driver, partition 8, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:16 INFO Executor: Running task 8.0 in stage 8.0 (TID 63)
17/03/18 10:55:16 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 57) in 4633 ms on localhost (executor driver) (1/12)
17/03/18 10:55:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:55:17 INFO Executor: Finished task 7.0 in stage 8.0 (TID 62). 1979 bytes result sent to driver
17/03/18 10:55:17 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 64, localhost, executor driver, partition 9, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:17 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 62) in 5131 ms on localhost (executor driver) (2/12)
17/03/18 10:55:17 INFO Executor: Running task 9.0 in stage 8.0 (TID 64)
17/03/18 10:55:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:55:17 INFO Executor: Finished task 5.0 in stage 8.0 (TID 60). 1979 bytes result sent to driver
17/03/18 10:55:17 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 65, localhost, executor driver, partition 10, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:17 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 60) in 5155 ms on localhost (executor driver) (3/12)
17/03/18 10:55:17 INFO Executor: Running task 10.0 in stage 8.0 (TID 65)
17/03/18 10:55:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:55:17 INFO Executor: Finished task 4.0 in stage 8.0 (TID 59). 1979 bytes result sent to driver
17/03/18 10:55:17 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 66, localhost, executor driver, partition 11, PROCESS_LOCAL, 7078 bytes)
17/03/18 10:55:17 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 59) in 5195 ms on localhost (executor driver) (4/12)
17/03/18 10:55:17 INFO Executor: Running task 11.0 in stage 8.0 (TID 66)
17/03/18 10:55:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:55:17 INFO Executor: Finished task 1.0 in stage 8.0 (TID 56). 1979 bytes result sent to driver
17/03/18 10:55:17 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 56) in 5481 ms on localhost (executor driver) (5/12)
17/03/18 10:55:17 INFO Executor: Finished task 6.0 in stage 8.0 (TID 61). 1979 bytes result sent to driver
17/03/18 10:55:17 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 61) in 5507 ms on localhost (executor driver) (6/12)
17/03/18 10:55:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:55:17 INFO Executor: Finished task 0.0 in stage 8.0 (TID 55). 1979 bytes result sent to driver
17/03/18 10:55:17 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 55) in 5813 ms on localhost (executor driver) (7/12)
17/03/18 10:55:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:55:18 INFO Executor: Finished task 3.0 in stage 8.0 (TID 58). 1979 bytes result sent to driver
17/03/18 10:55:18 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 58) in 6096 ms on localhost (executor driver) (8/12)
17/03/18 10:55:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:55:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:55:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:55:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:55:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:55:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:55:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:55:19 INFO Executor: Finished task 8.0 in stage 8.0 (TID 63). 1979 bytes result sent to driver
17/03/18 10:55:19 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 63) in 2986 ms on localhost (executor driver) (9/12)
17/03/18 10:55:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:55:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:55:20 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:55:20 INFO Executor: Finished task 11.0 in stage 8.0 (TID 66). 1979 bytes result sent to driver
17/03/18 10:55:20 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 66) in 3102 ms on localhost (executor driver) (10/12)
17/03/18 10:55:20 INFO Executor: Finished task 10.0 in stage 8.0 (TID 65). 1979 bytes result sent to driver
17/03/18 10:55:20 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 65) in 3311 ms on localhost (executor driver) (11/12)
17/03/18 10:55:20 INFO Executor: Finished task 9.0 in stage 8.0 (TID 64). 1979 bytes result sent to driver
17/03/18 10:55:20 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 64) in 3481 ms on localhost (executor driver) (12/12)
17/03/18 10:55:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/18 10:55:20 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:197) finished in 8,613 s
17/03/18 10:55:20 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:55:20 INFO DAGScheduler: running: Set()
17/03/18 10:55:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 9, ShuffleMapStage 10, ResultStage 11)
17/03/18 10:55:20 INFO DAGScheduler: failed: Set()
17/03/18 10:55:20 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[35] at collect at utils.scala:197), which has no missing parents
17/03/18 10:55:20 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 14.9 KB, free 6.2 GB)
17/03/18 10:55:20 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 7.5 KB, free 6.2 GB)
17/03/18 10:55:20 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:38568 (size: 7.5 KB, free: 6.2 GB)
17/03/18 10:55:20 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/03/18 10:55:20 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[35] at collect at utils.scala:197)
17/03/18 10:55:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 8 tasks
17/03/18 10:55:20 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 67, localhost, executor driver, partition 0, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 68, localhost, executor driver, partition 1, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 69, localhost, executor driver, partition 2, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 70, localhost, executor driver, partition 3, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 71, localhost, executor driver, partition 4, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 5.0 in stage 9.0 (TID 72, localhost, executor driver, partition 5, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 6.0 in stage 9.0 (TID 73, localhost, executor driver, partition 6, ANY, 5934 bytes)
17/03/18 10:55:20 INFO TaskSetManager: Starting task 7.0 in stage 9.0 (TID 74, localhost, executor driver, partition 7, ANY, 5934 bytes)
17/03/18 10:55:20 INFO Executor: Running task 0.0 in stage 9.0 (TID 67)
17/03/18 10:55:20 INFO Executor: Running task 1.0 in stage 9.0 (TID 68)
17/03/18 10:55:20 INFO Executor: Running task 4.0 in stage 9.0 (TID 71)
17/03/18 10:55:20 INFO Executor: Running task 7.0 in stage 9.0 (TID 74)
17/03/18 10:55:20 INFO Executor: Running task 5.0 in stage 9.0 (TID 72)
17/03/18 10:55:20 INFO Executor: Running task 2.0 in stage 9.0 (TID 69)
17/03/18 10:55:20 INFO Executor: Running task 6.0 in stage 9.0 (TID 73)
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:20 INFO Executor: Running task 3.0 in stage 9.0 (TID 70)
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 9 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 9 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 9 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 12 blocks
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
17/03/18 10:55:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/03/18 10:55:22 INFO UnsafeExternalSorter: Thread 109 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 10:55:22 INFO UnsafeExternalSorter: Thread 112 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 10:55:22 INFO UnsafeExternalSorter: Thread 110 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 10:55:23 INFO Executor: Finished task 7.0 in stage 9.0 (TID 74). 2838 bytes result sent to driver
17/03/18 10:55:23 INFO TaskSetManager: Finished task 7.0 in stage 9.0 (TID 74) in 3035 ms on localhost (executor driver) (1/8)
17/03/18 10:55:23 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:38568 in memory (size: 6.6 KB, free: 6.2 GB)
17/03/18 10:55:23 INFO Executor: Finished task 1.0 in stage 9.0 (TID 68). 2911 bytes result sent to driver
17/03/18 10:55:23 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 68) in 3367 ms on localhost (executor driver) (2/8)
17/03/18 10:55:24 INFO Executor: Finished task 3.0 in stage 9.0 (TID 70). 2911 bytes result sent to driver
17/03/18 10:55:24 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 70) in 3905 ms on localhost (executor driver) (3/8)
17/03/18 10:55:25 INFO Executor: Finished task 6.0 in stage 9.0 (TID 73). 2911 bytes result sent to driver
17/03/18 10:55:25 INFO TaskSetManager: Finished task 6.0 in stage 9.0 (TID 73) in 4595 ms on localhost (executor driver) (4/8)
17/03/18 10:55:25 INFO Executor: Finished task 5.0 in stage 9.0 (TID 72). 2911 bytes result sent to driver
17/03/18 10:55:25 INFO TaskSetManager: Finished task 5.0 in stage 9.0 (TID 72) in 4617 ms on localhost (executor driver) (5/8)
17/03/18 10:55:26 INFO Executor: Finished task 2.0 in stage 9.0 (TID 69). 2993 bytes result sent to driver
17/03/18 10:55:26 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 69) in 6358 ms on localhost (executor driver) (6/8)
17/03/18 10:55:26 INFO Executor: Finished task 0.0 in stage 9.0 (TID 67). 2993 bytes result sent to driver
17/03/18 10:55:26 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 67) in 6405 ms on localhost (executor driver) (7/8)
17/03/18 10:55:27 INFO Executor: Finished task 4.0 in stage 9.0 (TID 71). 2993 bytes result sent to driver
17/03/18 10:55:27 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 71) in 6717 ms on localhost (executor driver) (8/8)
17/03/18 10:55:27 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/18 10:55:27 INFO DAGScheduler: ShuffleMapStage 9 (collect at utils.scala:197) finished in 6,718 s
17/03/18 10:55:27 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:55:27 INFO DAGScheduler: running: Set()
17/03/18 10:55:27 INFO DAGScheduler: waiting: Set(ShuffleMapStage 10, ResultStage 11)
17/03/18 10:55:27 INFO DAGScheduler: failed: Set()
17/03/18 10:55:27 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[40] at collect at utils.scala:197), which has no missing parents
17/03/18 10:55:27 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 23.1 KB, free 6.2 GB)
17/03/18 10:55:27 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 10.2 KB, free 6.2 GB)
17/03/18 10:55:27 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:38568 (size: 10.2 KB, free: 6.2 GB)
17/03/18 10:55:27 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/03/18 10:55:27 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[40] at collect at utils.scala:197)
17/03/18 10:55:27 INFO TaskSchedulerImpl: Adding task set 10.0 with 8 tasks
17/03/18 10:55:27 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 75, localhost, executor driver, partition 0, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 76, localhost, executor driver, partition 1, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 77, localhost, executor driver, partition 2, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 78, localhost, executor driver, partition 3, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 79, localhost, executor driver, partition 4, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 5.0 in stage 10.0 (TID 80, localhost, executor driver, partition 5, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 6.0 in stage 10.0 (TID 81, localhost, executor driver, partition 6, ANY, 5934 bytes)
17/03/18 10:55:27 INFO TaskSetManager: Starting task 7.0 in stage 10.0 (TID 82, localhost, executor driver, partition 7, ANY, 5934 bytes)
17/03/18 10:55:27 INFO Executor: Running task 1.0 in stage 10.0 (TID 76)
17/03/18 10:55:27 INFO Executor: Running task 5.0 in stage 10.0 (TID 80)
17/03/18 10:55:27 INFO Executor: Running task 4.0 in stage 10.0 (TID 79)
17/03/18 10:55:27 INFO Executor: Running task 6.0 in stage 10.0 (TID 81)
17/03/18 10:55:27 INFO Executor: Running task 3.0 in stage 10.0 (TID 78)
17/03/18 10:55:27 INFO Executor: Running task 2.0 in stage 10.0 (TID 77)
17/03/18 10:55:27 INFO Executor: Running task 0.0 in stage 10.0 (TID 75)
17/03/18 10:55:27 INFO Executor: Running task 7.0 in stage 10.0 (TID 82)
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:43 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:38568 in memory (size: 7.5 KB, free: 6.2 GB)
17/03/18 10:55:49 INFO Executor: Finished task 5.0 in stage 10.0 (TID 80). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 5.0 in stage 10.0 (TID 80) in 21933 ms on localhost (executor driver) (1/8)
17/03/18 10:55:49 INFO Executor: Finished task 3.0 in stage 10.0 (TID 78). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 78) in 21978 ms on localhost (executor driver) (2/8)
17/03/18 10:55:49 INFO Executor: Finished task 7.0 in stage 10.0 (TID 82). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 7.0 in stage 10.0 (TID 82) in 22098 ms on localhost (executor driver) (3/8)
17/03/18 10:55:49 INFO Executor: Finished task 1.0 in stage 10.0 (TID 76). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 76) in 22283 ms on localhost (executor driver) (4/8)
17/03/18 10:55:49 INFO Executor: Finished task 2.0 in stage 10.0 (TID 77). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 77) in 22392 ms on localhost (executor driver) (5/8)
17/03/18 10:55:49 INFO Executor: Finished task 4.0 in stage 10.0 (TID 79). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 79) in 22534 ms on localhost (executor driver) (6/8)
17/03/18 10:55:49 INFO Executor: Finished task 0.0 in stage 10.0 (TID 75). 3671 bytes result sent to driver
17/03/18 10:55:49 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 75) in 22661 ms on localhost (executor driver) (7/8)
17/03/18 10:55:50 INFO Executor: Finished task 6.0 in stage 10.0 (TID 81). 3671 bytes result sent to driver
17/03/18 10:55:50 INFO TaskSetManager: Finished task 6.0 in stage 10.0 (TID 81) in 23104 ms on localhost (executor driver) (8/8)
17/03/18 10:55:50 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/18 10:55:50 INFO DAGScheduler: ShuffleMapStage 10 (collect at utils.scala:197) finished in 23,106 s
17/03/18 10:55:50 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:55:50 INFO DAGScheduler: running: Set()
17/03/18 10:55:50 INFO DAGScheduler: waiting: Set(ResultStage 11)
17/03/18 10:55:50 INFO DAGScheduler: failed: Set()
17/03/18 10:55:50 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[43] at collect at utils.scala:197), which has no missing parents
17/03/18 10:55:50 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:55:50 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:55:50 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:55:50 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/03/18 10:55:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[43] at collect at utils.scala:197)
17/03/18 10:55:50 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/03/18 10:55:50 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 83, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/03/18 10:55:50 INFO Executor: Running task 0.0 in stage 11.0 (TID 83)
17/03/18 10:55:50 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:55:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:55:50 INFO Executor: Finished task 0.0 in stage 11.0 (TID 83). 2042 bytes result sent to driver
17/03/18 10:55:50 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 83) in 4 ms on localhost (executor driver) (1/1)
17/03/18 10:55:50 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/03/18 10:55:50 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:197) finished in 0,004 s
17/03/18 10:55:50 INFO DAGScheduler: Job 5 finished: collect at utils.scala:197, took 38,459912 s
17/03/18 10:56:30 INFO SparkSqlParser: Parsing command: SELECT `banner_pos`, count(*) AS `cnt`
FROM `train`
GROUP BY `banner_pos`
17/03/18 10:56:30 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:56:30 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:56:30 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 10:56:30 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:56:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
17/03/18 10:56:30 INFO CodeGenerator: Code generated in 35.449475 ms
17/03/18 10:56:30 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
17/03/18 10:56:30 INFO CodeGenerator: Code generated in 19.731039 ms
17/03/18 10:56:30 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 10:56:30 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 10:56:30 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 10:56:30 INFO SparkContext: Created broadcast 14 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:56:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:56:30 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:56:30 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:30 INFO DAGScheduler: Registering RDD 49 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:30 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:56:30 INFO DAGScheduler: Final stage: ResultStage 14 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/03/18 10:56:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/03/18 10:56:30 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:56:30 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 17.2 KB, free 6.2 GB)
17/03/18 10:56:30 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 8.0 KB, free 6.2 GB)
17/03/18 10:56:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:38568 (size: 8.0 KB, free: 6.2 GB)
17/03/18 10:56:30 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:30 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:30 INFO TaskSchedulerImpl: Adding task set 12.0 with 12 tasks
17/03/18 10:56:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 84, localhost, executor driver, partition 0, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 85, localhost, executor driver, partition 1, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 86, localhost, executor driver, partition 2, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 3.0 in stage 12.0 (TID 87, localhost, executor driver, partition 3, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 4.0 in stage 12.0 (TID 88, localhost, executor driver, partition 4, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 5.0 in stage 12.0 (TID 89, localhost, executor driver, partition 5, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 6.0 in stage 12.0 (TID 90, localhost, executor driver, partition 6, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO TaskSetManager: Starting task 7.0 in stage 12.0 (TID 91, localhost, executor driver, partition 7, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:30 INFO Executor: Running task 1.0 in stage 12.0 (TID 85)
17/03/18 10:56:30 INFO Executor: Running task 6.0 in stage 12.0 (TID 90)
17/03/18 10:56:30 INFO Executor: Running task 5.0 in stage 12.0 (TID 89)
17/03/18 10:56:30 INFO Executor: Running task 4.0 in stage 12.0 (TID 88)
17/03/18 10:56:30 INFO Executor: Running task 7.0 in stage 12.0 (TID 91)
17/03/18 10:56:30 INFO Executor: Running task 0.0 in stage 12.0 (TID 84)
17/03/18 10:56:30 INFO Executor: Running task 2.0 in stage 12.0 (TID 86)
17/03/18 10:56:30 INFO Executor: Running task 3.0 in stage 12.0 (TID 87)
17/03/18 10:56:30 INFO CodeGenerator: Code generated in 6.963338 ms
17/03/18 10:56:30 INFO CodeGenerator: Code generated in 4.044967 ms
17/03/18 10:56:30 INFO CodeGenerator: Code generated in 4.336671 ms
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:56:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 7.0 in stage 12.0 (TID 91). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 8.0 in stage 12.0 (TID 92, localhost, executor driver, partition 8, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO Executor: Running task 8.0 in stage 12.0 (TID 92)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 7.0 in stage 12.0 (TID 91) in 467 ms on localhost (executor driver) (1/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 5.0 in stage 12.0 (TID 89). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 9.0 in stage 12.0 (TID 93, localhost, executor driver, partition 9, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO Executor: Running task 9.0 in stage 12.0 (TID 93)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 5.0 in stage 12.0 (TID 89) in 503 ms on localhost (executor driver) (2/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 4.0 in stage 12.0 (TID 88). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 10.0 in stage 12.0 (TID 94, localhost, executor driver, partition 10, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 4.0 in stage 12.0 (TID 88) in 544 ms on localhost (executor driver) (3/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Running task 10.0 in stage 12.0 (TID 94)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 0.0 in stage 12.0 (TID 84). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 11.0 in stage 12.0 (TID 95, localhost, executor driver, partition 11, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO Executor: Running task 11.0 in stage 12.0 (TID 95)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 84) in 554 ms on localhost (executor driver) (4/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 6.0 in stage 12.0 (TID 90). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 6.0 in stage 12.0 (TID 90) in 558 ms on localhost (executor driver) (5/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 2.0 in stage 12.0 (TID 86). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 86) in 643 ms on localhost (executor driver) (6/12)
17/03/18 10:56:31 INFO Executor: Finished task 3.0 in stage 12.0 (TID 87). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 3.0 in stage 12.0 (TID 87) in 692 ms on localhost (executor driver) (7/12)
17/03/18 10:56:31 INFO Executor: Finished task 1.0 in stage 12.0 (TID 85). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 85) in 695 ms on localhost (executor driver) (8/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 8.0 in stage 12.0 (TID 92). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 8.0 in stage 12.0 (TID 92) in 352 ms on localhost (executor driver) (9/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 10.0 in stage 12.0 (TID 94). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 10.0 in stage 12.0 (TID 94) in 373 ms on localhost (executor driver) (10/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 9.0 in stage 12.0 (TID 93). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 9.0 in stage 12.0 (TID 93) in 421 ms on localhost (executor driver) (11/12)
17/03/18 10:56:31 INFO Executor: Finished task 11.0 in stage 12.0 (TID 95). 2419 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 11.0 in stage 12.0 (TID 95) in 392 ms on localhost (executor driver) (12/12)
17/03/18 10:56:31 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/03/18 10:56:31 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0,945 s
17/03/18 10:56:31 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:56:31 INFO DAGScheduler: running: Set()
17/03/18 10:56:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 13, ResultStage 14)
17/03/18 10:56:31 INFO DAGScheduler: failed: Set()
17/03/18 10:56:31 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 20.7 KB, free 6.2 GB)
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 9.4 KB, free 6.2 GB)
17/03/18 10:56:31 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:38568 (size: 9.4 KB, free: 6.2 GB)
17/03/18 10:56:31 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:31 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:31 INFO TaskSchedulerImpl: Adding task set 13.0 with 8 tasks
17/03/18 10:56:31 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 96, localhost, executor driver, partition 0, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 97, localhost, executor driver, partition 1, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 4.0 in stage 13.0 (TID 98, localhost, executor driver, partition 4, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 5.0 in stage 13.0 (TID 99, localhost, executor driver, partition 5, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 100, localhost, executor driver, partition 2, ANY, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 101, localhost, executor driver, partition 3, ANY, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 6.0 in stage 13.0 (TID 102, localhost, executor driver, partition 6, ANY, 5935 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 7.0 in stage 13.0 (TID 103, localhost, executor driver, partition 7, ANY, 5935 bytes)
17/03/18 10:56:31 INFO Executor: Running task 5.0 in stage 13.0 (TID 99)
17/03/18 10:56:31 INFO Executor: Running task 0.0 in stage 13.0 (TID 96)
17/03/18 10:56:31 INFO Executor: Running task 6.0 in stage 13.0 (TID 102)
17/03/18 10:56:31 INFO Executor: Running task 1.0 in stage 13.0 (TID 97)
17/03/18 10:56:31 INFO Executor: Running task 2.0 in stage 13.0 (TID 100)
17/03/18 10:56:31 INFO Executor: Running task 7.0 in stage 13.0 (TID 103)
17/03/18 10:56:31 INFO Executor: Running task 4.0 in stage 13.0 (TID 98)
17/03/18 10:56:31 INFO Executor: Running task 3.0 in stage 13.0 (TID 101)
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO Executor: Finished task 6.0 in stage 13.0 (TID 102). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO Executor: Finished task 4.0 in stage 13.0 (TID 98). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO Executor: Finished task 0.0 in stage 13.0 (TID 96). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO Executor: Finished task 5.0 in stage 13.0 (TID 99). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO Executor: Finished task 3.0 in stage 13.0 (TID 101). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 6.0 in stage 13.0 (TID 102) in 7 ms on localhost (executor driver) (1/8)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 4.0 in stage 13.0 (TID 98) in 7 ms on localhost (executor driver) (2/8)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 5.0 in stage 13.0 (TID 99) in 7 ms on localhost (executor driver) (3/8)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 96) in 8 ms on localhost (executor driver) (4/8)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 101) in 8 ms on localhost (executor driver) (5/8)
17/03/18 10:56:31 INFO Executor: Finished task 1.0 in stage 13.0 (TID 97). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 97) in 10 ms on localhost (executor driver) (6/8)
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO Executor: Finished task 7.0 in stage 13.0 (TID 103). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 7.0 in stage 13.0 (TID 103) in 9 ms on localhost (executor driver) (7/8)
17/03/18 10:56:31 INFO Executor: Finished task 2.0 in stage 13.0 (TID 100). 3584 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 100) in 12 ms on localhost (executor driver) (8/8)
17/03/18 10:56:31 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/03/18 10:56:31 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0,013 s
17/03/18 10:56:31 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:56:31 INFO DAGScheduler: running: Set()
17/03/18 10:56:31 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/03/18 10:56:31 INFO DAGScheduler: failed: Set()
17/03/18 10:56:31 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[52] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:56:31 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:56:31 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[52] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:31 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/03/18 10:56:31 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 104, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/03/18 10:56:31 INFO Executor: Running task 0.0 in stage 14.0 (TID 104)
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:56:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:31 INFO Executor: Finished task 0.0 in stage 14.0 (TID 104). 2042 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 104) in 3 ms on localhost (executor driver) (1/1)
17/03/18 10:56:31 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/03/18 10:56:31 INFO DAGScheduler: ResultStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 10:56:31 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0,972667 s
17/03/18 10:56:31 INFO SparkSqlParser: Parsing command: SELECT `banner_pos`, count(*) AS `cnt`
FROM `train`
GROUP BY `banner_pos`
17/03/18 10:56:31 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:56:31 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:56:31 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 10:56:31 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:56:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
17/03/18 10:56:31 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enable is set to true, but current version of codegened fast hashmap does not support this aggregate.
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 10:56:31 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 10:56:31 INFO SparkContext: Created broadcast 18 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:56:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:56:31 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:56:31 INFO DAGScheduler: Registering RDD 55 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:31 INFO DAGScheduler: Registering RDD 58 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:31 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:56:31 INFO DAGScheduler: Final stage: ResultStage 17 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/03/18 10:56:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/03/18 10:56:31 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[55] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 17.2 KB, free 6.2 GB)
17/03/18 10:56:31 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 8.0 KB, free 6.2 GB)
17/03/18 10:56:31 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:38568 (size: 8.0 KB, free: 6.2 GB)
17/03/18 10:56:31 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:31 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[55] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:31 INFO TaskSchedulerImpl: Adding task set 15.0 with 12 tasks
17/03/18 10:56:31 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 105, localhost, executor driver, partition 0, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 106, localhost, executor driver, partition 1, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 107, localhost, executor driver, partition 2, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 108, localhost, executor driver, partition 3, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 109, localhost, executor driver, partition 4, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 110, localhost, executor driver, partition 5, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 111, localhost, executor driver, partition 6, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 112, localhost, executor driver, partition 7, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO Executor: Running task 1.0 in stage 15.0 (TID 106)
17/03/18 10:56:31 INFO Executor: Running task 2.0 in stage 15.0 (TID 107)
17/03/18 10:56:31 INFO Executor: Running task 6.0 in stage 15.0 (TID 111)
17/03/18 10:56:31 INFO Executor: Running task 0.0 in stage 15.0 (TID 105)
17/03/18 10:56:31 INFO Executor: Running task 3.0 in stage 15.0 (TID 108)
17/03/18 10:56:31 INFO Executor: Running task 7.0 in stage 15.0 (TID 112)
17/03/18 10:56:31 INFO Executor: Running task 5.0 in stage 15.0 (TID 110)
17/03/18 10:56:31 INFO Executor: Running task 4.0 in stage 15.0 (TID 109)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 1.0 in stage 15.0 (TID 106). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:56:31 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 113, localhost, executor driver, partition 8, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 106) in 192 ms on localhost (executor driver) (1/12)
17/03/18 10:56:31 INFO Executor: Running task 8.0 in stage 15.0 (TID 113)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 2.0 in stage 15.0 (TID 107). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 114, localhost, executor driver, partition 9, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 107) in 197 ms on localhost (executor driver) (2/12)
17/03/18 10:56:31 INFO Executor: Running task 9.0 in stage 15.0 (TID 114)
17/03/18 10:56:31 INFO Executor: Finished task 4.0 in stage 15.0 (TID 109). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 115, localhost, executor driver, partition 10, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 109) in 204 ms on localhost (executor driver) (3/12)
17/03/18 10:56:31 INFO Executor: Running task 10.0 in stage 15.0 (TID 115)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 3.0 in stage 15.0 (TID 108). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 116, localhost, executor driver, partition 11, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:56:31 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 108) in 209 ms on localhost (executor driver) (4/12)
17/03/18 10:56:31 INFO Executor: Running task 11.0 in stage 15.0 (TID 116)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 5.0 in stage 15.0 (TID 110). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 110) in 271 ms on localhost (executor driver) (5/12)
17/03/18 10:56:31 INFO Executor: Finished task 6.0 in stage 15.0 (TID 111). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 111) in 286 ms on localhost (executor driver) (6/12)
17/03/18 10:56:31 INFO Executor: Finished task 0.0 in stage 15.0 (TID 105). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 105) in 295 ms on localhost (executor driver) (7/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 7.0 in stage 15.0 (TID 112). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 112) in 338 ms on localhost (executor driver) (8/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 9.0 in stage 15.0 (TID 114). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 114) in 157 ms on localhost (executor driver) (9/12)
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:56:31 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:56:31 INFO Executor: Finished task 11.0 in stage 15.0 (TID 116). 2332 bytes result sent to driver
17/03/18 10:56:31 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 116) in 164 ms on localhost (executor driver) (10/12)
17/03/18 10:56:32 INFO Executor: Finished task 8.0 in stage 15.0 (TID 113). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 113) in 205 ms on localhost (executor driver) (11/12)
17/03/18 10:56:32 INFO Executor: Finished task 10.0 in stage 15.0 (TID 115). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 115) in 204 ms on localhost (executor driver) (12/12)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0,409 s
17/03/18 10:56:32 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:56:32 INFO DAGScheduler: running: Set()
17/03/18 10:56:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 16, ResultStage 17)
17/03/18 10:56:32 INFO DAGScheduler: failed: Set()
17/03/18 10:56:32 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[58] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 20.7 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.4 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:38568 (size: 9.4 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:32 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[58] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Adding task set 16.0 with 8 tasks
17/03/18 10:56:32 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 117, localhost, executor driver, partition 0, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 118, localhost, executor driver, partition 1, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 119, localhost, executor driver, partition 4, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 120, localhost, executor driver, partition 5, PROCESS_LOCAL, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 121, localhost, executor driver, partition 2, ANY, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 122, localhost, executor driver, partition 3, ANY, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 123, localhost, executor driver, partition 6, ANY, 5935 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 124, localhost, executor driver, partition 7, ANY, 5935 bytes)
17/03/18 10:56:32 INFO Executor: Running task 0.0 in stage 16.0 (TID 117)
17/03/18 10:56:32 INFO Executor: Running task 5.0 in stage 16.0 (TID 120)
17/03/18 10:56:32 INFO Executor: Running task 3.0 in stage 16.0 (TID 122)
17/03/18 10:56:32 INFO Executor: Running task 4.0 in stage 16.0 (TID 119)
17/03/18 10:56:32 INFO Executor: Running task 7.0 in stage 16.0 (TID 124)
17/03/18 10:56:32 INFO Executor: Running task 6.0 in stage 16.0 (TID 123)
17/03/18 10:56:32 INFO Executor: Running task 2.0 in stage 16.0 (TID 121)
17/03/18 10:56:32 INFO Executor: Running task 1.0 in stage 16.0 (TID 118)
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO Executor: Finished task 5.0 in stage 16.0 (TID 120). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO Executor: Finished task 0.0 in stage 16.0 (TID 117). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO Executor: Finished task 7.0 in stage 16.0 (TID 124). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO Executor: Finished task 3.0 in stage 16.0 (TID 122). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO Executor: Finished task 6.0 in stage 16.0 (TID 123). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 7.0 in stage 16.0 (TID 124) in 5 ms on localhost (executor driver) (1/8)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 117) in 6 ms on localhost (executor driver) (2/8)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 5.0 in stage 16.0 (TID 120) in 6 ms on localhost (executor driver) (3/8)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 122) in 6 ms on localhost (executor driver) (4/8)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 6.0 in stage 16.0 (TID 123) in 7 ms on localhost (executor driver) (5/8)
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO Executor: Finished task 1.0 in stage 16.0 (TID 118). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 118) in 10 ms on localhost (executor driver) (6/8)
17/03/18 10:56:32 INFO Executor: Finished task 4.0 in stage 16.0 (TID 119). 3584 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 4.0 in stage 16.0 (TID 119) in 10 ms on localhost (executor driver) (7/8)
17/03/18 10:56:32 INFO Executor: Finished task 2.0 in stage 16.0 (TID 121). 3671 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 121) in 11 ms on localhost (executor driver) (8/8)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0,013 s
17/03/18 10:56:32 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:56:32 INFO DAGScheduler: running: Set()
17/03/18 10:56:32 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/03/18 10:56:32 INFO DAGScheduler: failed: Set()
17/03/18 10:56:32 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[61] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[61] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/03/18 10:56:32 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 125, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/03/18 10:56:32 INFO Executor: Running task 0.0 in stage 17.0 (TID 125)
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO Executor: Finished task 0.0 in stage 17.0 (TID 125). 1955 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 125) in 3 ms on localhost (executor driver) (1/1)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ResultStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0,004 s
17/03/18 10:56:32 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0,436391 s
17/03/18 10:56:32 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT `banner_pos`, count(*) AS `cnt`
FROM `train`
GROUP BY `banner_pos`) `pxmfcfibnc`
LIMIT 7
17/03/18 10:56:32 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:56:32 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:56:32 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 10:56:32 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:56:32 INFO CodeGenerator: Code generated in 16.454891 ms
17/03/18 10:56:32 INFO CodeGenerator: Code generated in 44.527711 ms
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 22 from collect at utils.scala:197
17/03/18 10:56:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:56:32 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:56:32 INFO DAGScheduler: Registering RDD 64 (collect at utils.scala:197)
17/03/18 10:56:32 INFO DAGScheduler: Got job 8 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:56:32 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:197)
17/03/18 10:56:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/03/18 10:56:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
17/03/18 10:56:32 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[64] at collect at utils.scala:197), which has no missing parents
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 22.9 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:38568 (size: 10.5 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:32 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[64] at collect at utils.scala:197)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Adding task set 18.0 with 12 tasks
17/03/18 10:56:32 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 126, localhost, executor driver, partition 0, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 127, localhost, executor driver, partition 1, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 128, localhost, executor driver, partition 2, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 129, localhost, executor driver, partition 3, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 4.0 in stage 18.0 (TID 130, localhost, executor driver, partition 4, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 5.0 in stage 18.0 (TID 131, localhost, executor driver, partition 5, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 6.0 in stage 18.0 (TID 132, localhost, executor driver, partition 6, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 7.0 in stage 18.0 (TID 133, localhost, executor driver, partition 7, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO Executor: Running task 0.0 in stage 18.0 (TID 126)
17/03/18 10:56:32 INFO Executor: Running task 2.0 in stage 18.0 (TID 128)
17/03/18 10:56:32 INFO Executor: Running task 6.0 in stage 18.0 (TID 132)
17/03/18 10:56:32 INFO Executor: Running task 1.0 in stage 18.0 (TID 127)
17/03/18 10:56:32 INFO Executor: Running task 3.0 in stage 18.0 (TID 129)
17/03/18 10:56:32 INFO Executor: Running task 5.0 in stage 18.0 (TID 131)
17/03/18 10:56:32 INFO Executor: Running task 4.0 in stage 18.0 (TID 130)
17/03/18 10:56:32 INFO Executor: Running task 7.0 in stage 18.0 (TID 133)
17/03/18 10:56:32 INFO CodeGenerator: Code generated in 8.446493 ms
17/03/18 10:56:32 INFO CodeGenerator: Code generated in 6.864631 ms
17/03/18 10:56:32 INFO CodeGenerator: Code generated in 6.590219 ms
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 1.0 in stage 18.0 (TID 127). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Starting task 8.0 in stage 18.0 (TID 134, localhost, executor driver, partition 8, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 127) in 234 ms on localhost (executor driver) (1/12)
17/03/18 10:56:32 INFO Executor: Running task 8.0 in stage 18.0 (TID 134)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 3.0 in stage 18.0 (TID 129). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Starting task 9.0 in stage 18.0 (TID 135, localhost, executor driver, partition 9, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO Executor: Running task 9.0 in stage 18.0 (TID 135)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 129) in 243 ms on localhost (executor driver) (2/12)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 6.0 in stage 18.0 (TID 132). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Starting task 10.0 in stage 18.0 (TID 136, localhost, executor driver, partition 10, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO Executor: Running task 10.0 in stage 18.0 (TID 136)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 6.0 in stage 18.0 (TID 132) in 258 ms on localhost (executor driver) (3/12)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 4.0 in stage 18.0 (TID 130). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:56:32 INFO TaskSetManager: Starting task 11.0 in stage 18.0 (TID 137, localhost, executor driver, partition 11, PROCESS_LOCAL, 6993 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 4.0 in stage 18.0 (TID 130) in 271 ms on localhost (executor driver) (4/12)
17/03/18 10:56:32 INFO Executor: Running task 11.0 in stage 18.0 (TID 137)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 2.0 in stage 18.0 (TID 128). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 128) in 277 ms on localhost (executor driver) (5/12)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 5.0 in stage 18.0 (TID 131). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 5.0 in stage 18.0 (TID 131) in 292 ms on localhost (executor driver) (6/12)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 0.0 in stage 18.0 (TID 126). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 126) in 312 ms on localhost (executor driver) (7/12)
17/03/18 10:56:32 INFO Executor: Finished task 7.0 in stage 18.0 (TID 133). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 7.0 in stage 18.0 (TID 133) in 311 ms on localhost (executor driver) (8/12)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 11.0 in stage 18.0 (TID 137). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 11.0 in stage 18.0 (TID 137) in 69 ms on localhost (executor driver) (9/12)
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:56:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:56:32 INFO Executor: Finished task 8.0 in stage 18.0 (TID 134). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 8.0 in stage 18.0 (TID 134) in 146 ms on localhost (executor driver) (10/12)
17/03/18 10:56:32 INFO Executor: Finished task 9.0 in stage 18.0 (TID 135). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 9.0 in stage 18.0 (TID 135) in 149 ms on localhost (executor driver) (11/12)
17/03/18 10:56:32 INFO Executor: Finished task 10.0 in stage 18.0 (TID 136). 2332 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 10.0 in stage 18.0 (TID 136) in 135 ms on localhost (executor driver) (12/12)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ShuffleMapStage 18 (collect at utils.scala:197) finished in 0,394 s
17/03/18 10:56:32 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:56:32 INFO DAGScheduler: running: Set()
17/03/18 10:56:32 INFO DAGScheduler: waiting: Set(ResultStage 19)
17/03/18 10:56:32 INFO DAGScheduler: failed: Set()
17/03/18 10:56:32 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[67] at collect at utils.scala:197), which has no missing parents
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 19.7 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 9.2 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:38568 (size: 9.2 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[67] at collect at utils.scala:197)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/03/18 10:56:32 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 138, localhost, executor driver, partition 0, PROCESS_LOCAL, 5860 bytes)
17/03/18 10:56:32 INFO Executor: Running task 0.0 in stage 19.0 (TID 138)
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO Executor: Finished task 0.0 in stage 19.0 (TID 138). 2855 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 138) in 6 ms on localhost (executor driver) (1/1)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:197) finished in 0,006 s
17/03/18 10:56:32 INFO DAGScheduler: Job 8 finished: collect at utils.scala:197, took 0,407958 s
17/03/18 10:56:32 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:56:32 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 10 is 161 bytes
17/03/18 10:56:32 INFO DAGScheduler: Got job 9 (collect at utils.scala:197) with 4 output partitions
17/03/18 10:56:32 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:197)
17/03/18 10:56:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
17/03/18 10:56:32 INFO DAGScheduler: Missing parents: List()
17/03/18 10:56:32 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[67] at collect at utils.scala:197), which has no missing parents
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 19.7 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 9.2 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:38568 (size: 9.2 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:32 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 21 (MapPartitionsRDD[67] at collect at utils.scala:197)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Adding task set 21.0 with 4 tasks
17/03/18 10:56:32 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 139, localhost, executor driver, partition 1, PROCESS_LOCAL, 5860 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 3.0 in stage 21.0 (TID 140, localhost, executor driver, partition 4, PROCESS_LOCAL, 5860 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 141, localhost, executor driver, partition 2, ANY, 5860 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 142, localhost, executor driver, partition 3, ANY, 5860 bytes)
17/03/18 10:56:32 INFO Executor: Running task 2.0 in stage 21.0 (TID 142)
17/03/18 10:56:32 INFO Executor: Running task 1.0 in stage 21.0 (TID 141)
17/03/18 10:56:32 INFO Executor: Running task 3.0 in stage 21.0 (TID 140)
17/03/18 10:56:32 INFO Executor: Running task 0.0 in stage 21.0 (TID 139)
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO Executor: Finished task 3.0 in stage 21.0 (TID 140). 2855 bytes result sent to driver
17/03/18 10:56:32 INFO Executor: Finished task 0.0 in stage 21.0 (TID 139). 2855 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 3.0 in stage 21.0 (TID 140) in 5 ms on localhost (executor driver) (1/4)
17/03/18 10:56:32 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 139) in 5 ms on localhost (executor driver) (2/4)
17/03/18 10:56:32 INFO Executor: Finished task 1.0 in stage 21.0 (TID 141). 2876 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 141) in 4 ms on localhost (executor driver) (3/4)
17/03/18 10:56:32 INFO Executor: Finished task 2.0 in stage 21.0 (TID 142). 2905 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 142) in 4 ms on localhost (executor driver) (4/4)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:197) finished in 0,007 s
17/03/18 10:56:32 INFO DAGScheduler: Job 9 finished: collect at utils.scala:197, took 0,018055 s
17/03/18 10:56:32 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:56:32 INFO DAGScheduler: Got job 10 (collect at utils.scala:197) with 3 output partitions
17/03/18 10:56:32 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:197)
17/03/18 10:56:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 22)
17/03/18 10:56:32 INFO DAGScheduler: Missing parents: List()
17/03/18 10:56:32 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[67] at collect at utils.scala:197), which has no missing parents
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 19.7 KB, free 6.2 GB)
17/03/18 10:56:32 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 9.2 KB, free 6.2 GB)
17/03/18 10:56:32 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:38568 (size: 9.2 KB, free: 6.2 GB)
17/03/18 10:56:32 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/03/18 10:56:32 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 23 (MapPartitionsRDD[67] at collect at utils.scala:197)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Adding task set 23.0 with 3 tasks
17/03/18 10:56:32 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 143, localhost, executor driver, partition 5, PROCESS_LOCAL, 5860 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 144, localhost, executor driver, partition 6, ANY, 5860 bytes)
17/03/18 10:56:32 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 145, localhost, executor driver, partition 7, ANY, 5860 bytes)
17/03/18 10:56:32 INFO Executor: Running task 0.0 in stage 23.0 (TID 143)
17/03/18 10:56:32 INFO Executor: Running task 1.0 in stage 23.0 (TID 144)
17/03/18 10:56:32 INFO Executor: Running task 2.0 in stage 23.0 (TID 145)
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:56:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:56:32 INFO Executor: Finished task 0.0 in stage 23.0 (TID 143). 2855 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 143) in 4 ms on localhost (executor driver) (1/3)
17/03/18 10:56:32 INFO Executor: Finished task 2.0 in stage 23.0 (TID 145). 2872 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 145) in 4 ms on localhost (executor driver) (2/3)
17/03/18 10:56:32 INFO Executor: Finished task 1.0 in stage 23.0 (TID 144). 2892 bytes result sent to driver
17/03/18 10:56:32 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 144) in 4 ms on localhost (executor driver) (3/3)
17/03/18 10:56:32 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/03/18 10:56:32 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:197) finished in 0,005 s
17/03/18 10:56:32 INFO DAGScheduler: Job 10 finished: collect at utils.scala:197, took 0,010650 s
17/03/18 10:56:32 INFO CodeGenerator: Code generated in 4.541868 ms
17/03/18 10:58:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 10:58:30 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:58:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 10:58:30 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:58:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 10:58:30 INFO CodeGenerator: Code generated in 31.881624 ms
17/03/18 10:58:30 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 10:58:30 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 10:58:30 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 10:58:30 INFO SparkContext: Created broadcast 27 from collect at utils.scala:197
17/03/18 10:58:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:58:30 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:58:30 INFO DAGScheduler: Got job 11 (collect at utils.scala:197) with 12 output partitions
17/03/18 10:58:30 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:197)
17/03/18 10:58:30 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:58:30 INFO DAGScheduler: Missing parents: List()
17/03/18 10:58:30 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[70] at collect at utils.scala:197), which has no missing parents
17/03/18 10:58:30 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 22.8 KB, free 6.2 GB)
17/03/18 10:58:30 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.1 KB, free 6.2 GB)
17/03/18 10:58:30 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:38568 (size: 8.1 KB, free: 6.2 GB)
17/03/18 10:58:30 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/03/18 10:58:30 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 24 (MapPartitionsRDD[70] at collect at utils.scala:197)
17/03/18 10:58:30 INFO TaskSchedulerImpl: Adding task set 24.0 with 12 tasks
17/03/18 10:58:30 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 146, localhost, executor driver, partition 0, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 147, localhost, executor driver, partition 1, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 148, localhost, executor driver, partition 2, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 149, localhost, executor driver, partition 3, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 4.0 in stage 24.0 (TID 150, localhost, executor driver, partition 4, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 5.0 in stage 24.0 (TID 151, localhost, executor driver, partition 5, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 6.0 in stage 24.0 (TID 152, localhost, executor driver, partition 6, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO TaskSetManager: Starting task 7.0 in stage 24.0 (TID 153, localhost, executor driver, partition 7, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:30 INFO Executor: Running task 0.0 in stage 24.0 (TID 146)
17/03/18 10:58:30 INFO Executor: Running task 1.0 in stage 24.0 (TID 147)
17/03/18 10:58:30 INFO Executor: Running task 2.0 in stage 24.0 (TID 148)
17/03/18 10:58:30 INFO Executor: Running task 3.0 in stage 24.0 (TID 149)
17/03/18 10:58:30 INFO Executor: Running task 4.0 in stage 24.0 (TID 150)
17/03/18 10:58:30 INFO Executor: Running task 5.0 in stage 24.0 (TID 151)
17/03/18 10:58:30 INFO Executor: Running task 6.0 in stage 24.0 (TID 152)
17/03/18 10:58:30 INFO Executor: Running task 7.0 in stage 24.0 (TID 153)
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:58:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:58:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:58:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:58:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:58:32 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:38568 in memory (size: 9.4 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:38568 in memory (size: 9.2 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:38568 in memory (size: 9.2 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:38568 in memory (size: 8.0 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:38568 in memory (size: 9.4 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 3565
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:38568 in memory (size: 10.5 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:38568 in memory (size: 9.2 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2964
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2965
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2966
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2967
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2968
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2969
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2970
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2971
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2972
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2973
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2974
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2975
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2976
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2977
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2978
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2979
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2980
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2981
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2982
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2983
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2984
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2985
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2986
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2987
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2988
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:38568 in memory (size: 24.4 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO ContextCleaner: Cleaned shuffle 8
17/03/18 10:58:33 INFO ContextCleaner: Cleaned shuffle 9
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:38568 in memory (size: 10.2 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2363
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2364
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2365
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2366
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2367
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2368
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2369
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2370
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2371
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2372
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2373
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2374
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2375
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2376
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2377
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2378
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2379
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2380
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2381
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2382
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2383
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2384
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2385
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2386
17/03/18 10:58:33 INFO ContextCleaner: Cleaned accumulator 2387
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:38568 in memory (size: 24.4 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO ContextCleaner: Cleaned shuffle 6
17/03/18 10:58:33 INFO ContextCleaner: Cleaned shuffle 7
17/03/18 10:58:33 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:38568 in memory (size: 8.0 KB, free: 6.2 GB)
17/03/18 10:58:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:58:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:58:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:58:34 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:58:34 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:58:34 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:58:35 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:58:35 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:58:35 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:58:35 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:58:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:58:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:58:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:58:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:58:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:58:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:58:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:58:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:58:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:58:39 INFO Executor: Finished task 4.0 in stage 24.0 (TID 150). 17829 bytes result sent to driver
17/03/18 10:58:39 INFO TaskSetManager: Starting task 8.0 in stage 24.0 (TID 154, localhost, executor driver, partition 8, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:39 INFO Executor: Running task 8.0 in stage 24.0 (TID 154)
17/03/18 10:58:39 INFO TaskSetManager: Finished task 4.0 in stage 24.0 (TID 150) in 9198 ms on localhost (executor driver) (1/12)
17/03/18 10:58:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:58:39 INFO Executor: Finished task 7.0 in stage 24.0 (TID 153). 7709 bytes result sent to driver
17/03/18 10:58:39 INFO TaskSetManager: Starting task 9.0 in stage 24.0 (TID 155, localhost, executor driver, partition 9, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:39 INFO Executor: Running task 9.0 in stage 24.0 (TID 155)
17/03/18 10:58:39 INFO TaskSetManager: Finished task 7.0 in stage 24.0 (TID 153) in 9228 ms on localhost (executor driver) (2/12)
17/03/18 10:58:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:58:39 INFO Executor: Finished task 2.0 in stage 24.0 (TID 148). 19358 bytes result sent to driver
17/03/18 10:58:39 INFO TaskSetManager: Starting task 10.0 in stage 24.0 (TID 156, localhost, executor driver, partition 10, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:39 INFO Executor: Running task 10.0 in stage 24.0 (TID 156)
17/03/18 10:58:39 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 148) in 9420 ms on localhost (executor driver) (3/12)
17/03/18 10:58:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:58:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:58:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:58:41 INFO Executor: Finished task 0.0 in stage 24.0 (TID 146). 5586 bytes result sent to driver
17/03/18 10:58:41 INFO TaskSetManager: Starting task 11.0 in stage 24.0 (TID 157, localhost, executor driver, partition 11, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:58:41 INFO Executor: Running task 11.0 in stage 24.0 (TID 157)
17/03/18 10:58:41 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 146) in 11486 ms on localhost (executor driver) (4/12)
17/03/18 10:58:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:58:41 INFO Executor: Finished task 6.0 in stage 24.0 (TID 152). 23115 bytes result sent to driver
17/03/18 10:58:41 INFO TaskSetManager: Finished task 6.0 in stage 24.0 (TID 152) in 11629 ms on localhost (executor driver) (5/12)
17/03/18 10:58:41 INFO Executor: Finished task 3.0 in stage 24.0 (TID 149). 4291 bytes result sent to driver
17/03/18 10:58:41 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 149) in 11702 ms on localhost (executor driver) (6/12)
17/03/18 10:58:42 INFO Executor: Finished task 1.0 in stage 24.0 (TID 147). 9767 bytes result sent to driver
17/03/18 10:58:42 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 147) in 12003 ms on localhost (executor driver) (7/12)
17/03/18 10:58:42 INFO Executor: Finished task 5.0 in stage 24.0 (TID 151). 5536 bytes result sent to driver
17/03/18 10:58:42 INFO TaskSetManager: Finished task 5.0 in stage 24.0 (TID 151) in 12002 ms on localhost (executor driver) (8/12)
17/03/18 10:58:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:58:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:58:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:58:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:58:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:58:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:58:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:58:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:58:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:58:45 INFO Executor: Finished task 10.0 in stage 24.0 (TID 156). 4146 bytes result sent to driver
17/03/18 10:58:45 INFO TaskSetManager: Finished task 10.0 in stage 24.0 (TID 156) in 5447 ms on localhost (executor driver) (9/12)
17/03/18 10:58:45 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:58:45 INFO Executor: Finished task 11.0 in stage 24.0 (TID 157). 3872 bytes result sent to driver
17/03/18 10:58:45 INFO TaskSetManager: Finished task 11.0 in stage 24.0 (TID 157) in 3412 ms on localhost (executor driver) (10/12)
17/03/18 10:58:45 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:58:45 INFO Executor: Finished task 8.0 in stage 24.0 (TID 154). 4822 bytes result sent to driver
17/03/18 10:58:45 INFO TaskSetManager: Finished task 8.0 in stage 24.0 (TID 154) in 5792 ms on localhost (executor driver) (11/12)
17/03/18 10:58:45 INFO Executor: Finished task 9.0 in stage 24.0 (TID 155). 5012 bytes result sent to driver
17/03/18 10:58:45 INFO TaskSetManager: Finished task 9.0 in stage 24.0 (TID 155) in 6022 ms on localhost (executor driver) (12/12)
17/03/18 10:58:45 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/03/18 10:58:45 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:197) finished in 15,251 s
17/03/18 10:58:45 INFO DAGScheduler: Job 11 finished: collect at utils.scala:197, took 15,255190 s
17/03/18 10:58:45 INFO CodeGenerator: Code generated in 14.729246 ms
17/03/18 10:59:00 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = '3')
17/03/18 10:59:00 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:59:00 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(banner_pos#14 as double) = 3.0)
17/03/18 10:59:00 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:59:00 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 10:59:00 INFO CodeGenerator: Code generated in 26.965651 ms
17/03/18 10:59:00 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 10:59:00 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 10:59:00 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 10:59:00 INFO SparkContext: Created broadcast 29 from collect at utils.scala:197
17/03/18 10:59:00 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:59:00 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:59:00 INFO DAGScheduler: Got job 12 (collect at utils.scala:197) with 12 output partitions
17/03/18 10:59:00 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:197)
17/03/18 10:59:00 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:59:00 INFO DAGScheduler: Missing parents: List()
17/03/18 10:59:00 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[73] at collect at utils.scala:197), which has no missing parents
17/03/18 10:59:00 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 21.2 KB, free 6.2 GB)
17/03/18 10:59:00 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.3 KB, free 6.2 GB)
17/03/18 10:59:00 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:38568 (size: 7.3 KB, free: 6.2 GB)
17/03/18 10:59:00 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/03/18 10:59:00 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 25 (MapPartitionsRDD[73] at collect at utils.scala:197)
17/03/18 10:59:00 INFO TaskSchedulerImpl: Adding task set 25.0 with 12 tasks
17/03/18 10:59:00 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 158, localhost, executor driver, partition 0, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 159, localhost, executor driver, partition 1, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 160, localhost, executor driver, partition 2, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 3.0 in stage 25.0 (TID 161, localhost, executor driver, partition 3, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 4.0 in stage 25.0 (TID 162, localhost, executor driver, partition 4, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 5.0 in stage 25.0 (TID 163, localhost, executor driver, partition 5, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 6.0 in stage 25.0 (TID 164, localhost, executor driver, partition 6, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO TaskSetManager: Starting task 7.0 in stage 25.0 (TID 165, localhost, executor driver, partition 7, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:00 INFO Executor: Running task 1.0 in stage 25.0 (TID 159)
17/03/18 10:59:00 INFO Executor: Running task 0.0 in stage 25.0 (TID 158)
17/03/18 10:59:00 INFO Executor: Running task 3.0 in stage 25.0 (TID 161)
17/03/18 10:59:00 INFO Executor: Running task 7.0 in stage 25.0 (TID 165)
17/03/18 10:59:00 INFO Executor: Running task 2.0 in stage 25.0 (TID 160)
17/03/18 10:59:00 INFO Executor: Running task 4.0 in stage 25.0 (TID 162)
17/03/18 10:59:00 INFO Executor: Running task 5.0 in stage 25.0 (TID 163)
17/03/18 10:59:00 INFO Executor: Running task 6.0 in stage 25.0 (TID 164)
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:59:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:59:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:59:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:59:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:59:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:59:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:59:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:59:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:59:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:59:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:59:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:59:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:59:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:59:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:59:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:59:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:59:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:59:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:59:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:59:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:59:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:59:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:59:07 INFO Executor: Finished task 6.0 in stage 25.0 (TID 164). 23202 bytes result sent to driver
17/03/18 10:59:07 INFO TaskSetManager: Starting task 8.0 in stage 25.0 (TID 166, localhost, executor driver, partition 8, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:07 INFO Executor: Running task 8.0 in stage 25.0 (TID 166)
17/03/18 10:59:07 INFO TaskSetManager: Finished task 6.0 in stage 25.0 (TID 164) in 7214 ms on localhost (executor driver) (1/12)
17/03/18 10:59:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:59:08 INFO Executor: Finished task 2.0 in stage 25.0 (TID 160). 19358 bytes result sent to driver
17/03/18 10:59:08 INFO TaskSetManager: Starting task 9.0 in stage 25.0 (TID 167, localhost, executor driver, partition 9, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:08 INFO Executor: Running task 9.0 in stage 25.0 (TID 167)
17/03/18 10:59:08 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 160) in 8072 ms on localhost (executor driver) (2/12)
17/03/18 10:59:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:59:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:59:09 INFO Executor: Finished task 7.0 in stage 25.0 (TID 165). 7709 bytes result sent to driver
17/03/18 10:59:09 INFO TaskSetManager: Starting task 10.0 in stage 25.0 (TID 168, localhost, executor driver, partition 10, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:09 INFO TaskSetManager: Finished task 7.0 in stage 25.0 (TID 165) in 8498 ms on localhost (executor driver) (3/12)
17/03/18 10:59:09 INFO Executor: Running task 10.0 in stage 25.0 (TID 168)
17/03/18 10:59:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:59:09 INFO Executor: Finished task 0.0 in stage 25.0 (TID 158). 5586 bytes result sent to driver
17/03/18 10:59:09 INFO TaskSetManager: Starting task 11.0 in stage 25.0 (TID 169, localhost, executor driver, partition 11, PROCESS_LOCAL, 7090 bytes)
17/03/18 10:59:09 INFO Executor: Running task 11.0 in stage 25.0 (TID 169)
17/03/18 10:59:09 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 158) in 8650 ms on localhost (executor driver) (4/12)
17/03/18 10:59:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:59:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:59:09 INFO Executor: Finished task 4.0 in stage 25.0 (TID 162). 17742 bytes result sent to driver
17/03/18 10:59:09 INFO TaskSetManager: Finished task 4.0 in stage 25.0 (TID 162) in 9163 ms on localhost (executor driver) (5/12)
17/03/18 10:59:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:59:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:59:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:59:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:59:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:59:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:59:11 INFO Executor: Finished task 5.0 in stage 25.0 (TID 163). 5536 bytes result sent to driver
17/03/18 10:59:11 INFO TaskSetManager: Finished task 5.0 in stage 25.0 (TID 163) in 10887 ms on localhost (executor driver) (6/12)
17/03/18 10:59:12 INFO Executor: Finished task 3.0 in stage 25.0 (TID 161). 4291 bytes result sent to driver
17/03/18 10:59:12 INFO TaskSetManager: Finished task 3.0 in stage 25.0 (TID 161) in 11373 ms on localhost (executor driver) (7/12)
17/03/18 10:59:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:59:12 INFO Executor: Finished task 1.0 in stage 25.0 (TID 159). 9767 bytes result sent to driver
17/03/18 10:59:12 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 159) in 11992 ms on localhost (executor driver) (8/12)
17/03/18 10:59:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:59:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:59:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:59:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:59:13 INFO Executor: Finished task 11.0 in stage 25.0 (TID 169). 3799 bytes result sent to driver
17/03/18 10:59:13 INFO TaskSetManager: Finished task 11.0 in stage 25.0 (TID 169) in 4271 ms on localhost (executor driver) (9/12)
17/03/18 10:59:13 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:59:13 INFO Executor: Finished task 8.0 in stage 25.0 (TID 166). 4822 bytes result sent to driver
17/03/18 10:59:13 INFO TaskSetManager: Finished task 8.0 in stage 25.0 (TID 166) in 5960 ms on localhost (executor driver) (10/12)
17/03/18 10:59:14 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:59:14 INFO Executor: Finished task 9.0 in stage 25.0 (TID 167). 4939 bytes result sent to driver
17/03/18 10:59:14 INFO TaskSetManager: Finished task 9.0 in stage 25.0 (TID 167) in 5470 ms on localhost (executor driver) (11/12)
17/03/18 10:59:14 INFO Executor: Finished task 10.0 in stage 25.0 (TID 168). 4073 bytes result sent to driver
17/03/18 10:59:14 INFO TaskSetManager: Finished task 10.0 in stage 25.0 (TID 168) in 5355 ms on localhost (executor driver) (12/12)
17/03/18 10:59:14 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/03/18 10:59:14 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:197) finished in 13,855 s
17/03/18 10:59:14 INFO DAGScheduler: Job 12 finished: collect at utils.scala:197, took 13,859257 s
17/03/18 10:59:14 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:38568 in memory (size: 7.3 KB, free: 6.2 GB)
17/03/18 10:59:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 10:59:43 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:59:43 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:59:43 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:59:43 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:59:43 INFO CodeGenerator: Code generated in 9.564807 ms
17/03/18 10:59:43 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 10:59:43 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 10:59:43 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:38568 (size: 24.2 KB, free: 6.2 GB)
17/03/18 10:59:43 INFO SparkContext: Created broadcast 31 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:59:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:59:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:59:43 INFO DAGScheduler: Registering RDD 76 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:43 INFO DAGScheduler: Got job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:59:43 INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
17/03/18 10:59:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 26)
17/03/18 10:59:43 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:59:43 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 10:59:43 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 10:59:43 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:38568 (size: 5.3 KB, free: 6.2 GB)
17/03/18 10:59:43 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/03/18 10:59:43 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[76] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:43 INFO TaskSchedulerImpl: Adding task set 26.0 with 12 tasks
17/03/18 10:59:43 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 170, localhost, executor driver, partition 0, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 171, localhost, executor driver, partition 1, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 172, localhost, executor driver, partition 2, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 3.0 in stage 26.0 (TID 173, localhost, executor driver, partition 3, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 4.0 in stage 26.0 (TID 174, localhost, executor driver, partition 4, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 5.0 in stage 26.0 (TID 175, localhost, executor driver, partition 5, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 6.0 in stage 26.0 (TID 176, localhost, executor driver, partition 6, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO TaskSetManager: Starting task 7.0 in stage 26.0 (TID 177, localhost, executor driver, partition 7, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:43 INFO Executor: Running task 1.0 in stage 26.0 (TID 171)
17/03/18 10:59:43 INFO Executor: Running task 0.0 in stage 26.0 (TID 170)
17/03/18 10:59:43 INFO Executor: Running task 6.0 in stage 26.0 (TID 176)
17/03/18 10:59:43 INFO Executor: Running task 2.0 in stage 26.0 (TID 172)
17/03/18 10:59:43 INFO Executor: Running task 5.0 in stage 26.0 (TID 175)
17/03/18 10:59:43 INFO Executor: Running task 3.0 in stage 26.0 (TID 173)
17/03/18 10:59:43 INFO Executor: Running task 4.0 in stage 26.0 (TID 174)
17/03/18 10:59:43 INFO Executor: Running task 7.0 in stage 26.0 (TID 177)
17/03/18 10:59:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:59:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:59:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:59:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:59:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 4.0 in stage 26.0 (TID 174). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Starting task 8.0 in stage 26.0 (TID 178, localhost, executor driver, partition 8, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 4.0 in stage 26.0 (TID 174) in 37 ms on localhost (executor driver) (1/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Running task 8.0 in stage 26.0 (TID 178)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 6.0 in stage 26.0 (TID 176). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Starting task 9.0 in stage 26.0 (TID 179, localhost, executor driver, partition 9, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Running task 9.0 in stage 26.0 (TID 179)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 6.0 in stage 26.0 (TID 176) in 39 ms on localhost (executor driver) (2/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 3.0 in stage 26.0 (TID 173). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Starting task 10.0 in stage 26.0 (TID 180, localhost, executor driver, partition 10, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Finished task 3.0 in stage 26.0 (TID 173) in 40 ms on localhost (executor driver) (3/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Running task 10.0 in stage 26.0 (TID 180)
17/03/18 10:59:44 INFO Executor: Finished task 7.0 in stage 26.0 (TID 177). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 5.0 in stage 26.0 (TID 175). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 1.0 in stage 26.0 (TID 171). 1970 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 2.0 in stage 26.0 (TID 172). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Starting task 11.0 in stage 26.0 (TID 181, localhost, executor driver, partition 11, PROCESS_LOCAL, 7079 bytes)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Finished task 7.0 in stage 26.0 (TID 177) in 42 ms on localhost (executor driver) (4/12)
17/03/18 10:59:44 INFO Executor: Running task 11.0 in stage 26.0 (TID 181)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 171) in 44 ms on localhost (executor driver) (5/12)
17/03/18 10:59:44 INFO Executor: Finished task 0.0 in stage 26.0 (TID 170). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 172) in 43 ms on localhost (executor driver) (6/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Finished task 5.0 in stage 26.0 (TID 175) in 43 ms on localhost (executor driver) (7/12)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 170) in 45 ms on localhost (executor driver) (8/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 8.0 in stage 26.0 (TID 178). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 8.0 in stage 26.0 (TID 178) in 9 ms on localhost (executor driver) (9/12)
17/03/18 10:59:44 INFO Executor: Finished task 9.0 in stage 26.0 (TID 179). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Finished task 9.0 in stage 26.0 (TID 179) in 8 ms on localhost (executor driver) (10/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 10.0 in stage 26.0 (TID 180). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 10.0 in stage 26.0 (TID 180) in 10 ms on localhost (executor driver) (11/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 11.0 in stage 26.0 (TID 181). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 11.0 in stage 26.0 (TID 181) in 26 ms on localhost (executor driver) (12/12)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/03/18 10:59:44 INFO DAGScheduler: ShuffleMapStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0,069 s
17/03/18 10:59:44 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:59:44 INFO DAGScheduler: running: Set()
17/03/18 10:59:44 INFO DAGScheduler: waiting: Set(ResultStage 27)
17/03/18 10:59:44 INFO DAGScheduler: failed: Set()
17/03/18 10:59:44 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:59:44 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:59:44 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/03/18 10:59:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[79] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/03/18 10:59:44 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 182, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/03/18 10:59:44 INFO Executor: Running task 0.0 in stage 27.0 (TID 182)
17/03/18 10:59:44 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:59:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:59:44 INFO Executor: Finished task 0.0 in stage 27.0 (TID 182). 2042 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 182) in 3 ms on localhost (executor driver) (1/1)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/03/18 10:59:44 INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 10:59:44 INFO DAGScheduler: Job 13 finished: count at NativeMethodAccessorImpl.java:0, took 0,079206 s
17/03/18 10:59:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 10:59:44 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:59:44 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:59:44 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 10:59:44 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 10:59:44 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:38568 (size: 24.2 KB, free: 6.2 GB)
17/03/18 10:59:44 INFO SparkContext: Created broadcast 34 from count at NativeMethodAccessorImpl.java:0
17/03/18 10:59:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:59:44 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 10:59:44 INFO DAGScheduler: Registering RDD 82 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:44 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 10:59:44 INFO DAGScheduler: Final stage: ResultStage 29 (count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 28)
17/03/18 10:59:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 28)
17/03/18 10:59:44 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 10:59:44 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:38568 (size: 5.3 KB, free: 6.2 GB)
17/03/18 10:59:44 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/03/18 10:59:44 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[82] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Adding task set 28.0 with 12 tasks
17/03/18 10:59:44 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 183, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 184, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 185, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 3.0 in stage 28.0 (TID 186, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 4.0 in stage 28.0 (TID 187, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 5.0 in stage 28.0 (TID 188, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 6.0 in stage 28.0 (TID 189, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 7.0 in stage 28.0 (TID 190, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO Executor: Running task 2.0 in stage 28.0 (TID 185)
17/03/18 10:59:44 INFO Executor: Running task 4.0 in stage 28.0 (TID 187)
17/03/18 10:59:44 INFO Executor: Running task 0.0 in stage 28.0 (TID 183)
17/03/18 10:59:44 INFO Executor: Running task 3.0 in stage 28.0 (TID 186)
17/03/18 10:59:44 INFO Executor: Running task 5.0 in stage 28.0 (TID 188)
17/03/18 10:59:44 INFO Executor: Running task 7.0 in stage 28.0 (TID 190)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Running task 1.0 in stage 28.0 (TID 184)
17/03/18 10:59:44 INFO Executor: Running task 6.0 in stage 28.0 (TID 189)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 4.0 in stage 28.0 (TID 187). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO Executor: Finished task 5.0 in stage 28.0 (TID 188). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Starting task 8.0 in stage 28.0 (TID 191, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO Executor: Running task 8.0 in stage 28.0 (TID 191)
17/03/18 10:59:44 INFO Executor: Finished task 7.0 in stage 28.0 (TID 190). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO Executor: Finished task 1.0 in stage 28.0 (TID 184). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO Executor: Finished task 2.0 in stage 28.0 (TID 185). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Starting task 9.0 in stage 28.0 (TID 192, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO Executor: Running task 9.0 in stage 28.0 (TID 192)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 4.0 in stage 28.0 (TID 187) in 11 ms on localhost (executor driver) (1/12)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 5.0 in stage 28.0 (TID 188) in 11 ms on localhost (executor driver) (2/12)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 10.0 in stage 28.0 (TID 193, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO Executor: Running task 10.0 in stage 28.0 (TID 193)
17/03/18 10:59:44 INFO TaskSetManager: Starting task 11.0 in stage 28.0 (TID 194, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 7.0 in stage 28.0 (TID 190) in 11 ms on localhost (executor driver) (3/12)
17/03/18 10:59:44 INFO Executor: Running task 11.0 in stage 28.0 (TID 194)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 184) in 13 ms on localhost (executor driver) (4/12)
17/03/18 10:59:44 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 185) in 12 ms on localhost (executor driver) (5/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 0.0 in stage 28.0 (TID 183). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 183) in 19 ms on localhost (executor driver) (6/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 6.0 in stage 28.0 (TID 189). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Finished task 6.0 in stage 28.0 (TID 189) in 20 ms on localhost (executor driver) (7/12)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 9.0 in stage 28.0 (TID 192). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 9.0 in stage 28.0 (TID 192) in 12 ms on localhost (executor driver) (8/12)
17/03/18 10:59:44 INFO Executor: Finished task 8.0 in stage 28.0 (TID 191). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 8.0 in stage 28.0 (TID 191) in 13 ms on localhost (executor driver) (9/12)
17/03/18 10:59:44 INFO Executor: Finished task 11.0 in stage 28.0 (TID 194). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 11.0 in stage 28.0 (TID 194) in 12 ms on localhost (executor driver) (10/12)
17/03/18 10:59:44 INFO Executor: Finished task 10.0 in stage 28.0 (TID 193). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 10:59:44 INFO TaskSetManager: Finished task 10.0 in stage 28.0 (TID 193) in 13 ms on localhost (executor driver) (11/12)
17/03/18 10:59:44 INFO Executor: Finished task 3.0 in stage 28.0 (TID 186). 2057 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 3.0 in stage 28.0 (TID 186) in 26 ms on localhost (executor driver) (12/12)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/03/18 10:59:44 INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,028 s
17/03/18 10:59:44 INFO DAGScheduler: looking for newly runnable stages
17/03/18 10:59:44 INFO DAGScheduler: running: Set()
17/03/18 10:59:44 INFO DAGScheduler: waiting: Set(ResultStage 29)
17/03/18 10:59:44 INFO DAGScheduler: failed: Set()
17/03/18 10:59:44 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[85] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 10:59:44 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 10:59:44 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/03/18 10:59:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[85] at count at NativeMethodAccessorImpl.java:0)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/03/18 10:59:44 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 195, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 10:59:44 INFO Executor: Running task 0.0 in stage 29.0 (TID 195)
17/03/18 10:59:44 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 10:59:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 10:59:44 INFO Executor: Finished task 0.0 in stage 29.0 (TID 195). 2042 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 195) in 2 ms on localhost (executor driver) (1/1)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/03/18 10:59:44 INFO DAGScheduler: ResultStage 29 (count at NativeMethodAccessorImpl.java:0) finished in 0,004 s
17/03/18 10:59:44 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0,038116 s
17/03/18 10:59:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
LIMIT 10
17/03/18 10:59:44 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 10:59:44 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 10:59:44 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 10:59:44 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 10:59:44 INFO CodeGenerator: Code generated in 11.838846 ms
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 10:59:44 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 10:59:44 INFO SparkContext: Created broadcast 37 from collect at utils.scala:197
17/03/18 10:59:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 10:59:44 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 10:59:44 INFO DAGScheduler: Got job 15 (collect at utils.scala:197) with 1 output partitions
17/03/18 10:59:44 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:197)
17/03/18 10:59:44 INFO DAGScheduler: Parents of final stage: List()
17/03/18 10:59:44 INFO DAGScheduler: Missing parents: List()
17/03/18 10:59:44 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[88] at collect at utils.scala:197), which has no missing parents
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 18.7 KB, free 6.2 GB)
17/03/18 10:59:44 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 6.4 KB, free 6.2 GB)
17/03/18 10:59:44 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:38568 (size: 6.4 KB, free: 6.2 GB)
17/03/18 10:59:44 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/03/18 10:59:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[88] at collect at utils.scala:197)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/03/18 10:59:44 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 196, localhost, executor driver, partition 0, PROCESS_LOCAL, 7005 bytes)
17/03/18 10:59:44 INFO Executor: Running task 0.0 in stage 30.0 (TID 196)
17/03/18 10:59:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 10:59:44 INFO Executor: Finished task 0.0 in stage 30.0 (TID 196). 2691 bytes result sent to driver
17/03/18 10:59:44 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 196) in 184 ms on localhost (executor driver) (1/1)
17/03/18 10:59:44 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/03/18 10:59:44 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:197) finished in 0,184 s
17/03/18 10:59:44 INFO DAGScheduler: Job 15 finished: collect at utils.scala:197, took 0,187920 s
17/03/18 11:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = '3')
17/03/18 11:03:15 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:03:15 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(banner_pos#14 as double) = 3.0)
17/03/18 11:03:15 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 11:03:15 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:03:15 INFO CodeGenerator: Code generated in 13.513621 ms
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 39 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:03:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:03:15 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:03:15 INFO DAGScheduler: Registering RDD 91 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:03:15 INFO DAGScheduler: Final stage: ResultStage 32 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 31)
17/03/18 11:03:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 31)
17/03/18 11:03:15 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[91] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 13.3 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 6.3 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:38568 (size: 6.3 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/03/18 11:03:15 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[91] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Adding task set 31.0 with 12 tasks
17/03/18 11:03:15 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 197, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 198, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 199, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 200, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 4.0 in stage 31.0 (TID 201, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 5.0 in stage 31.0 (TID 202, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 6.0 in stage 31.0 (TID 203, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 7.0 in stage 31.0 (TID 204, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Running task 0.0 in stage 31.0 (TID 197)
17/03/18 11:03:15 INFO Executor: Running task 1.0 in stage 31.0 (TID 198)
17/03/18 11:03:15 INFO Executor: Running task 2.0 in stage 31.0 (TID 199)
17/03/18 11:03:15 INFO Executor: Running task 3.0 in stage 31.0 (TID 200)
17/03/18 11:03:15 INFO Executor: Running task 4.0 in stage 31.0 (TID 201)
17/03/18 11:03:15 INFO Executor: Running task 5.0 in stage 31.0 (TID 202)
17/03/18 11:03:15 INFO Executor: Running task 6.0 in stage 31.0 (TID 203)
17/03/18 11:03:15 INFO Executor: Running task 7.0 in stage 31.0 (TID 204)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 7.0 in stage 31.0 (TID 204). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Starting task 8.0 in stage 31.0 (TID 205, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Running task 8.0 in stage 31.0 (TID 205)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 2.0 in stage 31.0 (TID 199). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO Executor: Finished task 4.0 in stage 31.0 (TID 201). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO Executor: Finished task 5.0 in stage 31.0 (TID 202). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 7.0 in stage 31.0 (TID 204) in 110 ms on localhost (executor driver) (1/12)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 9.0 in stage 31.0 (TID 206, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Finished task 1.0 in stage 31.0 (TID 198). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO Executor: Finished task 6.0 in stage 31.0 (TID 203). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Starting task 10.0 in stage 31.0 (TID 207, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Running task 9.0 in stage 31.0 (TID 206)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 11.0 in stage 31.0 (TID 208, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 199) in 118 ms on localhost (executor driver) (2/12)
17/03/18 11:03:15 INFO Executor: Running task 10.0 in stage 31.0 (TID 207)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 5.0 in stage 31.0 (TID 202) in 117 ms on localhost (executor driver) (3/12)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 4.0 in stage 31.0 (TID 201) in 117 ms on localhost (executor driver) (4/12)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 198) in 118 ms on localhost (executor driver) (5/12)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 6.0 in stage 31.0 (TID 203) in 117 ms on localhost (executor driver) (6/12)
17/03/18 11:03:15 INFO Executor: Running task 11.0 in stage 31.0 (TID 208)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 3.0 in stage 31.0 (TID 200). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 200) in 120 ms on localhost (executor driver) (7/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 0.0 in stage 31.0 (TID 197). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 197) in 138 ms on localhost (executor driver) (8/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 8.0 in stage 31.0 (TID 205). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 8.0 in stage 31.0 (TID 205) in 40 ms on localhost (executor driver) (9/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 10.0 in stage 31.0 (TID 207). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:03:15 INFO TaskSetManager: Finished task 10.0 in stage 31.0 (TID 207) in 40 ms on localhost (executor driver) (10/12)
17/03/18 11:03:15 INFO Executor: Finished task 11.0 in stage 31.0 (TID 208). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO Executor: Finished task 9.0 in stage 31.0 (TID 206). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 11.0 in stage 31.0 (TID 208) in 42 ms on localhost (executor driver) (11/12)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 9.0 in stage 31.0 (TID 206) in 42 ms on localhost (executor driver) (12/12)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/03/18 11:03:15 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0,160 s
17/03/18 11:03:15 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:03:15 INFO DAGScheduler: running: Set()
17/03/18 11:03:15 INFO DAGScheduler: waiting: Set(ResultStage 32)
17/03/18 11:03:15 INFO DAGScheduler: failed: Set()
17/03/18 11:03:15 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[94] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/03/18 11:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[94] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/03/18 11:03:15 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 209, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:03:15 INFO Executor: Running task 0.0 in stage 32.0 (TID 209)
17/03/18 11:03:15 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:03:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:03:15 INFO Executor: Finished task 0.0 in stage 32.0 (TID 209). 2042 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 209) in 2 ms on localhost (executor driver) (1/1)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/03/18 11:03:15 INFO DAGScheduler: ResultStage 32 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 11:03:15 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0,169741 s
17/03/18 11:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = '3')
17/03/18 11:03:15 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:03:15 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(banner_pos#14 as double) = 3.0)
17/03/18 11:03:15 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 11:03:15 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 42 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:03:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:03:15 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:03:15 INFO DAGScheduler: Registering RDD 97 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO DAGScheduler: Got job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:03:15 INFO DAGScheduler: Final stage: ResultStage 34 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 33)
17/03/18 11:03:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 33)
17/03/18 11:03:15 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[97] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 13.3 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 6.3 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:38568 (size: 6.3 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/03/18 11:03:15 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[97] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Adding task set 33.0 with 12 tasks
17/03/18 11:03:15 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 210, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 211, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 212, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 3.0 in stage 33.0 (TID 213, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 4.0 in stage 33.0 (TID 214, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 5.0 in stage 33.0 (TID 215, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 6.0 in stage 33.0 (TID 216, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Starting task 7.0 in stage 33.0 (TID 217, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Running task 0.0 in stage 33.0 (TID 210)
17/03/18 11:03:15 INFO Executor: Running task 3.0 in stage 33.0 (TID 213)
17/03/18 11:03:15 INFO Executor: Running task 2.0 in stage 33.0 (TID 212)
17/03/18 11:03:15 INFO Executor: Running task 7.0 in stage 33.0 (TID 217)
17/03/18 11:03:15 INFO Executor: Running task 6.0 in stage 33.0 (TID 216)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Running task 4.0 in stage 33.0 (TID 214)
17/03/18 11:03:15 INFO Executor: Running task 1.0 in stage 33.0 (TID 211)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Running task 5.0 in stage 33.0 (TID 215)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 0.0 in stage 33.0 (TID 210). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Starting task 8.0 in stage 33.0 (TID 218, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Running task 8.0 in stage 33.0 (TID 218)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 210) in 71 ms on localhost (executor driver) (1/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 6.0 in stage 33.0 (TID 216). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Starting task 9.0 in stage 33.0 (TID 219, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Running task 9.0 in stage 33.0 (TID 219)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 6.0 in stage 33.0 (TID 216) in 72 ms on localhost (executor driver) (2/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 4.0 in stage 33.0 (TID 214). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Starting task 10.0 in stage 33.0 (TID 220, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO Executor: Running task 10.0 in stage 33.0 (TID 220)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 4.0 in stage 33.0 (TID 214) in 75 ms on localhost (executor driver) (3/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 3.0 in stage 33.0 (TID 213). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Starting task 11.0 in stage 33.0 (TID 221, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 3.0 in stage 33.0 (TID 213) in 81 ms on localhost (executor driver) (4/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 2.0 in stage 33.0 (TID 212). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 2.0 in stage 33.0 (TID 212) in 84 ms on localhost (executor driver) (5/12)
17/03/18 11:03:15 INFO Executor: Running task 11.0 in stage 33.0 (TID 221)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 1.0 in stage 33.0 (TID 211). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO Executor: Finished task 7.0 in stage 33.0 (TID 217). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 7.0 in stage 33.0 (TID 217) in 95 ms on localhost (executor driver) (6/12)
17/03/18 11:03:15 INFO TaskSetManager: Finished task 1.0 in stage 33.0 (TID 211) in 97 ms on localhost (executor driver) (7/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 5.0 in stage 33.0 (TID 215). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 5.0 in stage 33.0 (TID 215) in 102 ms on localhost (executor driver) (8/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 8.0 in stage 33.0 (TID 218). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 8.0 in stage 33.0 (TID 218) in 47 ms on localhost (executor driver) (9/12)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 11.0 in stage 33.0 (TID 221). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 11.0 in stage 33.0 (TID 221) in 40 ms on localhost (executor driver) (10/12)
17/03/18 11:03:15 INFO Executor: Finished task 9.0 in stage 33.0 (TID 219). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 9.0 in stage 33.0 (TID 219) in 51 ms on localhost (executor driver) (11/12)
17/03/18 11:03:15 INFO Executor: Finished task 10.0 in stage 33.0 (TID 220). 2119 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 10.0 in stage 33.0 (TID 220) in 50 ms on localhost (executor driver) (12/12)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/03/18 11:03:15 INFO DAGScheduler: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0) finished in 0,127 s
17/03/18 11:03:15 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:03:15 INFO DAGScheduler: running: Set()
17/03/18 11:03:15 INFO DAGScheduler: waiting: Set(ResultStage 34)
17/03/18 11:03:15 INFO DAGScheduler: failed: Set()
17/03/18 11:03:15 INFO DAGScheduler: Submitting ResultStage 34 (MapPartitionsRDD[100] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
17/03/18 11:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 34 (MapPartitionsRDD[100] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Adding task set 34.0 with 1 tasks
17/03/18 11:03:15 INFO TaskSetManager: Starting task 0.0 in stage 34.0 (TID 222, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:03:15 INFO Executor: Running task 0.0 in stage 34.0 (TID 222)
17/03/18 11:03:15 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:03:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:03:15 INFO Executor: Finished task 0.0 in stage 34.0 (TID 222). 2042 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 0.0 in stage 34.0 (TID 222) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Removed TaskSet 34.0, whose tasks have all completed, from pool 
17/03/18 11:03:15 INFO DAGScheduler: ResultStage 34 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 11:03:15 INFO DAGScheduler: Job 17 finished: count at NativeMethodAccessorImpl.java:0, took 0,136304 s
17/03/18 11:03:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM (SELECT *
FROM `train`
WHERE (`banner_pos` = '3')) `vhxerfpicq`
LIMIT 10
17/03/18 11:03:15 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:03:15 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(banner_pos#14 as double) = 3.0)
17/03/18 11:03:15 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:03:15 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 45 from collect at utils.scala:197
17/03/18 11:03:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:03:15 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:03:15 INFO DAGScheduler: Got job 18 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:03:15 INFO DAGScheduler: Final stage: ResultStage 35 (collect at utils.scala:197)
17/03/18 11:03:15 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:03:15 INFO DAGScheduler: Missing parents: List()
17/03/18 11:03:15 INFO DAGScheduler: Submitting ResultStage 35 (MapPartitionsRDD[103] at collect at utils.scala:197), which has no missing parents
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 21.1 KB, free 6.2 GB)
17/03/18 11:03:15 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 7.2 KB, free 6.2 GB)
17/03/18 11:03:15 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:38568 (size: 7.2 KB, free: 6.2 GB)
17/03/18 11:03:15 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/03/18 11:03:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 35 (MapPartitionsRDD[103] at collect at utils.scala:197)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Adding task set 35.0 with 1 tasks
17/03/18 11:03:15 INFO TaskSetManager: Starting task 0.0 in stage 35.0 (TID 223, localhost, executor driver, partition 0, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:03:15 INFO Executor: Running task 0.0 in stage 35.0 (TID 223)
17/03/18 11:03:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:03:15 INFO Executor: Finished task 0.0 in stage 35.0 (TID 223). 2360 bytes result sent to driver
17/03/18 11:03:15 INFO TaskSetManager: Finished task 0.0 in stage 35.0 (TID 223) in 82 ms on localhost (executor driver) (1/1)
17/03/18 11:03:15 INFO TaskSchedulerImpl: Removed TaskSet 35.0, whose tasks have all completed, from pool 
17/03/18 11:03:15 INFO DAGScheduler: ResultStage 35 (collect at utils.scala:197) finished in 0,082 s
17/03/18 11:03:15 INFO DAGScheduler: Job 18 finished: collect at utils.scala:197, took 0,084866 s
17/03/18 11:03:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = '3')
17/03/18 11:03:23 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:03:23 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(banner_pos#14 as double) = 3.0)
17/03/18 11:03:23 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:03:23 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:03:23 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:03:23 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:03:23 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:03:23 INFO SparkContext: Created broadcast 47 from collect at utils.scala:197
17/03/18 11:03:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:03:23 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:03:23 INFO DAGScheduler: Got job 19 (collect at utils.scala:197) with 12 output partitions
17/03/18 11:03:23 INFO DAGScheduler: Final stage: ResultStage 36 (collect at utils.scala:197)
17/03/18 11:03:23 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:03:23 INFO DAGScheduler: Missing parents: List()
17/03/18 11:03:23 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[106] at collect at utils.scala:197), which has no missing parents
17/03/18 11:03:23 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 21.2 KB, free 6.2 GB)
17/03/18 11:03:23 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 7.3 KB, free 6.2 GB)
17/03/18 11:03:23 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on 127.0.0.1:38568 (size: 7.3 KB, free: 6.2 GB)
17/03/18 11:03:23 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:996
17/03/18 11:03:23 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 36 (MapPartitionsRDD[106] at collect at utils.scala:197)
17/03/18 11:03:23 INFO TaskSchedulerImpl: Adding task set 36.0 with 12 tasks
17/03/18 11:03:23 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 224, localhost, executor driver, partition 0, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 1.0 in stage 36.0 (TID 225, localhost, executor driver, partition 1, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 2.0 in stage 36.0 (TID 226, localhost, executor driver, partition 2, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 3.0 in stage 36.0 (TID 227, localhost, executor driver, partition 3, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 4.0 in stage 36.0 (TID 228, localhost, executor driver, partition 4, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 5.0 in stage 36.0 (TID 229, localhost, executor driver, partition 5, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 6.0 in stage 36.0 (TID 230, localhost, executor driver, partition 6, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO TaskSetManager: Starting task 7.0 in stage 36.0 (TID 231, localhost, executor driver, partition 7, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:23 INFO Executor: Running task 2.0 in stage 36.0 (TID 226)
17/03/18 11:03:23 INFO Executor: Running task 4.0 in stage 36.0 (TID 228)
17/03/18 11:03:23 INFO Executor: Running task 6.0 in stage 36.0 (TID 230)
17/03/18 11:03:23 INFO Executor: Running task 0.0 in stage 36.0 (TID 224)
17/03/18 11:03:23 INFO Executor: Running task 5.0 in stage 36.0 (TID 229)
17/03/18 11:03:23 INFO Executor: Running task 3.0 in stage 36.0 (TID 227)
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:03:23 INFO Executor: Running task 1.0 in stage 36.0 (TID 225)
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:03:23 INFO Executor: Running task 7.0 in stage 36.0 (TID 231)
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:03:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:03:24 INFO Executor: Finished task 0.0 in stage 36.0 (TID 224). 5513 bytes result sent to driver
17/03/18 11:03:24 INFO TaskSetManager: Starting task 8.0 in stage 36.0 (TID 232, localhost, executor driver, partition 8, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:24 INFO Executor: Running task 8.0 in stage 36.0 (TID 232)
17/03/18 11:03:24 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 224) in 723 ms on localhost (executor driver) (1/12)
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:03:24 INFO Executor: Finished task 8.0 in stage 36.0 (TID 232). 4749 bytes result sent to driver
17/03/18 11:03:24 INFO TaskSetManager: Starting task 9.0 in stage 36.0 (TID 233, localhost, executor driver, partition 9, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:24 INFO Executor: Running task 9.0 in stage 36.0 (TID 233)
17/03/18 11:03:24 INFO TaskSetManager: Finished task 8.0 in stage 36.0 (TID 232) in 535 ms on localhost (executor driver) (2/12)
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:03:24 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:38568 in memory (size: 6.3 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5961
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5962
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5963
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5964
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5965
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5966
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5967
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5968
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5969
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5970
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5971
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5972
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5973
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5974
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5975
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_42_piece0 on 127.0.0.1:38568 in memory (size: 24.4 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned shuffle 14
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:38568 in memory (size: 6.3 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_46_piece0 on 127.0.0.1:38568 in memory (size: 7.2 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4787
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4788
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4789
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4790
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4791
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4792
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4793
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4794
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4795
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4796
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4797
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4798
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4799
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 4800
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:38568 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned shuffle 11
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:38568 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5161
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5162
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5163
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5164
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5165
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5166
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5167
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5168
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5169
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5170
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5171
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5172
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5173
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5174
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:38568 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned shuffle 12
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:38568 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:38568 in memory (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5586
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5587
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5588
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5589
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5590
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5591
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5592
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5593
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5594
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5595
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5596
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5597
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5598
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5599
17/03/18 11:03:25 INFO ContextCleaner: Cleaned accumulator 5600
17/03/18 11:03:25 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:38568 in memory (size: 24.4 KB, free: 6.2 GB)
17/03/18 11:03:25 INFO ContextCleaner: Cleaned shuffle 13
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:03:25 INFO Executor: Finished task 5.0 in stage 36.0 (TID 229). 5536 bytes result sent to driver
17/03/18 11:03:25 INFO TaskSetManager: Starting task 10.0 in stage 36.0 (TID 234, localhost, executor driver, partition 10, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:25 INFO TaskSetManager: Finished task 5.0 in stage 36.0 (TID 229) in 1842 ms on localhost (executor driver) (3/12)
17/03/18 11:03:25 INFO Executor: Running task 10.0 in stage 36.0 (TID 234)
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:03:25 INFO Executor: Finished task 4.0 in stage 36.0 (TID 228). 17742 bytes result sent to driver
17/03/18 11:03:25 INFO TaskSetManager: Starting task 11.0 in stage 36.0 (TID 235, localhost, executor driver, partition 11, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:03:25 INFO TaskSetManager: Finished task 4.0 in stage 36.0 (TID 228) in 2229 ms on localhost (executor driver) (4/12)
17/03/18 11:03:25 INFO Executor: Running task 11.0 in stage 36.0 (TID 235)
17/03/18 11:03:25 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:03:26 INFO Executor: Finished task 6.0 in stage 36.0 (TID 230). 23115 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 6.0 in stage 36.0 (TID 230) in 2457 ms on localhost (executor driver) (5/12)
17/03/18 11:03:26 INFO Executor: Finished task 9.0 in stage 36.0 (TID 233). 5012 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 9.0 in stage 36.0 (TID 233) in 1213 ms on localhost (executor driver) (6/12)
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:03:26 INFO Executor: Finished task 2.0 in stage 36.0 (TID 226). 19358 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 2.0 in stage 36.0 (TID 226) in 2481 ms on localhost (executor driver) (7/12)
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:03:26 INFO Executor: Finished task 3.0 in stage 36.0 (TID 227). 4291 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 3.0 in stage 36.0 (TID 227) in 2792 ms on localhost (executor driver) (8/12)
17/03/18 11:03:26 INFO Executor: Finished task 1.0 in stage 36.0 (TID 225). 9767 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 1.0 in stage 36.0 (TID 225) in 2828 ms on localhost (executor driver) (9/12)
17/03/18 11:03:26 INFO Executor: Finished task 10.0 in stage 36.0 (TID 234). 4146 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 10.0 in stage 36.0 (TID 234) in 997 ms on localhost (executor driver) (10/12)
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:03:26 INFO Executor: Finished task 7.0 in stage 36.0 (TID 231). 7709 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 7.0 in stage 36.0 (TID 231) in 2881 ms on localhost (executor driver) (11/12)
17/03/18 11:03:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:03:26 INFO Executor: Finished task 11.0 in stage 36.0 (TID 235). 3872 bytes result sent to driver
17/03/18 11:03:26 INFO TaskSetManager: Finished task 11.0 in stage 36.0 (TID 235) in 744 ms on localhost (executor driver) (12/12)
17/03/18 11:03:26 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool 
17/03/18 11:03:26 INFO DAGScheduler: ResultStage 36 (collect at utils.scala:197) finished in 2,974 s
17/03/18 11:03:26 INFO DAGScheduler: Job 19 finished: collect at utils.scala:197, took 2,977714 s
17/03/18 11:05:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 11:05:16 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:05:16 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 11:05:16 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:05:16 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:05:16 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:05:16 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:05:16 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:05:16 INFO SparkContext: Created broadcast 49 from collect at utils.scala:197
17/03/18 11:05:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:05:16 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:05:16 INFO DAGScheduler: Got job 20 (collect at utils.scala:197) with 12 output partitions
17/03/18 11:05:16 INFO DAGScheduler: Final stage: ResultStage 37 (collect at utils.scala:197)
17/03/18 11:05:16 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:05:16 INFO DAGScheduler: Missing parents: List()
17/03/18 11:05:16 INFO DAGScheduler: Submitting ResultStage 37 (MapPartitionsRDD[109] at collect at utils.scala:197), which has no missing parents
17/03/18 11:05:16 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 22.8 KB, free 6.2 GB)
17/03/18 11:05:16 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 8.1 KB, free 6.2 GB)
17/03/18 11:05:16 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on 127.0.0.1:38568 (size: 8.1 KB, free: 6.2 GB)
17/03/18 11:05:16 INFO SparkContext: Created broadcast 50 from broadcast at DAGScheduler.scala:996
17/03/18 11:05:16 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 37 (MapPartitionsRDD[109] at collect at utils.scala:197)
17/03/18 11:05:16 INFO TaskSchedulerImpl: Adding task set 37.0 with 12 tasks
17/03/18 11:05:16 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 236, localhost, executor driver, partition 0, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 1.0 in stage 37.0 (TID 237, localhost, executor driver, partition 1, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 2.0 in stage 37.0 (TID 238, localhost, executor driver, partition 2, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 3.0 in stage 37.0 (TID 239, localhost, executor driver, partition 3, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 4.0 in stage 37.0 (TID 240, localhost, executor driver, partition 4, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 5.0 in stage 37.0 (TID 241, localhost, executor driver, partition 5, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 6.0 in stage 37.0 (TID 242, localhost, executor driver, partition 6, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO TaskSetManager: Starting task 7.0 in stage 37.0 (TID 243, localhost, executor driver, partition 7, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:16 INFO Executor: Running task 0.0 in stage 37.0 (TID 236)
17/03/18 11:05:16 INFO Executor: Running task 1.0 in stage 37.0 (TID 237)
17/03/18 11:05:16 INFO Executor: Running task 2.0 in stage 37.0 (TID 238)
17/03/18 11:05:16 INFO Executor: Running task 3.0 in stage 37.0 (TID 239)
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:05:16 INFO Executor: Running task 4.0 in stage 37.0 (TID 240)
17/03/18 11:05:16 INFO Executor: Running task 5.0 in stage 37.0 (TID 241)
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:05:16 INFO Executor: Running task 6.0 in stage 37.0 (TID 242)
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:05:16 INFO Executor: Running task 7.0 in stage 37.0 (TID 243)
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:05:16 INFO BlockManagerInfo: Removed broadcast_48_piece0 on 127.0.0.1:38568 in memory (size: 7.3 KB, free: 6.2 GB)
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:05:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:05:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:05:18 INFO Executor: Finished task 6.0 in stage 37.0 (TID 242). 23115 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Starting task 8.0 in stage 37.0 (TID 244, localhost, executor driver, partition 8, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:18 INFO TaskSetManager: Finished task 6.0 in stage 37.0 (TID 242) in 2017 ms on localhost (executor driver) (1/12)
17/03/18 11:05:18 INFO Executor: Running task 8.0 in stage 37.0 (TID 244)
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:05:18 INFO Executor: Finished task 2.0 in stage 37.0 (TID 238). 19358 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Starting task 9.0 in stage 37.0 (TID 245, localhost, executor driver, partition 9, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:18 INFO TaskSetManager: Finished task 2.0 in stage 37.0 (TID 238) in 2161 ms on localhost (executor driver) (2/12)
17/03/18 11:05:18 INFO Executor: Running task 9.0 in stage 37.0 (TID 245)
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:05:18 INFO Executor: Finished task 7.0 in stage 37.0 (TID 243). 7709 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Starting task 10.0 in stage 37.0 (TID 246, localhost, executor driver, partition 10, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:18 INFO TaskSetManager: Finished task 7.0 in stage 37.0 (TID 243) in 2172 ms on localhost (executor driver) (3/12)
17/03/18 11:05:18 INFO Executor: Running task 10.0 in stage 37.0 (TID 246)
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:05:18 INFO Executor: Finished task 4.0 in stage 37.0 (TID 240). 17742 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Starting task 11.0 in stage 37.0 (TID 247, localhost, executor driver, partition 11, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:05:18 INFO Executor: Running task 11.0 in stage 37.0 (TID 247)
17/03/18 11:05:18 INFO TaskSetManager: Finished task 4.0 in stage 37.0 (TID 240) in 2189 ms on localhost (executor driver) (4/12)
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:05:18 INFO Executor: Finished task 1.0 in stage 37.0 (TID 237). 9767 bytes result sent to driver
17/03/18 11:05:18 INFO Executor: Finished task 0.0 in stage 37.0 (TID 236). 5499 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Finished task 1.0 in stage 37.0 (TID 237) in 2212 ms on localhost (executor driver) (5/12)
17/03/18 11:05:18 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 236) in 2212 ms on localhost (executor driver) (6/12)
17/03/18 11:05:18 INFO Executor: Finished task 5.0 in stage 37.0 (TID 241). 5536 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Finished task 5.0 in stage 37.0 (TID 241) in 2291 ms on localhost (executor driver) (7/12)
17/03/18 11:05:18 INFO Executor: Finished task 3.0 in stage 37.0 (TID 239). 4291 bytes result sent to driver
17/03/18 11:05:18 INFO TaskSetManager: Finished task 3.0 in stage 37.0 (TID 239) in 2326 ms on localhost (executor driver) (8/12)
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:05:18 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:05:19 INFO Executor: Finished task 11.0 in stage 37.0 (TID 247). 3872 bytes result sent to driver
17/03/18 11:05:19 INFO TaskSetManager: Finished task 11.0 in stage 37.0 (TID 247) in 684 ms on localhost (executor driver) (9/12)
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:05:19 INFO Executor: Finished task 10.0 in stage 37.0 (TID 246). 4146 bytes result sent to driver
17/03/18 11:05:19 INFO TaskSetManager: Finished task 10.0 in stage 37.0 (TID 246) in 931 ms on localhost (executor driver) (10/12)
17/03/18 11:05:19 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:05:19 INFO Executor: Finished task 8.0 in stage 37.0 (TID 244). 4822 bytes result sent to driver
17/03/18 11:05:19 INFO TaskSetManager: Finished task 8.0 in stage 37.0 (TID 244) in 1384 ms on localhost (executor driver) (11/12)
17/03/18 11:05:19 INFO Executor: Finished task 9.0 in stage 37.0 (TID 245). 5012 bytes result sent to driver
17/03/18 11:05:19 INFO TaskSetManager: Finished task 9.0 in stage 37.0 (TID 245) in 1325 ms on localhost (executor driver) (12/12)
17/03/18 11:05:19 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool 
17/03/18 11:05:19 INFO DAGScheduler: ResultStage 37 (collect at utils.scala:197) finished in 3,488 s
17/03/18 11:05:19 INFO DAGScheduler: Job 20 finished: collect at utils.scala:197, took 3,490715 s
17/03/18 11:09:21 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `cnt`
FROM (SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)) `vljjlgnrwu`
17/03/18 11:09:21 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:09:21 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 11:09:21 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 11:09:21 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:09:21 INFO CodeGenerator: Code generated in 14.615856 ms
17/03/18 11:09:21 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 11:09:21 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 11:09:21 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 11:09:21 INFO SparkContext: Created broadcast 51 from collect at utils.scala:197
17/03/18 11:09:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:09:21 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:09:21 INFO DAGScheduler: Registering RDD 112 (collect at utils.scala:197)
17/03/18 11:09:21 INFO DAGScheduler: Got job 21 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:09:21 INFO DAGScheduler: Final stage: ResultStage 39 (collect at utils.scala:197)
17/03/18 11:09:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
17/03/18 11:09:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 38)
17/03/18 11:09:21 INFO DAGScheduler: Submitting ShuffleMapStage 38 (MapPartitionsRDD[112] at collect at utils.scala:197), which has no missing parents
17/03/18 11:09:21 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 15.2 KB, free 6.2 GB)
17/03/18 11:09:21 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 7.3 KB, free 6.2 GB)
17/03/18 11:09:21 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on 127.0.0.1:38568 (size: 7.3 KB, free: 6.2 GB)
17/03/18 11:09:21 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:996
17/03/18 11:09:21 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 38 (MapPartitionsRDD[112] at collect at utils.scala:197)
17/03/18 11:09:21 INFO TaskSchedulerImpl: Adding task set 38.0 with 12 tasks
17/03/18 11:09:21 INFO TaskSetManager: Starting task 0.0 in stage 38.0 (TID 248, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 1.0 in stage 38.0 (TID 249, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 2.0 in stage 38.0 (TID 250, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 3.0 in stage 38.0 (TID 251, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 4.0 in stage 38.0 (TID 252, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 5.0 in stage 38.0 (TID 253, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 6.0 in stage 38.0 (TID 254, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO TaskSetManager: Starting task 7.0 in stage 38.0 (TID 255, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:21 INFO Executor: Running task 2.0 in stage 38.0 (TID 250)
17/03/18 11:09:21 INFO Executor: Running task 0.0 in stage 38.0 (TID 248)
17/03/18 11:09:21 INFO Executor: Running task 3.0 in stage 38.0 (TID 251)
17/03/18 11:09:21 INFO Executor: Running task 1.0 in stage 38.0 (TID 249)
17/03/18 11:09:21 INFO Executor: Running task 6.0 in stage 38.0 (TID 254)
17/03/18 11:09:21 INFO Executor: Running task 4.0 in stage 38.0 (TID 252)
17/03/18 11:09:21 INFO Executor: Running task 5.0 in stage 38.0 (TID 253)
17/03/18 11:09:21 INFO Executor: Running task 7.0 in stage 38.0 (TID 255)
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:09:21 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:09:22 INFO BlockManagerInfo: Removed broadcast_50_piece0 on 127.0.0.1:38568 in memory (size: 8.1 KB, free: 6.2 GB)
17/03/18 11:09:22 INFO ContextCleaner: Cleaned accumulator 7020
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 5.0 in stage 38.0 (TID 253). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Starting task 8.0 in stage 38.0 (TID 256, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:22 INFO Executor: Running task 8.0 in stage 38.0 (TID 256)
17/03/18 11:09:22 INFO TaskSetManager: Finished task 5.0 in stage 38.0 (TID 253) in 718 ms on localhost (executor driver) (1/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 1.0 in stage 38.0 (TID 249). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Starting task 9.0 in stage 38.0 (TID 257, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:22 INFO Executor: Running task 9.0 in stage 38.0 (TID 257)
17/03/18 11:09:22 INFO TaskSetManager: Finished task 1.0 in stage 38.0 (TID 249) in 753 ms on localhost (executor driver) (2/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 4.0 in stage 38.0 (TID 252). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Starting task 10.0 in stage 38.0 (TID 258, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:22 INFO Executor: Running task 10.0 in stage 38.0 (TID 258)
17/03/18 11:09:22 INFO TaskSetManager: Finished task 4.0 in stage 38.0 (TID 252) in 788 ms on localhost (executor driver) (3/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 0.0 in stage 38.0 (TID 248). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Starting task 11.0 in stage 38.0 (TID 259, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:22 INFO Executor: Running task 11.0 in stage 38.0 (TID 259)
17/03/18 11:09:22 INFO TaskSetManager: Finished task 0.0 in stage 38.0 (TID 248) in 824 ms on localhost (executor driver) (4/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 2.0 in stage 38.0 (TID 250). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 2.0 in stage 38.0 (TID 250) in 862 ms on localhost (executor driver) (5/12)
17/03/18 11:09:22 INFO Executor: Finished task 7.0 in stage 38.0 (TID 255). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 7.0 in stage 38.0 (TID 255) in 863 ms on localhost (executor driver) (6/12)
17/03/18 11:09:22 INFO Executor: Finished task 3.0 in stage 38.0 (TID 251). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 3.0 in stage 38.0 (TID 251) in 876 ms on localhost (executor driver) (7/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 11.0 in stage 38.0 (TID 259). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:09:22 INFO TaskSetManager: Finished task 11.0 in stage 38.0 (TID 259) in 343 ms on localhost (executor driver) (8/12)
17/03/18 11:09:22 INFO Executor: Finished task 6.0 in stage 38.0 (TID 254). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 6.0 in stage 38.0 (TID 254) in 1171 ms on localhost (executor driver) (9/12)
17/03/18 11:09:22 INFO Executor: Finished task 8.0 in stage 38.0 (TID 256). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 8.0 in stage 38.0 (TID 256) in 458 ms on localhost (executor driver) (10/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 9.0 in stage 38.0 (TID 257). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 9.0 in stage 38.0 (TID 257) in 500 ms on localhost (executor driver) (11/12)
17/03/18 11:09:22 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:09:22 INFO Executor: Finished task 10.0 in stage 38.0 (TID 258). 2192 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 10.0 in stage 38.0 (TID 258) in 518 ms on localhost (executor driver) (12/12)
17/03/18 11:09:22 INFO TaskSchedulerImpl: Removed TaskSet 38.0, whose tasks have all completed, from pool 
17/03/18 11:09:22 INFO DAGScheduler: ShuffleMapStage 38 (collect at utils.scala:197) finished in 1,308 s
17/03/18 11:09:22 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:09:22 INFO DAGScheduler: running: Set()
17/03/18 11:09:22 INFO DAGScheduler: waiting: Set(ResultStage 39)
17/03/18 11:09:22 INFO DAGScheduler: failed: Set()
17/03/18 11:09:22 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[115] at collect at utils.scala:197), which has no missing parents
17/03/18 11:09:22 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:09:22 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:09:22 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:09:22 INFO SparkContext: Created broadcast 53 from broadcast at DAGScheduler.scala:996
17/03/18 11:09:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[115] at collect at utils.scala:197)
17/03/18 11:09:22 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks
17/03/18 11:09:22 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 260, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:09:22 INFO Executor: Running task 0.0 in stage 39.0 (TID 260)
17/03/18 11:09:22 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:09:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:09:22 INFO Executor: Finished task 0.0 in stage 39.0 (TID 260). 2042 bytes result sent to driver
17/03/18 11:09:22 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 260) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:09:22 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool 
17/03/18 11:09:22 INFO DAGScheduler: ResultStage 39 (collect at utils.scala:197) finished in 0,004 s
17/03/18 11:09:22 INFO DAGScheduler: Job 21 finished: collect at utils.scala:197, took 1,318968 s
17/03/18 11:09:26 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `cnt`
FROM (SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)) `ansecfddea`
17/03/18 11:09:26 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:09:26 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 11:09:26 INFO FileSourceStrategy: Output Data Schema: struct<banner_pos: int>
17/03/18 11:09:26 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:09:26 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 297.2 KB, free 6.2 GB)
17/03/18 11:09:26 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 24.4 KB, free 6.2 GB)
17/03/18 11:09:26 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on 127.0.0.1:38568 (size: 24.4 KB, free: 6.2 GB)
17/03/18 11:09:26 INFO SparkContext: Created broadcast 54 from collect at utils.scala:197
17/03/18 11:09:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:09:26 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:09:26 INFO DAGScheduler: Registering RDD 118 (collect at utils.scala:197)
17/03/18 11:09:26 INFO DAGScheduler: Got job 22 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:09:26 INFO DAGScheduler: Final stage: ResultStage 41 (collect at utils.scala:197)
17/03/18 11:09:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 40)
17/03/18 11:09:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
17/03/18 11:09:26 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[118] at collect at utils.scala:197), which has no missing parents
17/03/18 11:09:26 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 15.2 KB, free 6.2 GB)
17/03/18 11:09:26 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 7.3 KB, free 6.2 GB)
17/03/18 11:09:26 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on 127.0.0.1:38568 (size: 7.3 KB, free: 6.2 GB)
17/03/18 11:09:26 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:996
17/03/18 11:09:26 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[118] at collect at utils.scala:197)
17/03/18 11:09:26 INFO TaskSchedulerImpl: Adding task set 40.0 with 12 tasks
17/03/18 11:09:26 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 261, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 1.0 in stage 40.0 (TID 262, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 2.0 in stage 40.0 (TID 263, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 3.0 in stage 40.0 (TID 264, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 4.0 in stage 40.0 (TID 265, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 5.0 in stage 40.0 (TID 266, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 6.0 in stage 40.0 (TID 267, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO TaskSetManager: Starting task 7.0 in stage 40.0 (TID 268, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:26 INFO Executor: Running task 1.0 in stage 40.0 (TID 262)
17/03/18 11:09:26 INFO Executor: Running task 4.0 in stage 40.0 (TID 265)
17/03/18 11:09:26 INFO Executor: Running task 3.0 in stage 40.0 (TID 264)
17/03/18 11:09:26 INFO Executor: Running task 7.0 in stage 40.0 (TID 268)
17/03/18 11:09:26 INFO Executor: Running task 2.0 in stage 40.0 (TID 263)
17/03/18 11:09:26 INFO Executor: Running task 0.0 in stage 40.0 (TID 261)
17/03/18 11:09:26 INFO Executor: Running task 5.0 in stage 40.0 (TID 266)
17/03/18 11:09:26 INFO Executor: Running task 6.0 in stage 40.0 (TID 267)
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:09:26 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:09:27 INFO BlockManagerInfo: Removed broadcast_53_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:09:27 INFO ContextCleaner: Cleaned accumulator 7395
17/03/18 11:09:27 INFO BlockManagerInfo: Removed broadcast_52_piece0 on 127.0.0.1:38568 in memory (size: 7.3 KB, free: 6.2 GB)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 6.0 in stage 40.0 (TID 267). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Starting task 8.0 in stage 40.0 (TID 269, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:27 INFO Executor: Running task 8.0 in stage 40.0 (TID 269)
17/03/18 11:09:27 INFO TaskSetManager: Finished task 6.0 in stage 40.0 (TID 267) in 505 ms on localhost (executor driver) (1/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 4.0 in stage 40.0 (TID 265). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Starting task 9.0 in stage 40.0 (TID 270, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:27 INFO Executor: Running task 9.0 in stage 40.0 (TID 270)
17/03/18 11:09:27 INFO TaskSetManager: Finished task 4.0 in stage 40.0 (TID 265) in 658 ms on localhost (executor driver) (2/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 0.0 in stage 40.0 (TID 261). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Starting task 10.0 in stage 40.0 (TID 271, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:27 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 261) in 669 ms on localhost (executor driver) (3/12)
17/03/18 11:09:27 INFO Executor: Running task 10.0 in stage 40.0 (TID 271)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 7.0 in stage 40.0 (TID 268). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Starting task 11.0 in stage 40.0 (TID 272, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:09:27 INFO Executor: Running task 11.0 in stage 40.0 (TID 272)
17/03/18 11:09:27 INFO TaskSetManager: Finished task 7.0 in stage 40.0 (TID 268) in 696 ms on localhost (executor driver) (4/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 3.0 in stage 40.0 (TID 264). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 3.0 in stage 40.0 (TID 264) in 713 ms on localhost (executor driver) (5/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 2.0 in stage 40.0 (TID 263). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 2.0 in stage 40.0 (TID 263) in 736 ms on localhost (executor driver) (6/12)
17/03/18 11:09:27 INFO Executor: Finished task 5.0 in stage 40.0 (TID 266). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 5.0 in stage 40.0 (TID 266) in 739 ms on localhost (executor driver) (7/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 1.0 in stage 40.0 (TID 262). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 1.0 in stage 40.0 (TID 262) in 755 ms on localhost (executor driver) (8/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 8.0 in stage 40.0 (TID 269). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 8.0 in stage 40.0 (TID 269) in 361 ms on localhost (executor driver) (9/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 11.0 in stage 40.0 (TID 272). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 11.0 in stage 40.0 (TID 272) in 189 ms on localhost (executor driver) (10/12)
17/03/18 11:09:27 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:09:27 INFO Executor: Finished task 9.0 in stage 40.0 (TID 270). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 9.0 in stage 40.0 (TID 270) in 268 ms on localhost (executor driver) (11/12)
17/03/18 11:09:27 INFO Executor: Finished task 10.0 in stage 40.0 (TID 271). 2192 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 10.0 in stage 40.0 (TID 271) in 263 ms on localhost (executor driver) (12/12)
17/03/18 11:09:27 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool 
17/03/18 11:09:27 INFO DAGScheduler: ShuffleMapStage 40 (collect at utils.scala:197) finished in 0,932 s
17/03/18 11:09:27 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:09:27 INFO DAGScheduler: running: Set()
17/03/18 11:09:27 INFO DAGScheduler: waiting: Set(ResultStage 41)
17/03/18 11:09:27 INFO DAGScheduler: failed: Set()
17/03/18 11:09:27 INFO DAGScheduler: Submitting ResultStage 41 (MapPartitionsRDD[121] at collect at utils.scala:197), which has no missing parents
17/03/18 11:09:27 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:09:27 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:09:27 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:09:27 INFO SparkContext: Created broadcast 56 from broadcast at DAGScheduler.scala:996
17/03/18 11:09:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 41 (MapPartitionsRDD[121] at collect at utils.scala:197)
17/03/18 11:09:27 INFO TaskSchedulerImpl: Adding task set 41.0 with 1 tasks
17/03/18 11:09:27 INFO TaskSetManager: Starting task 0.0 in stage 41.0 (TID 273, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:09:27 INFO Executor: Running task 0.0 in stage 41.0 (TID 273)
17/03/18 11:09:27 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:09:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 11:09:27 INFO Executor: Finished task 0.0 in stage 41.0 (TID 273). 2042 bytes result sent to driver
17/03/18 11:09:27 INFO TaskSetManager: Finished task 0.0 in stage 41.0 (TID 273) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:09:27 INFO TaskSchedulerImpl: Removed TaskSet 41.0, whose tasks have all completed, from pool 
17/03/18 11:09:27 INFO DAGScheduler: ResultStage 41 (collect at utils.scala:197) finished in 0,004 s
17/03/18 11:09:27 INFO DAGScheduler: Job 22 finished: collect at utils.scala:197, took 0,942974 s
17/03/18 11:09:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 11:09:30 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:09:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 11:09:30 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:09:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:09:30 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:09:30 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:09:30 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:09:30 INFO SparkContext: Created broadcast 57 from collect at utils.scala:197
17/03/18 11:09:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:09:30 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:09:30 INFO DAGScheduler: Got job 23 (collect at utils.scala:197) with 12 output partitions
17/03/18 11:09:30 INFO DAGScheduler: Final stage: ResultStage 42 (collect at utils.scala:197)
17/03/18 11:09:30 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:09:30 INFO DAGScheduler: Missing parents: List()
17/03/18 11:09:30 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[124] at collect at utils.scala:197), which has no missing parents
17/03/18 11:09:30 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 22.8 KB, free 6.2 GB)
17/03/18 11:09:30 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 8.1 KB, free 6.2 GB)
17/03/18 11:09:30 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on 127.0.0.1:38568 (size: 8.1 KB, free: 6.2 GB)
17/03/18 11:09:30 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:996
17/03/18 11:09:30 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 42 (MapPartitionsRDD[124] at collect at utils.scala:197)
17/03/18 11:09:30 INFO TaskSchedulerImpl: Adding task set 42.0 with 12 tasks
17/03/18 11:09:30 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 274, localhost, executor driver, partition 0, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 1.0 in stage 42.0 (TID 275, localhost, executor driver, partition 1, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 2.0 in stage 42.0 (TID 276, localhost, executor driver, partition 2, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 3.0 in stage 42.0 (TID 277, localhost, executor driver, partition 3, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 4.0 in stage 42.0 (TID 278, localhost, executor driver, partition 4, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 5.0 in stage 42.0 (TID 279, localhost, executor driver, partition 5, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 6.0 in stage 42.0 (TID 280, localhost, executor driver, partition 6, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO TaskSetManager: Starting task 7.0 in stage 42.0 (TID 281, localhost, executor driver, partition 7, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:30 INFO Executor: Running task 2.0 in stage 42.0 (TID 276)
17/03/18 11:09:30 INFO Executor: Running task 0.0 in stage 42.0 (TID 274)
17/03/18 11:09:30 INFO Executor: Running task 3.0 in stage 42.0 (TID 277)
17/03/18 11:09:30 INFO Executor: Running task 7.0 in stage 42.0 (TID 281)
17/03/18 11:09:30 INFO Executor: Running task 5.0 in stage 42.0 (TID 279)
17/03/18 11:09:30 INFO Executor: Running task 6.0 in stage 42.0 (TID 280)
17/03/18 11:09:30 INFO Executor: Running task 1.0 in stage 42.0 (TID 275)
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:09:30 INFO Executor: Running task 4.0 in stage 42.0 (TID 278)
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:09:30 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:09:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:09:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:09:33 INFO BlockManagerInfo: Removed broadcast_55_piece0 on 127.0.0.1:38568 in memory (size: 7.3 KB, free: 6.2 GB)
17/03/18 11:09:33 INFO BlockManagerInfo: Removed broadcast_56_piece0 on 127.0.0.1:38568 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:09:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:09:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:09:33 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:09:34 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:09:34 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:09:34 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:09:36 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:09:36 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:09:36 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:09:36 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:09:36 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:09:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:09:37 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:09:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:09:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:09:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:09:38 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:09:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:09:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:09:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:09:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:09:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:09:41 INFO Executor: Finished task 3.0 in stage 42.0 (TID 277). 4291 bytes result sent to driver
17/03/18 11:09:41 INFO TaskSetManager: Starting task 8.0 in stage 42.0 (TID 282, localhost, executor driver, partition 8, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:41 INFO Executor: Running task 8.0 in stage 42.0 (TID 282)
17/03/18 11:09:41 INFO TaskSetManager: Finished task 3.0 in stage 42.0 (TID 277) in 10668 ms on localhost (executor driver) (1/12)
17/03/18 11:09:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:09:41 INFO Executor: Finished task 2.0 in stage 42.0 (TID 276). 19358 bytes result sent to driver
17/03/18 11:09:41 INFO TaskSetManager: Starting task 9.0 in stage 42.0 (TID 283, localhost, executor driver, partition 9, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:41 INFO Executor: Running task 9.0 in stage 42.0 (TID 283)
17/03/18 11:09:41 INFO TaskSetManager: Finished task 2.0 in stage 42.0 (TID 276) in 10701 ms on localhost (executor driver) (2/12)
17/03/18 11:09:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:09:41 INFO Executor: Finished task 0.0 in stage 42.0 (TID 274). 5586 bytes result sent to driver
17/03/18 11:09:41 INFO TaskSetManager: Starting task 10.0 in stage 42.0 (TID 284, localhost, executor driver, partition 10, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:41 INFO Executor: Running task 10.0 in stage 42.0 (TID 284)
17/03/18 11:09:41 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 274) in 10762 ms on localhost (executor driver) (3/12)
17/03/18 11:09:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:09:41 INFO Executor: Finished task 7.0 in stage 42.0 (TID 281). 7709 bytes result sent to driver
17/03/18 11:09:41 INFO TaskSetManager: Starting task 11.0 in stage 42.0 (TID 285, localhost, executor driver, partition 11, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:41 INFO Executor: Running task 11.0 in stage 42.0 (TID 285)
17/03/18 11:09:41 INFO TaskSetManager: Finished task 7.0 in stage 42.0 (TID 281) in 10932 ms on localhost (executor driver) (4/12)
17/03/18 11:09:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:09:41 INFO Executor: Finished task 4.0 in stage 42.0 (TID 278). 17742 bytes result sent to driver
17/03/18 11:09:41 INFO TaskSetManager: Finished task 4.0 in stage 42.0 (TID 278) in 11052 ms on localhost (executor driver) (5/12)
17/03/18 11:09:42 INFO Executor: Finished task 5.0 in stage 42.0 (TID 279). 5536 bytes result sent to driver
17/03/18 11:09:42 INFO TaskSetManager: Finished task 5.0 in stage 42.0 (TID 279) in 12059 ms on localhost (executor driver) (6/12)
17/03/18 11:09:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:09:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:09:43 INFO Executor: Finished task 1.0 in stage 42.0 (TID 275). 9767 bytes result sent to driver
17/03/18 11:09:43 INFO TaskSetManager: Finished task 1.0 in stage 42.0 (TID 275) in 12663 ms on localhost (executor driver) (7/12)
17/03/18 11:09:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:09:44 INFO Executor: Finished task 6.0 in stage 42.0 (TID 280). 23115 bytes result sent to driver
17/03/18 11:09:44 INFO TaskSetManager: Finished task 6.0 in stage 42.0 (TID 280) in 13222 ms on localhost (executor driver) (8/12)
17/03/18 11:09:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:09:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:09:45 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:09:45 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:09:45 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:09:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:09:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:09:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:09:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:09:47 INFO Executor: Finished task 11.0 in stage 42.0 (TID 285). 3872 bytes result sent to driver
17/03/18 11:09:47 INFO TaskSetManager: Finished task 11.0 in stage 42.0 (TID 285) in 5210 ms on localhost (executor driver) (9/12)
17/03/18 11:09:47 INFO Executor: Finished task 9.0 in stage 42.0 (TID 283). 5012 bytes result sent to driver
17/03/18 11:09:47 INFO TaskSetManager: Finished task 9.0 in stage 42.0 (TID 283) in 5534 ms on localhost (executor driver) (10/12)
17/03/18 11:09:47 INFO Executor: Finished task 8.0 in stage 42.0 (TID 282). 4822 bytes result sent to driver
17/03/18 11:09:47 INFO TaskSetManager: Finished task 8.0 in stage 42.0 (TID 282) in 5601 ms on localhost (executor driver) (11/12)
17/03/18 11:09:47 INFO Executor: Finished task 10.0 in stage 42.0 (TID 284). 4146 bytes result sent to driver
17/03/18 11:09:47 INFO TaskSetManager: Finished task 10.0 in stage 42.0 (TID 284) in 5730 ms on localhost (executor driver) (12/12)
17/03/18 11:09:47 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool 
17/03/18 11:09:47 INFO DAGScheduler: ResultStage 42 (collect at utils.scala:197) finished in 16,491 s
17/03/18 11:09:47 INFO DAGScheduler: Job 23 finished: collect at utils.scala:197, took 16,495264 s
17/03/18 11:09:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 11:09:51 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:09:51 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 11:09:51 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:09:51 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:09:51 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:09:51 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:09:51 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:09:51 INFO SparkContext: Created broadcast 59 from collect at utils.scala:197
17/03/18 11:09:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:09:51 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:09:51 INFO DAGScheduler: Got job 24 (collect at utils.scala:197) with 12 output partitions
17/03/18 11:09:51 INFO DAGScheduler: Final stage: ResultStage 43 (collect at utils.scala:197)
17/03/18 11:09:51 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:09:51 INFO DAGScheduler: Missing parents: List()
17/03/18 11:09:51 INFO DAGScheduler: Submitting ResultStage 43 (MapPartitionsRDD[127] at collect at utils.scala:197), which has no missing parents
17/03/18 11:09:51 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 22.8 KB, free 6.2 GB)
17/03/18 11:09:51 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 8.1 KB, free 6.2 GB)
17/03/18 11:09:51 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on 127.0.0.1:38568 (size: 8.1 KB, free: 6.2 GB)
17/03/18 11:09:51 INFO SparkContext: Created broadcast 60 from broadcast at DAGScheduler.scala:996
17/03/18 11:09:51 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 43 (MapPartitionsRDD[127] at collect at utils.scala:197)
17/03/18 11:09:51 INFO TaskSchedulerImpl: Adding task set 43.0 with 12 tasks
17/03/18 11:09:51 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 286, localhost, executor driver, partition 0, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 1.0 in stage 43.0 (TID 287, localhost, executor driver, partition 1, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 2.0 in stage 43.0 (TID 288, localhost, executor driver, partition 2, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 3.0 in stage 43.0 (TID 289, localhost, executor driver, partition 3, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 4.0 in stage 43.0 (TID 290, localhost, executor driver, partition 4, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 5.0 in stage 43.0 (TID 291, localhost, executor driver, partition 5, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 6.0 in stage 43.0 (TID 292, localhost, executor driver, partition 6, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO TaskSetManager: Starting task 7.0 in stage 43.0 (TID 293, localhost, executor driver, partition 7, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:09:51 INFO Executor: Running task 2.0 in stage 43.0 (TID 288)
17/03/18 11:09:51 INFO Executor: Running task 4.0 in stage 43.0 (TID 290)
17/03/18 11:09:51 INFO Executor: Running task 3.0 in stage 43.0 (TID 289)
17/03/18 11:09:51 INFO Executor: Running task 1.0 in stage 43.0 (TID 287)
17/03/18 11:09:51 INFO Executor: Running task 6.0 in stage 43.0 (TID 292)
17/03/18 11:09:51 INFO Executor: Running task 0.0 in stage 43.0 (TID 286)
17/03/18 11:09:51 INFO Executor: Running task 5.0 in stage 43.0 (TID 291)
17/03/18 11:09:51 INFO Executor: Running task 7.0 in stage 43.0 (TID 293)
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:09:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:09:53 INFO BlockManagerInfo: Removed broadcast_58_piece0 on 127.0.0.1:38568 in memory (size: 8.1 KB, free: 6.2 GB)
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:09:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:09:55 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:09:55 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:09:55 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:09:56 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:09:57 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:09:57 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:09:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:09:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:09:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:09:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:09:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:09:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:09:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:09:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:10:00 INFO Executor: Finished task 1.0 in stage 43.0 (TID 287). 9767 bytes result sent to driver
17/03/18 11:10:00 INFO TaskSetManager: Starting task 8.0 in stage 43.0 (TID 294, localhost, executor driver, partition 8, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:10:00 INFO Executor: Running task 8.0 in stage 43.0 (TID 294)
17/03/18 11:10:00 INFO TaskSetManager: Finished task 1.0 in stage 43.0 (TID 287) in 9449 ms on localhost (executor driver) (1/12)
17/03/18 11:10:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:10:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:10:01 INFO Executor: Finished task 4.0 in stage 43.0 (TID 290). 17742 bytes result sent to driver
17/03/18 11:10:01 INFO TaskSetManager: Starting task 9.0 in stage 43.0 (TID 295, localhost, executor driver, partition 9, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:10:01 INFO Executor: Running task 9.0 in stage 43.0 (TID 295)
17/03/18 11:10:01 INFO TaskSetManager: Finished task 4.0 in stage 43.0 (TID 290) in 10412 ms on localhost (executor driver) (2/12)
17/03/18 11:10:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:10:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:10:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:10:02 INFO Executor: Finished task 6.0 in stage 43.0 (TID 292). 23115 bytes result sent to driver
17/03/18 11:10:02 INFO TaskSetManager: Starting task 10.0 in stage 43.0 (TID 296, localhost, executor driver, partition 10, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:10:02 INFO TaskSetManager: Finished task 6.0 in stage 43.0 (TID 292) in 11134 ms on localhost (executor driver) (3/12)
17/03/18 11:10:02 INFO Executor: Running task 10.0 in stage 43.0 (TID 296)
17/03/18 11:10:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:10:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:10:02 INFO Executor: Finished task 0.0 in stage 43.0 (TID 286). 5586 bytes result sent to driver
17/03/18 11:10:02 INFO TaskSetManager: Starting task 11.0 in stage 43.0 (TID 297, localhost, executor driver, partition 11, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:10:02 INFO Executor: Running task 11.0 in stage 43.0 (TID 297)
17/03/18 11:10:02 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 286) in 11529 ms on localhost (executor driver) (4/12)
17/03/18 11:10:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:10:03 INFO Executor: Finished task 2.0 in stage 43.0 (TID 288). 19358 bytes result sent to driver
17/03/18 11:10:03 INFO TaskSetManager: Finished task 2.0 in stage 43.0 (TID 288) in 12271 ms on localhost (executor driver) (5/12)
17/03/18 11:10:03 INFO Executor: Finished task 3.0 in stage 43.0 (TID 289). 4291 bytes result sent to driver
17/03/18 11:10:03 INFO TaskSetManager: Finished task 3.0 in stage 43.0 (TID 289) in 12314 ms on localhost (executor driver) (6/12)
17/03/18 11:10:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:10:04 INFO Executor: Finished task 7.0 in stage 43.0 (TID 293). 7709 bytes result sent to driver
17/03/18 11:10:04 INFO TaskSetManager: Finished task 7.0 in stage 43.0 (TID 293) in 13233 ms on localhost (executor driver) (7/12)
17/03/18 11:10:04 INFO Executor: Finished task 5.0 in stage 43.0 (TID 291). 5536 bytes result sent to driver
17/03/18 11:10:04 INFO TaskSetManager: Finished task 5.0 in stage 43.0 (TID 291) in 13239 ms on localhost (executor driver) (8/12)
17/03/18 11:10:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:10:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:10:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:10:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:10:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:10:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:10:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:10:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:10:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:10:07 INFO Executor: Finished task 11.0 in stage 43.0 (TID 297). 3872 bytes result sent to driver
17/03/18 11:10:07 INFO TaskSetManager: Finished task 11.0 in stage 43.0 (TID 297) in 4655 ms on localhost (executor driver) (9/12)
17/03/18 11:10:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:10:07 INFO Executor: Finished task 8.0 in stage 43.0 (TID 294). 4822 bytes result sent to driver
17/03/18 11:10:07 INFO TaskSetManager: Finished task 8.0 in stage 43.0 (TID 294) in 6961 ms on localhost (executor driver) (10/12)
17/03/18 11:10:07 INFO Executor: Finished task 9.0 in stage 43.0 (TID 295). 5012 bytes result sent to driver
17/03/18 11:10:07 INFO TaskSetManager: Finished task 9.0 in stage 43.0 (TID 295) in 6010 ms on localhost (executor driver) (11/12)
17/03/18 11:10:08 INFO Executor: Finished task 10.0 in stage 43.0 (TID 296). 4146 bytes result sent to driver
17/03/18 11:10:08 INFO TaskSetManager: Finished task 10.0 in stage 43.0 (TID 296) in 5626 ms on localhost (executor driver) (12/12)
17/03/18 11:10:08 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool 
17/03/18 11:10:08 INFO DAGScheduler: ResultStage 43 (collect at utils.scala:197) finished in 16,762 s
17/03/18 11:10:08 INFO DAGScheduler: Job 24 finished: collect at utils.scala:197, took 16,765739 s
17/03/18 11:15:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 11:15:36 INFO SparkSqlParser: Parsing command: banner.3
17/03/18 11:15:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 11:15:54 INFO SparkSqlParser: Parsing command: banner_3
17/03/18 11:15:54 INFO SparkSqlParser: Parsing command: SELECT *
FROM `banner_3` AS `zzz2`
WHERE (0 = 1)
17/03/18 11:15:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `banner_3`
17/03/18 11:15:54 INFO SparkSqlParser: Parsing command: `banner_3`
17/03/18 11:15:54 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:15:54 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(banner_pos#14),(cast(cast(banner_pos#14 as decimal(10,0)) as decimal(11,1)) = 3.0)
17/03/18 11:15:54 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:15:54 INFO FileSourceStrategy: Pushed Filters: IsNotNull(banner_pos)
17/03/18 11:15:54 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:15:54 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:15:54 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on 127.0.0.1:38568 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:15:54 INFO SparkContext: Created broadcast 61 from sql at <unknown>:0
17/03/18 11:15:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:15:54 INFO CodeGenerator: Code generated in 6.187724 ms
17/03/18 11:15:54 INFO SparkContext: Starting job: sql at <unknown>:0
17/03/18 11:15:54 INFO DAGScheduler: Registering RDD 134 (sql at <unknown>:0)
17/03/18 11:15:54 INFO DAGScheduler: Got job 25 (sql at <unknown>:0) with 1 output partitions
17/03/18 11:15:54 INFO DAGScheduler: Final stage: ResultStage 45 (sql at <unknown>:0)
17/03/18 11:15:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
17/03/18 11:15:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 44)
17/03/18 11:15:54 INFO DAGScheduler: Submitting ShuffleMapStage 44 (MapPartitionsRDD[134] at sql at <unknown>:0), which has no missing parents
17/03/18 11:15:54 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 41.8 KB, free 6.2 GB)
17/03/18 11:15:54 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 15.4 KB, free 6.2 GB)
17/03/18 11:15:54 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on 127.0.0.1:38568 (size: 15.4 KB, free: 6.2 GB)
17/03/18 11:15:54 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:996
17/03/18 11:15:54 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 44 (MapPartitionsRDD[134] at sql at <unknown>:0)
17/03/18 11:15:54 INFO TaskSchedulerImpl: Adding task set 44.0 with 12 tasks
17/03/18 11:15:54 INFO TaskSetManager: Starting task 0.0 in stage 44.0 (TID 298, localhost, executor driver, partition 0, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 1.0 in stage 44.0 (TID 299, localhost, executor driver, partition 1, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 2.0 in stage 44.0 (TID 300, localhost, executor driver, partition 2, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 3.0 in stage 44.0 (TID 301, localhost, executor driver, partition 3, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 4.0 in stage 44.0 (TID 302, localhost, executor driver, partition 4, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 5.0 in stage 44.0 (TID 303, localhost, executor driver, partition 5, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 6.0 in stage 44.0 (TID 304, localhost, executor driver, partition 6, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO TaskSetManager: Starting task 7.0 in stage 44.0 (TID 305, localhost, executor driver, partition 7, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:15:54 INFO Executor: Running task 0.0 in stage 44.0 (TID 298)
17/03/18 11:15:54 INFO Executor: Running task 1.0 in stage 44.0 (TID 299)
17/03/18 11:15:54 INFO Executor: Running task 2.0 in stage 44.0 (TID 300)
17/03/18 11:15:54 INFO Executor: Running task 3.0 in stage 44.0 (TID 301)
17/03/18 11:15:54 INFO Executor: Running task 4.0 in stage 44.0 (TID 302)
17/03/18 11:15:54 INFO Executor: Running task 5.0 in stage 44.0 (TID 303)
17/03/18 11:15:54 INFO Executor: Running task 6.0 in stage 44.0 (TID 304)
17/03/18 11:15:54 INFO Executor: Running task 7.0 in stage 44.0 (TID 305)
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:15:54 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:15:56 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:15:57 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:15:57 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:15:57 INFO BlockManagerInfo: Removed broadcast_60_piece0 on 127.0.0.1:38568 in memory (size: 8.1 KB, free: 6.2 GB)
17/03/18 11:15:57 INFO ContextCleaner: Cleaned accumulator 8408
17/03/18 11:15:57 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:15:57 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:15:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:15:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:15:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:15:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:15:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:15:59 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:16:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:16:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:16:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:16:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:16:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:16:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:16:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:16:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:16:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:16:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:16:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:16:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:16:05 INFO MemoryStore: Block rdd_131_4 stored as values in memory (estimated size 21.6 KB, free 6.2 GB)
17/03/18 11:16:05 INFO BlockManagerInfo: Added rdd_131_4 in memory on 127.0.0.1:38568 (size: 21.6 KB, free: 6.2 GB)
17/03/18 11:16:05 INFO CodeGenerator: Code generated in 53.635764 ms
17/03/18 11:16:05 INFO CodeGenerator: Code generated in 13.861477 ms
17/03/18 11:16:05 INFO Executor: Finished task 4.0 in stage 44.0 (TID 302). 3136 bytes result sent to driver
17/03/18 11:16:05 INFO TaskSetManager: Starting task 8.0 in stage 44.0 (TID 306, localhost, executor driver, partition 8, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:16:05 INFO Executor: Running task 8.0 in stage 44.0 (TID 306)
17/03/18 11:16:05 INFO TaskSetManager: Finished task 4.0 in stage 44.0 (TID 302) in 10412 ms on localhost (executor driver) (1/12)
17/03/18 11:16:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:16:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:16:05 INFO MemoryStore: Block rdd_131_5 stored as values in memory (estimated size 8.4 KB, free 6.2 GB)
17/03/18 11:16:05 INFO BlockManagerInfo: Added rdd_131_5 in memory on 127.0.0.1:38568 (size: 8.4 KB, free: 6.2 GB)
17/03/18 11:16:05 INFO Executor: Finished task 5.0 in stage 44.0 (TID 303). 3136 bytes result sent to driver
17/03/18 11:16:05 INFO TaskSetManager: Starting task 9.0 in stage 44.0 (TID 307, localhost, executor driver, partition 9, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:16:05 INFO Executor: Running task 9.0 in stage 44.0 (TID 307)
17/03/18 11:16:05 INFO TaskSetManager: Finished task 5.0 in stage 44.0 (TID 303) in 10418 ms on localhost (executor driver) (2/12)
17/03/18 11:16:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:16:05 INFO MemoryStore: Block rdd_131_1 stored as values in memory (estimated size 14.1 KB, free 6.2 GB)
17/03/18 11:16:05 INFO BlockManagerInfo: Added rdd_131_1 in memory on 127.0.0.1:38568 (size: 14.1 KB, free: 6.2 GB)
17/03/18 11:16:05 INFO Executor: Finished task 1.0 in stage 44.0 (TID 299). 3136 bytes result sent to driver
17/03/18 11:16:05 INFO TaskSetManager: Starting task 10.0 in stage 44.0 (TID 308, localhost, executor driver, partition 10, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:16:05 INFO Executor: Running task 10.0 in stage 44.0 (TID 308)
17/03/18 11:16:05 INFO TaskSetManager: Finished task 1.0 in stage 44.0 (TID 299) in 10671 ms on localhost (executor driver) (3/12)
17/03/18 11:16:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:16:05 INFO MemoryStore: Block rdd_131_6 stored as values in memory (estimated size 26.9 KB, free 6.2 GB)
17/03/18 11:16:05 INFO BlockManagerInfo: Added rdd_131_6 in memory on 127.0.0.1:38568 (size: 26.9 KB, free: 6.2 GB)
17/03/18 11:16:05 INFO Executor: Finished task 6.0 in stage 44.0 (TID 304). 3136 bytes result sent to driver
17/03/18 11:16:05 INFO TaskSetManager: Starting task 11.0 in stage 44.0 (TID 309, localhost, executor driver, partition 11, PROCESS_LOCAL, 7088 bytes)
17/03/18 11:16:05 INFO Executor: Running task 11.0 in stage 44.0 (TID 309)
17/03/18 11:16:05 INFO TaskSetManager: Finished task 6.0 in stage 44.0 (TID 304) in 10775 ms on localhost (executor driver) (4/12)
17/03/18 11:16:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:16:06 INFO MemoryStore: Block rdd_131_0 stored as values in memory (estimated size 8.2 KB, free 6.2 GB)
17/03/18 11:16:06 INFO BlockManagerInfo: Added rdd_131_0 in memory on 127.0.0.1:38568 (size: 8.2 KB, free: 6.2 GB)
17/03/18 11:16:06 INFO Executor: Finished task 0.0 in stage 44.0 (TID 298). 3136 bytes result sent to driver
17/03/18 11:16:06 INFO TaskSetManager: Finished task 0.0 in stage 44.0 (TID 298) in 11382 ms on localhost (executor driver) (5/12)
17/03/18 11:16:06 INFO MemoryStore: Block rdd_131_2 stored as values in memory (estimated size 27.6 KB, free 6.2 GB)
17/03/18 11:16:06 INFO BlockManagerInfo: Added rdd_131_2 in memory on 127.0.0.1:38568 (size: 27.6 KB, free: 6.2 GB)
17/03/18 11:16:06 INFO Executor: Finished task 2.0 in stage 44.0 (TID 300). 3136 bytes result sent to driver
17/03/18 11:16:06 INFO TaskSetManager: Finished task 2.0 in stage 44.0 (TID 300) in 11975 ms on localhost (executor driver) (6/12)
17/03/18 11:16:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:16:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:16:07 INFO MemoryStore: Block rdd_131_3 stored as values in memory (estimated size 6.6 KB, free 6.2 GB)
17/03/18 11:16:07 INFO BlockManagerInfo: Added rdd_131_3 in memory on 127.0.0.1:38568 (size: 6.6 KB, free: 6.2 GB)
17/03/18 11:16:07 INFO Executor: Finished task 3.0 in stage 44.0 (TID 301). 3136 bytes result sent to driver
17/03/18 11:16:07 INFO TaskSetManager: Finished task 3.0 in stage 44.0 (TID 301) in 12951 ms on localhost (executor driver) (7/12)
17/03/18 11:16:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:16:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:16:08 INFO MemoryStore: Block rdd_131_7 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:16:08 INFO BlockManagerInfo: Added rdd_131_7 in memory on 127.0.0.1:38568 (size: 10.5 KB, free: 6.2 GB)
17/03/18 11:16:08 INFO Executor: Finished task 7.0 in stage 44.0 (TID 305). 3136 bytes result sent to driver
17/03/18 11:16:08 INFO TaskSetManager: Finished task 7.0 in stage 44.0 (TID 305) in 13373 ms on localhost (executor driver) (8/12)
17/03/18 11:16:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:16:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:16:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:16:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:16:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:16:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:16:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:16:10 INFO MemoryStore: Block rdd_131_11 stored as values in memory (estimated size 6.0 KB, free 6.2 GB)
17/03/18 11:16:10 INFO BlockManagerInfo: Added rdd_131_11 in memory on 127.0.0.1:38568 (size: 6.0 KB, free: 6.2 GB)
17/03/18 11:16:10 INFO Executor: Finished task 11.0 in stage 44.0 (TID 309). 3136 bytes result sent to driver
17/03/18 11:16:10 INFO TaskSetManager: Finished task 11.0 in stage 44.0 (TID 309) in 4713 ms on localhost (executor driver) (9/12)
17/03/18 11:16:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:16:10 INFO MemoryStore: Block rdd_131_10 stored as values in memory (estimated size 6.4 KB, free 6.2 GB)
17/03/18 11:16:10 INFO BlockManagerInfo: Added rdd_131_10 in memory on 127.0.0.1:38568 (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:16:10 INFO Executor: Finished task 10.0 in stage 44.0 (TID 308). 3136 bytes result sent to driver
17/03/18 11:16:10 INFO TaskSetManager: Finished task 10.0 in stage 44.0 (TID 308) in 5403 ms on localhost (executor driver) (10/12)
17/03/18 11:16:10 INFO MemoryStore: Block rdd_131_8 stored as values in memory (estimated size 7.2 KB, free 6.2 GB)
17/03/18 11:16:10 INFO BlockManagerInfo: Added rdd_131_8 in memory on 127.0.0.1:38568 (size: 7.2 KB, free: 6.2 GB)
17/03/18 11:16:10 INFO Executor: Finished task 8.0 in stage 44.0 (TID 306). 3136 bytes result sent to driver
17/03/18 11:16:10 INFO TaskSetManager: Finished task 8.0 in stage 44.0 (TID 306) in 5667 ms on localhost (executor driver) (11/12)
17/03/18 11:16:11 INFO MemoryStore: Block rdd_131_9 stored as values in memory (estimated size 7.5 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added rdd_131_9 in memory on 127.0.0.1:38568 (size: 7.5 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO Executor: Finished task 9.0 in stage 44.0 (TID 307). 3136 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 9.0 in stage 44.0 (TID 307) in 5909 ms on localhost (executor driver) (12/12)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 44.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ShuffleMapStage 44 (sql at <unknown>:0) finished in 16,329 s
17/03/18 11:16:11 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:16:11 INFO DAGScheduler: running: Set()
17/03/18 11:16:11 INFO DAGScheduler: waiting: Set(ResultStage 45)
17/03/18 11:16:11 INFO DAGScheduler: failed: Set()
17/03/18 11:16:11 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[137] at sql at <unknown>:0), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 63 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[137] at sql at <unknown>:0)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 310, localhost, executor driver, partition 0, ANY, 5955 bytes)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 45.0 (TID 310)
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 45.0 (TID 310). 2042 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 310) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ResultStage 45 (sql at <unknown>:0) finished in 0,004 s
17/03/18 11:16:11 INFO DAGScheduler: Job 25 finished: sql at <unknown>:0, took 16,353369 s
17/03/18 11:16:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `banner_3`
17/03/18 11:16:11 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:16:11 INFO DAGScheduler: Registering RDD 141 (collect at utils.scala:197)
17/03/18 11:16:11 INFO DAGScheduler: Got job 26 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:16:11 INFO DAGScheduler: Final stage: ResultStage 47 (collect at utils.scala:197)
17/03/18 11:16:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 46)
17/03/18 11:16:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 46)
17/03/18 11:16:11 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[141] at collect at utils.scala:197), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 41.8 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 15.4 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on 127.0.0.1:38568 (size: 15.4 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[141] at collect at utils.scala:197)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 46.0 with 12 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 311, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 1.0 in stage 46.0 (TID 312, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 2.0 in stage 46.0 (TID 313, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 3.0 in stage 46.0 (TID 314, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 4.0 in stage 46.0 (TID 315, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 5.0 in stage 46.0 (TID 316, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 6.0 in stage 46.0 (TID 317, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 7.0 in stage 46.0 (TID 318, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 1.0 in stage 46.0 (TID 312)
17/03/18 11:16:11 INFO Executor: Running task 2.0 in stage 46.0 (TID 313)
17/03/18 11:16:11 INFO Executor: Running task 4.0 in stage 46.0 (TID 315)
17/03/18 11:16:11 INFO Executor: Running task 7.0 in stage 46.0 (TID 318)
17/03/18 11:16:11 INFO Executor: Running task 6.0 in stage 46.0 (TID 317)
17/03/18 11:16:11 INFO Executor: Running task 3.0 in stage 46.0 (TID 314)
17/03/18 11:16:11 INFO Executor: Running task 5.0 in stage 46.0 (TID 316)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_2 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_3 locally
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 46.0 (TID 311)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_6 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_4 locally
17/03/18 11:16:11 INFO Executor: Finished task 3.0 in stage 46.0 (TID 314). 2428 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 6.0 in stage 46.0 (TID 317). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_1 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_5 locally
17/03/18 11:16:11 INFO TaskSetManager: Starting task 8.0 in stage 46.0 (TID 319, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 8.0 in stage 46.0 (TID 319)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_7 locally
17/03/18 11:16:11 INFO Executor: Finished task 4.0 in stage 46.0 (TID 315). 2262 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Starting task 9.0 in stage 46.0 (TID 320, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 9.0 in stage 46.0 (TID 320)
17/03/18 11:16:11 INFO Executor: Finished task 2.0 in stage 46.0 (TID 313). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 3.0 in stage 46.0 (TID 314) in 6 ms on localhost (executor driver) (1/12)
17/03/18 11:16:11 INFO Executor: Finished task 5.0 in stage 46.0 (TID 316). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Starting task 10.0 in stage 46.0 (TID 321, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 6.0 in stage 46.0 (TID 317) in 6 ms on localhost (executor driver) (2/12)
17/03/18 11:16:11 INFO Executor: Running task 10.0 in stage 46.0 (TID 321)
17/03/18 11:16:11 INFO Executor: Finished task 7.0 in stage 46.0 (TID 318). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Starting task 11.0 in stage 46.0 (TID 322, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 2.0 in stage 46.0 (TID 313) in 7 ms on localhost (executor driver) (3/12)
17/03/18 11:16:11 INFO Executor: Running task 11.0 in stage 46.0 (TID 322)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 7.0 in stage 46.0 (TID 318) in 6 ms on localhost (executor driver) (4/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 5.0 in stage 46.0 (TID 316) in 7 ms on localhost (executor driver) (5/12)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_9 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_10 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_8 locally
17/03/18 11:16:11 INFO Executor: Finished task 1.0 in stage 46.0 (TID 312). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_11 locally
17/03/18 11:16:11 INFO Executor: Finished task 9.0 in stage 46.0 (TID 320). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 10.0 in stage 46.0 (TID 321). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 4.0 in stage 46.0 (TID 315) in 9 ms on localhost (executor driver) (6/12)
17/03/18 11:16:11 INFO Executor: Finished task 8.0 in stage 46.0 (TID 319). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_0 locally
17/03/18 11:16:11 INFO TaskSetManager: Finished task 1.0 in stage 46.0 (TID 312) in 10 ms on localhost (executor driver) (7/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 9.0 in stage 46.0 (TID 320) in 5 ms on localhost (executor driver) (8/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 10.0 in stage 46.0 (TID 321) in 4 ms on localhost (executor driver) (9/12)
17/03/18 11:16:11 INFO Executor: Finished task 11.0 in stage 46.0 (TID 322). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 46.0 (TID 311). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 11.0 in stage 46.0 (TID 322) in 5 ms on localhost (executor driver) (10/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 311) in 14 ms on localhost (executor driver) (11/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 8.0 in stage 46.0 (TID 319) in 6 ms on localhost (executor driver) (12/12)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ShuffleMapStage 46 (collect at utils.scala:197) finished in 0,017 s
17/03/18 11:16:11 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:16:11 INFO DAGScheduler: running: Set()
17/03/18 11:16:11 INFO DAGScheduler: waiting: Set(ResultStage 47)
17/03/18 11:16:11 INFO DAGScheduler: failed: Set()
17/03/18 11:16:11 INFO DAGScheduler: Submitting ResultStage 47 (MapPartitionsRDD[144] at collect at utils.scala:197), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 47 (MapPartitionsRDD[144] at collect at utils.scala:197)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 47.0 with 1 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 47.0 (TID 323, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 47.0 (TID 323)
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 47.0 (TID 323). 1955 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 47.0 (TID 323) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 47.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ResultStage 47 (collect at utils.scala:197) finished in 0,003 s
17/03/18 11:16:11 INFO DAGScheduler: Job 26 finished: collect at utils.scala:197, took 0,035202 s
17/03/18 11:16:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `banner_3` AS `zzz3`
WHERE (0 = 1)
17/03/18 11:16:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `banner_3`
17/03/18 11:16:11 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:16:11 INFO DAGScheduler: Registering RDD 147 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO DAGScheduler: Got job 27 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:16:11 INFO DAGScheduler: Final stage: ResultStage 49 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 48)
17/03/18 11:16:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 48)
17/03/18 11:16:11 INFO DAGScheduler: Submitting ShuffleMapStage 48 (MapPartitionsRDD[147] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 41.8 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 15.4 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on 127.0.0.1:38568 (size: 15.4 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 66 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 48 (MapPartitionsRDD[147] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 48.0 with 12 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 324, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 1.0 in stage 48.0 (TID 325, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 2.0 in stage 48.0 (TID 326, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 3.0 in stage 48.0 (TID 327, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 4.0 in stage 48.0 (TID 328, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 5.0 in stage 48.0 (TID 329, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 6.0 in stage 48.0 (TID 330, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 7.0 in stage 48.0 (TID 331, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 48.0 (TID 324)
17/03/18 11:16:11 INFO Executor: Running task 4.0 in stage 48.0 (TID 328)
17/03/18 11:16:11 INFO Executor: Running task 3.0 in stage 48.0 (TID 327)
17/03/18 11:16:11 INFO Executor: Running task 2.0 in stage 48.0 (TID 326)
17/03/18 11:16:11 INFO Executor: Running task 6.0 in stage 48.0 (TID 330)
17/03/18 11:16:11 INFO Executor: Running task 1.0 in stage 48.0 (TID 325)
17/03/18 11:16:11 INFO Executor: Running task 5.0 in stage 48.0 (TID 329)
17/03/18 11:16:11 INFO Executor: Running task 7.0 in stage 48.0 (TID 331)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_4 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_1 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_7 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_5 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_6 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_3 locally
17/03/18 11:16:11 INFO Executor: Finished task 7.0 in stage 48.0 (TID 331). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 1.0 in stage 48.0 (TID 325). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 4.0 in stage 48.0 (TID 328). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 5.0 in stage 48.0 (TID 329). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 3.0 in stage 48.0 (TID 327). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 6.0 in stage 48.0 (TID 330). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Starting task 8.0 in stage 48.0 (TID 332, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_0 locally
17/03/18 11:16:11 INFO TaskSetManager: Starting task 9.0 in stage 48.0 (TID 333, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 8.0 in stage 48.0 (TID 332)
17/03/18 11:16:11 INFO Executor: Running task 9.0 in stage 48.0 (TID 333)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 10.0 in stage 48.0 (TID 334, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 11.0 in stage 48.0 (TID 335, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 11.0 in stage 48.0 (TID 335)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 7.0 in stage 48.0 (TID 331) in 6 ms on localhost (executor driver) (1/12)
17/03/18 11:16:11 INFO Executor: Running task 10.0 in stage 48.0 (TID 334)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 1.0 in stage 48.0 (TID 325) in 7 ms on localhost (executor driver) (2/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 3.0 in stage 48.0 (TID 327) in 7 ms on localhost (executor driver) (3/12)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_2 locally
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 48.0 (TID 324). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 2.0 in stage 48.0 (TID 326). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_8 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_10 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_11 locally
17/03/18 11:16:11 INFO Executor: Finished task 10.0 in stage 48.0 (TID 334). 2262 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 8.0 in stage 48.0 (TID 332). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 324) in 11 ms on localhost (executor driver) (4/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 5.0 in stage 48.0 (TID 329) in 9 ms on localhost (executor driver) (5/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 6.0 in stage 48.0 (TID 330) in 9 ms on localhost (executor driver) (6/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 4.0 in stage 48.0 (TID 328) in 10 ms on localhost (executor driver) (7/12)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_9 locally
17/03/18 11:16:11 INFO TaskSetManager: Finished task 10.0 in stage 48.0 (TID 334) in 4 ms on localhost (executor driver) (8/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 2.0 in stage 48.0 (TID 326) in 10 ms on localhost (executor driver) (9/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 8.0 in stage 48.0 (TID 332) in 5 ms on localhost (executor driver) (10/12)
17/03/18 11:16:11 INFO Executor: Finished task 11.0 in stage 48.0 (TID 335). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 11.0 in stage 48.0 (TID 335) in 5 ms on localhost (executor driver) (11/12)
17/03/18 11:16:11 INFO Executor: Finished task 9.0 in stage 48.0 (TID 333). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 9.0 in stage 48.0 (TID 333) in 6 ms on localhost (executor driver) (12/12)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ShuffleMapStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0,013 s
17/03/18 11:16:11 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:16:11 INFO DAGScheduler: running: Set()
17/03/18 11:16:11 INFO DAGScheduler: waiting: Set(ResultStage 49)
17/03/18 11:16:11 INFO DAGScheduler: failed: Set()
17/03/18 11:16:11 INFO DAGScheduler: Submitting ResultStage 49 (MapPartitionsRDD[150] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 49 (MapPartitionsRDD[150] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 336, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 49.0 (TID 336)
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 49.0 (TID 336). 2042 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 336) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ResultStage 49 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 11:16:11 INFO DAGScheduler: Job 27 finished: count at NativeMethodAccessorImpl.java:0, took 0,023854 s
17/03/18 11:16:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `banner_3`
17/03/18 11:16:11 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:16:11 INFO DAGScheduler: Registering RDD 153 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO DAGScheduler: Got job 28 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:16:11 INFO DAGScheduler: Final stage: ResultStage 51 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
17/03/18 11:16:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 50)
17/03/18 11:16:11 INFO DAGScheduler: Submitting ShuffleMapStage 50 (MapPartitionsRDD[153] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 41.8 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 15.5 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on 127.0.0.1:38568 (size: 15.5 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 50 (MapPartitionsRDD[153] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 50.0 with 12 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 50.0 (TID 337, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 1.0 in stage 50.0 (TID 338, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 2.0 in stage 50.0 (TID 339, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 3.0 in stage 50.0 (TID 340, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 4.0 in stage 50.0 (TID 341, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 5.0 in stage 50.0 (TID 342, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 6.0 in stage 50.0 (TID 343, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 7.0 in stage 50.0 (TID 344, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 3.0 in stage 50.0 (TID 340)
17/03/18 11:16:11 INFO Executor: Running task 4.0 in stage 50.0 (TID 341)
17/03/18 11:16:11 INFO Executor: Running task 2.0 in stage 50.0 (TID 339)
17/03/18 11:16:11 INFO Executor: Running task 7.0 in stage 50.0 (TID 344)
17/03/18 11:16:11 INFO Executor: Running task 5.0 in stage 50.0 (TID 342)
17/03/18 11:16:11 INFO Executor: Running task 6.0 in stage 50.0 (TID 343)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 50.0 (TID 337)
17/03/18 11:16:11 INFO Executor: Running task 1.0 in stage 50.0 (TID 338)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_5 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_6 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_2 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_3 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_0 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_4 locally
17/03/18 11:16:11 INFO Executor: Finished task 2.0 in stage 50.0 (TID 339). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 3.0 in stage 50.0 (TID 340). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 5.0 in stage 50.0 (TID 342). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 50.0 (TID 337). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 4.0 in stage 50.0 (TID 341). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 6.0 in stage 50.0 (TID 343). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_1 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_7 locally
17/03/18 11:16:11 INFO Executor: Finished task 1.0 in stage 50.0 (TID 338). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 7.0 in stage 50.0 (TID 344). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Starting task 8.0 in stage 50.0 (TID 345, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 8.0 in stage 50.0 (TID 345)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 9.0 in stage 50.0 (TID 346, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 2.0 in stage 50.0 (TID 339) in 8 ms on localhost (executor driver) (1/12)
17/03/18 11:16:11 INFO Executor: Running task 9.0 in stage 50.0 (TID 346)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 10.0 in stage 50.0 (TID 347, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 10.0 in stage 50.0 (TID 347)
17/03/18 11:16:11 INFO TaskSetManager: Starting task 11.0 in stage 50.0 (TID 348, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:16:11 INFO Executor: Running task 11.0 in stage 50.0 (TID 348)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 1.0 in stage 50.0 (TID 338) in 9 ms on localhost (executor driver) (2/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 6.0 in stage 50.0 (TID 343) in 8 ms on localhost (executor driver) (3/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 4.0 in stage 50.0 (TID 341) in 10 ms on localhost (executor driver) (4/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 5.0 in stage 50.0 (TID 342) in 10 ms on localhost (executor driver) (5/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 7.0 in stage 50.0 (TID 344) in 9 ms on localhost (executor driver) (6/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 50.0 (TID 337) in 11 ms on localhost (executor driver) (7/12)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_9 locally
17/03/18 11:16:11 INFO TaskSetManager: Finished task 3.0 in stage 50.0 (TID 340) in 11 ms on localhost (executor driver) (8/12)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_11 locally
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_10 locally
17/03/18 11:16:11 INFO Executor: Finished task 11.0 in stage 50.0 (TID 348). 2262 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 11.0 in stage 50.0 (TID 348) in 3 ms on localhost (executor driver) (9/12)
17/03/18 11:16:11 INFO Executor: Finished task 9.0 in stage 50.0 (TID 346). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO Executor: Finished task 10.0 in stage 50.0 (TID 347). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 9.0 in stage 50.0 (TID 346) in 5 ms on localhost (executor driver) (10/12)
17/03/18 11:16:11 INFO TaskSetManager: Finished task 10.0 in stage 50.0 (TID 347) in 4 ms on localhost (executor driver) (11/12)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_8 locally
17/03/18 11:16:11 INFO Executor: Finished task 8.0 in stage 50.0 (TID 345). 2341 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 8.0 in stage 50.0 (TID 345) in 9 ms on localhost (executor driver) (12/12)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 50.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ShuffleMapStage 50 (count at NativeMethodAccessorImpl.java:0) finished in 0,017 s
17/03/18 11:16:11 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:16:11 INFO DAGScheduler: running: Set()
17/03/18 11:16:11 INFO DAGScheduler: waiting: Set(ResultStage 51)
17/03/18 11:16:11 INFO DAGScheduler: failed: Set()
17/03/18 11:16:11 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[156] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on 127.0.0.1:38568 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 69 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[156] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 349, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 51.0 (TID 349)
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:16:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 51.0 (TID 349). 1955 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 349) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ResultStage 51 (count at NativeMethodAccessorImpl.java:0) finished in 0,003 s
17/03/18 11:16:11 INFO DAGScheduler: Job 28 finished: count at NativeMethodAccessorImpl.java:0, took 0,027530 s
17/03/18 11:16:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `banner_3`
LIMIT 10
17/03/18 11:16:11 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:16:11 INFO DAGScheduler: Got job 29 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:16:11 INFO DAGScheduler: Final stage: ResultStage 52 (collect at utils.scala:197)
17/03/18 11:16:11 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:16:11 INFO DAGScheduler: Missing parents: List()
17/03/18 11:16:11 INFO DAGScheduler: Submitting ResultStage 52 (MapPartitionsRDD[158] at collect at utils.scala:197), which has no missing parents
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 37.9 KB, free 6.2 GB)
17/03/18 11:16:11 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 13.4 KB, free 6.2 GB)
17/03/18 11:16:11 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on 127.0.0.1:38568 (size: 13.4 KB, free: 6.2 GB)
17/03/18 11:16:11 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:996
17/03/18 11:16:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 52 (MapPartitionsRDD[158] at collect at utils.scala:197)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks
17/03/18 11:16:11 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 350, localhost, executor driver, partition 0, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:16:11 INFO Executor: Running task 0.0 in stage 52.0 (TID 350)
17/03/18 11:16:11 INFO BlockManager: Found block rdd_131_0 locally
17/03/18 11:16:11 INFO CodeGenerator: Code generated in 22.472844 ms
17/03/18 11:16:11 WARN Executor: 1 block locks were not released by TID = 350:
[rdd_131_0]
17/03/18 11:16:11 INFO Executor: Finished task 0.0 in stage 52.0 (TID 350). 2488 bytes result sent to driver
17/03/18 11:16:11 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 350) in 50 ms on localhost (executor driver) (1/1)
17/03/18 11:16:11 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool 
17/03/18 11:16:11 INFO DAGScheduler: ResultStage 52 (collect at utils.scala:197) finished in 0,050 s
17/03/18 11:16:11 INFO DAGScheduler: Job 29 finished: collect at utils.scala:197, took 0,054339 s
17/03/18 11:16:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:16:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:16:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:16:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:16:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:16:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:16:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:17:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
WHERE (`banner_pos` = 3.0)
17/03/18 11:17:59 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:17:59 INFO DAGScheduler: Got job 30 (collect at utils.scala:197) with 12 output partitions
17/03/18 11:17:59 INFO DAGScheduler: Final stage: ResultStage 53 (collect at utils.scala:197)
17/03/18 11:17:59 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:17:59 INFO DAGScheduler: Missing parents: List()
17/03/18 11:17:59 INFO DAGScheduler: Submitting ResultStage 53 (MapPartitionsRDD[161] at collect at utils.scala:197), which has no missing parents
17/03/18 11:17:59 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 38.0 KB, free 6.2 GB)
17/03/18 11:17:59 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 13.5 KB, free 6.2 GB)
17/03/18 11:17:59 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on 127.0.0.1:38568 (size: 13.5 KB, free: 6.2 GB)
17/03/18 11:17:59 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:996
17/03/18 11:17:59 INFO DAGScheduler: Submitting 12 missing tasks from ResultStage 53 (MapPartitionsRDD[161] at collect at utils.scala:197)
17/03/18 11:17:59 INFO TaskSchedulerImpl: Adding task set 53.0 with 12 tasks
17/03/18 11:17:59 INFO TaskSetManager: Starting task 0.0 in stage 53.0 (TID 351, localhost, executor driver, partition 0, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 1.0 in stage 53.0 (TID 352, localhost, executor driver, partition 1, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 2.0 in stage 53.0 (TID 353, localhost, executor driver, partition 2, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 3.0 in stage 53.0 (TID 354, localhost, executor driver, partition 3, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 4.0 in stage 53.0 (TID 355, localhost, executor driver, partition 4, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 5.0 in stage 53.0 (TID 356, localhost, executor driver, partition 5, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 6.0 in stage 53.0 (TID 357, localhost, executor driver, partition 6, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 7.0 in stage 53.0 (TID 358, localhost, executor driver, partition 7, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO Executor: Running task 0.0 in stage 53.0 (TID 351)
17/03/18 11:17:59 INFO Executor: Running task 1.0 in stage 53.0 (TID 352)
17/03/18 11:17:59 INFO Executor: Running task 2.0 in stage 53.0 (TID 353)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_0 locally
17/03/18 11:17:59 INFO Executor: Running task 3.0 in stage 53.0 (TID 354)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_1 locally
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_2 locally
17/03/18 11:17:59 INFO Executor: Running task 4.0 in stage 53.0 (TID 355)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_3 locally
17/03/18 11:17:59 INFO Executor: Running task 5.0 in stage 53.0 (TID 356)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_4 locally
17/03/18 11:17:59 INFO Executor: Finished task 0.0 in stage 53.0 (TID 351). 5652 bytes result sent to driver
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_5 locally
17/03/18 11:17:59 INFO Executor: Finished task 3.0 in stage 53.0 (TID 354). 4304 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Starting task 8.0 in stage 53.0 (TID 359, localhost, executor driver, partition 8, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO Executor: Running task 8.0 in stage 53.0 (TID 359)
17/03/18 11:17:59 INFO Executor: Running task 7.0 in stage 53.0 (TID 358)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 9.0 in stage 53.0 (TID 360, localhost, executor driver, partition 9, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO TaskSetManager: Finished task 3.0 in stage 53.0 (TID 354) in 13 ms on localhost (executor driver) (1/12)
17/03/18 11:17:59 INFO TaskSetManager: Finished task 0.0 in stage 53.0 (TID 351) in 14 ms on localhost (executor driver) (2/12)
17/03/18 11:17:59 INFO Executor: Running task 6.0 in stage 53.0 (TID 357)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_8 locally
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_7 locally
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_6 locally
17/03/18 11:17:59 INFO Executor: Finished task 1.0 in stage 53.0 (TID 352). 9632 bytes result sent to driver
17/03/18 11:17:59 INFO Executor: Running task 9.0 in stage 53.0 (TID 360)
17/03/18 11:17:59 INFO TaskSetManager: Starting task 10.0 in stage 53.0 (TID 361, localhost, executor driver, partition 10, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO Executor: Running task 10.0 in stage 53.0 (TID 361)
17/03/18 11:17:59 INFO TaskSetManager: Finished task 1.0 in stage 53.0 (TID 352) in 20 ms on localhost (executor driver) (3/12)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_10 locally
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_9 locally
17/03/18 11:17:59 INFO Executor: Finished task 4.0 in stage 53.0 (TID 355). 17214 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Starting task 11.0 in stage 53.0 (TID 362, localhost, executor driver, partition 11, PROCESS_LOCAL, 7091 bytes)
17/03/18 11:17:59 INFO Executor: Running task 11.0 in stage 53.0 (TID 362)
17/03/18 11:17:59 INFO TaskSetManager: Finished task 4.0 in stage 53.0 (TID 355) in 30 ms on localhost (executor driver) (4/12)
17/03/18 11:17:59 INFO BlockManager: Found block rdd_131_11 locally
17/03/18 11:17:59 INFO Executor: Finished task 10.0 in stage 53.0 (TID 361). 4188 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 10.0 in stage 53.0 (TID 361) in 15 ms on localhost (executor driver) (5/12)
17/03/18 11:17:59 INFO Executor: Finished task 9.0 in stage 53.0 (TID 360). 4991 bytes result sent to driver
17/03/18 11:17:59 INFO Executor: Finished task 8.0 in stage 53.0 (TID 359). 4811 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 9.0 in stage 53.0 (TID 360) in 22 ms on localhost (executor driver) (6/12)
17/03/18 11:17:59 INFO TaskSetManager: Finished task 8.0 in stage 53.0 (TID 359) in 24 ms on localhost (executor driver) (7/12)
17/03/18 11:17:59 INFO Executor: Finished task 11.0 in stage 53.0 (TID 362). 3910 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 11.0 in stage 53.0 (TID 362) in 10 ms on localhost (executor driver) (8/12)
17/03/18 11:17:59 INFO Executor: Finished task 2.0 in stage 53.0 (TID 353). 19145 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 2.0 in stage 53.0 (TID 353) in 38 ms on localhost (executor driver) (9/12)
17/03/18 11:17:59 INFO Executor: Finished task 7.0 in stage 53.0 (TID 358). 7750 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 7.0 in stage 53.0 (TID 358) in 38 ms on localhost (executor driver) (10/12)
17/03/18 11:17:59 INFO Executor: Finished task 5.0 in stage 53.0 (TID 356). 5599 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 5.0 in stage 53.0 (TID 356) in 38 ms on localhost (executor driver) (11/12)
17/03/18 11:17:59 INFO Executor: Finished task 6.0 in stage 53.0 (TID 357). 21684 bytes result sent to driver
17/03/18 11:17:59 INFO TaskSetManager: Finished task 6.0 in stage 53.0 (TID 357) in 49 ms on localhost (executor driver) (12/12)
17/03/18 11:17:59 INFO TaskSchedulerImpl: Removed TaskSet 53.0, whose tasks have all completed, from pool 
17/03/18 11:17:59 INFO DAGScheduler: ResultStage 53 (collect at utils.scala:197) finished in 0,051 s
17/03/18 11:17:59 INFO DAGScheduler: Job 30 finished: collect at utils.scala:197, took 0,056685 s
17/03/18 11:18:15 INFO SparkSqlParser: Parsing command: SELECT * FROM banner_3 LIMIT 1000
17/03/18 11:18:15 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:18:15 INFO DAGScheduler: Got job 31 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:18:15 INFO DAGScheduler: Final stage: ResultStage 54 (collect at utils.scala:197)
17/03/18 11:18:15 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:18:15 INFO DAGScheduler: Missing parents: List()
17/03/18 11:18:15 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[163] at collect at utils.scala:197), which has no missing parents
17/03/18 11:18:15 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 37.9 KB, free 6.2 GB)
17/03/18 11:18:15 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 13.5 KB, free 6.2 GB)
17/03/18 11:18:15 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on 127.0.0.1:38568 (size: 13.5 KB, free: 6.2 GB)
17/03/18 11:18:15 INFO SparkContext: Created broadcast 72 from broadcast at DAGScheduler.scala:996
17/03/18 11:18:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[163] at collect at utils.scala:197)
17/03/18 11:18:15 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks
17/03/18 11:18:15 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 363, localhost, executor driver, partition 0, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:18:15 INFO Executor: Running task 0.0 in stage 54.0 (TID 363)
17/03/18 11:18:15 INFO BlockManager: Found block rdd_131_0 locally
17/03/18 11:18:15 INFO Executor: Finished task 0.0 in stage 54.0 (TID 363). 5628 bytes result sent to driver
17/03/18 11:18:15 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 363) in 7 ms on localhost (executor driver) (1/1)
17/03/18 11:18:15 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool 
17/03/18 11:18:15 INFO DAGScheduler: ResultStage 54 (collect at utils.scala:197) finished in 0,007 s
17/03/18 11:18:15 INFO DAGScheduler: Job 31 finished: collect at utils.scala:197, took 0,012957 s
17/03/18 11:18:15 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:18:15 INFO DAGScheduler: Got job 32 (collect at utils.scala:197) with 4 output partitions
17/03/18 11:18:15 INFO DAGScheduler: Final stage: ResultStage 55 (collect at utils.scala:197)
17/03/18 11:18:15 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:18:15 INFO DAGScheduler: Missing parents: List()
17/03/18 11:18:15 INFO DAGScheduler: Submitting ResultStage 55 (MapPartitionsRDD[163] at collect at utils.scala:197), which has no missing parents
17/03/18 11:18:15 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 37.9 KB, free 6.2 GB)
17/03/18 11:18:15 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 13.5 KB, free 6.2 GB)
17/03/18 11:18:15 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on 127.0.0.1:38568 (size: 13.5 KB, free: 6.2 GB)
17/03/18 11:18:15 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:996
17/03/18 11:18:15 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 55 (MapPartitionsRDD[163] at collect at utils.scala:197)
17/03/18 11:18:15 INFO TaskSchedulerImpl: Adding task set 55.0 with 4 tasks
17/03/18 11:18:15 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 364, localhost, executor driver, partition 1, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:18:15 INFO TaskSetManager: Starting task 1.0 in stage 55.0 (TID 365, localhost, executor driver, partition 2, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:18:15 INFO TaskSetManager: Starting task 2.0 in stage 55.0 (TID 366, localhost, executor driver, partition 3, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:18:15 INFO TaskSetManager: Starting task 3.0 in stage 55.0 (TID 367, localhost, executor driver, partition 4, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:18:15 INFO Executor: Running task 0.0 in stage 55.0 (TID 364)
17/03/18 11:18:15 INFO Executor: Running task 1.0 in stage 55.0 (TID 365)
17/03/18 11:18:15 INFO Executor: Running task 3.0 in stage 55.0 (TID 367)
17/03/18 11:18:15 INFO Executor: Running task 2.0 in stage 55.0 (TID 366)
17/03/18 11:18:15 INFO BlockManager: Found block rdd_131_1 locally
17/03/18 11:18:15 INFO BlockManager: Found block rdd_131_2 locally
17/03/18 11:18:15 INFO BlockManager: Found block rdd_131_4 locally
17/03/18 11:18:15 INFO BlockManager: Found block rdd_131_3 locally
17/03/18 11:18:15 INFO Executor: Finished task 2.0 in stage 55.0 (TID 366). 4280 bytes result sent to driver
17/03/18 11:18:15 INFO Executor: Finished task 0.0 in stage 55.0 (TID 364). 9608 bytes result sent to driver
17/03/18 11:18:15 INFO TaskSetManager: Finished task 2.0 in stage 55.0 (TID 366) in 7 ms on localhost (executor driver) (1/4)
17/03/18 11:18:15 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 364) in 8 ms on localhost (executor driver) (2/4)
17/03/18 11:18:15 INFO Executor: Finished task 3.0 in stage 55.0 (TID 367). 17190 bytes result sent to driver
17/03/18 11:18:15 INFO Executor: Finished task 1.0 in stage 55.0 (TID 365). 19121 bytes result sent to driver
17/03/18 11:18:15 INFO TaskSetManager: Finished task 3.0 in stage 55.0 (TID 367) in 7 ms on localhost (executor driver) (3/4)
17/03/18 11:18:15 INFO TaskSetManager: Finished task 1.0 in stage 55.0 (TID 365) in 8 ms on localhost (executor driver) (4/4)
17/03/18 11:18:15 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool 
17/03/18 11:18:15 INFO DAGScheduler: ResultStage 55 (collect at utils.scala:197) finished in 0,010 s
17/03/18 11:18:15 INFO DAGScheduler: Job 32 finished: collect at utils.scala:197, took 0,014797 s
17/03/18 11:18:41 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 11:18:42 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/03/18 11:18:42 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 11:18:42 INFO MemoryStore: MemoryStore cleared
17/03/18 11:18:42 INFO BlockManager: BlockManager stopped
17/03/18 11:18:42 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 11:18:42 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 11:18:42 INFO SparkContext: Successfully stopped SparkContext
17/03/18 11:18:42 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:18:42 INFO ShutdownHookManager: Deleting directory /home/yannick/tmp/sparklyr/spark-4dd36f89-34ae-4f00-b390-cc46d2ca5d45
17/03/18 11:19:03 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:19:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:19:03 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 11:19:04 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:19:04 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:19:04 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:19:04 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:19:04 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:19:04 INFO Utils: Successfully started service 'sparkDriver' on port 42137.
17/03/18 11:19:04 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:19:04 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:19:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:19:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:19:04 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-346b5dab-303c-4748-ac5d-c4ec6883c0e9
17/03/18 11:19:04 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 11:19:04 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:19:04 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/18 11:19:04 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/03/18 11:19:04 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:42137/jars/sparklyr-2.1-2.11.jar with timestamp 1489832344413
17/03/18 11:19:04 INFO Executor: Starting executor ID driver on host localhost
17/03/18 11:19:04 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60595.
17/03/18 11:19:04 INFO NettyBlockTransferService: Server created on 127.0.0.1:60595
17/03/18 11:19:04 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 11:19:04 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60595, None)
17/03/18 11:19:04 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60595 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 60595, None)
17/03/18 11:19:04 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60595, None)
17/03/18 11:19:04 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60595, None)
17/03/18 11:19:04 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 11:19:04 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 11:19:04 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 11:19:05 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 11:19:05 INFO ObjectStore: ObjectStore, initialize called
17/03/18 11:19:05 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 11:19:05 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 11:19:06 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 11:19:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:19:06 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:19:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:19:07 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:19:07 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 11:19:07 INFO ObjectStore: Initialized ObjectStore
17/03/18 11:19:07 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 11:19:07 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 11:19:07 INFO HiveMetaStore: Added admin role in metastore
17/03/18 11:19:07 INFO HiveMetaStore: Added public role in metastore
17/03/18 11:19:07 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 11:19:08 INFO HiveMetaStore: 0: get_all_databases
17/03/18 11:19:08 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 11:19:08 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 11:19:08 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 11:19:08 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:19:08 INFO SessionState: Created local directory: /tmp/60b15ea0-795e-4947-b022-7c247a882686_resources
17/03/18 11:19:08 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/60b15ea0-795e-4947-b022-7c247a882686
17/03/18 11:19:08 INFO SessionState: Created local directory: /tmp/yannick/60b15ea0-795e-4947-b022-7c247a882686
17/03/18 11:19:08 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/60b15ea0-795e-4947-b022-7c247a882686/_tmp_space.db
17/03/18 11:19:08 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 11:19:08 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:08 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:08 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 11:19:08 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 11:19:08 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 11:19:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:19:32 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:32 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:32 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:32 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:19:32 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:19:32 INFO CodeGenerator: Code generated in 204.91549 ms
17/03/18 11:19:32 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:19:32 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:19:32 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/03/18 11:19:32 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:19:32 INFO DAGScheduler: Missing parents: List()
17/03/18 11:19:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/03/18 11:19:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:19:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:19:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:19:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/18 11:19:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/03/18 11:19:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/18 11:19:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/03/18 11:19:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/18 11:19:32 INFO Executor: Fetching spark://127.0.0.1:42137/jars/sparklyr-2.1-2.11.jar with timestamp 1489832344413
17/03/18 11:19:32 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:42137 after 9 ms (0 ms spent in bootstraps)
17/03/18 11:19:32 INFO Utils: Fetching spark://127.0.0.1:42137/jars/sparklyr-2.1-2.11.jar to /home/yannick/tmp/sparklyr/spark-18ee6ccc-398d-415f-b542-ecdea0925428/userFiles-e6feec61-55ac-40ec-a9e3-123d0addcf99/fetchFileTemp5284297207753111241.tmp
17/03/18 11:19:32 INFO Executor: Adding file:/home/yannick/tmp/sparklyr/spark-18ee6ccc-398d-415f-b542-ecdea0925428/userFiles-e6feec61-55ac-40ec-a9e3-123d0addcf99/sparklyr-2.1-2.11.jar to class loader
17/03/18 11:19:33 INFO CodeGenerator: Code generated in 10.310536 ms
17/03/18 11:19:33 INFO CodeGenerator: Code generated in 9.858484 ms
17/03/18 11:19:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/03/18 11:19:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 191 ms on localhost (executor driver) (1/1)
17/03/18 11:19:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/18 11:19:33 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0,206 s
17/03/18 11:19:33 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 0,309667 s
17/03/18 11:19:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:19:45 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:45 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:45 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:45 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:19:45 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:19:45 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:19:45 INFO DAGScheduler: Got job 1 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:19:45 INFO DAGScheduler: Final stage: ResultStage 1 (collect at utils.scala:59)
17/03/18 11:19:45 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:19:45 INFO DAGScheduler: Missing parents: List()
17/03/18 11:19:45 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[11] at map at utils.scala:56), which has no missing parents
17/03/18 11:19:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:19:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:19:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:19:45 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/03/18 11:19:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[11] at map at utils.scala:56)
17/03/18 11:19:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/18 11:19:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/03/18 11:19:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/18 11:19:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1231 bytes result sent to driver
17/03/18 11:19:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 12 ms on localhost (executor driver) (1/1)
17/03/18 11:19:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/18 11:19:45 INFO DAGScheduler: ResultStage 1 (collect at utils.scala:59) finished in 0,012 s
17/03/18 11:19:45 INFO DAGScheduler: Job 1 finished: collect at utils.scala:59, took 0,021148 s
17/03/18 11:19:45 INFO SparkSqlParser: Parsing command: train10k
17/03/18 11:19:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz1`
WHERE (0 = 1)
17/03/18 11:19:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 11:19:45 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:19:45 INFO ContextCleaner: Cleaned accumulator 0
17/03/18 11:19:45 INFO ContextCleaner: Cleaned accumulator 1
17/03/18 11:19:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:19:45 INFO ContextCleaner: Cleaned accumulator 50
17/03/18 11:19:45 INFO ContextCleaner: Cleaned accumulator 51
17/03/18 11:19:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:19:45 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:19:45 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:19:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:19:45 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:45 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:45 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:19:45 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:19:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:19:45 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:19:45 INFO CodeGenerator: Code generated in 10.4599 ms
17/03/18 11:20:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:20:06 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:06 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:06 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:06 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:20:06 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:20:06 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:20:06 INFO DAGScheduler: Got job 2 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:20:06 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:59)
17/03/18 11:20:06 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:20:06 INFO DAGScheduler: Missing parents: List()
17/03/18 11:20:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[19] at map at utils.scala:56), which has no missing parents
17/03/18 11:20:06 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:20:06 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:20:06 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:20:06 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[19] at map at utils.scala:56)
17/03/18 11:20:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/18 11:20:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6357 bytes)
17/03/18 11:20:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/18 11:20:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1242 bytes result sent to driver
17/03/18 11:20:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 13 ms on localhost (executor driver) (1/1)
17/03/18 11:20:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/18 11:20:06 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:59) finished in 0,014 s
17/03/18 11:20:06 INFO DAGScheduler: Job 2 finished: collect at utils.scala:59, took 0,021845 s
17/03/18 11:20:06 INFO SparkSqlParser: Parsing command: train10k
17/03/18 11:20:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz2`
WHERE (0 = 1)
17/03/18 11:20:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 11:20:07 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:20:07 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:20:07 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:20:07 INFO FileSourceStrategy: Output Data Schema: struct<id: string, hour: string, click: int, banner_pos: int ... 2 more fields>
17/03/18 11:20:07 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:20:07 INFO deprecation: mapred.job.id is deprecated. Instead, use mapreduce.job.id
17/03/18 11:20:07 INFO deprecation: mapred.tip.id is deprecated. Instead, use mapreduce.task.id
17/03/18 11:20:07 INFO deprecation: mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
17/03/18 11:20:07 INFO deprecation: mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
17/03/18 11:20:07 INFO deprecation: mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
17/03/18 11:20:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:20:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:20:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:20:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:20:07 INFO CodeGenerator: Code generated in 5.064984 ms
17/03/18 11:20:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 296.7 KB, free 6.2 GB)
17/03/18 11:20:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 11:20:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60595 (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:20:07 INFO SparkContext: Created broadcast 3 from parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:20:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:20:07 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:20:07 INFO DAGScheduler: Got job 3 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:20:07 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:07 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:20:07 INFO DAGScheduler: Missing parents: List()
17/03/18 11:20:07 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[22] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:20:07 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 83.3 KB, free 6.2 GB)
17/03/18 11:20:07 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 32.5 KB, free 6.2 GB)
17/03/18 11:20:07 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60595 (size: 32.5 KB, free: 6.2 GB)
17/03/18 11:20:07 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[22] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:07 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/18 11:20:07 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6587 bytes)
17/03/18 11:20:07 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/18 11:20:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:20:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:20:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:20:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:20:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional binary hour (UTF8);
  optional int32 click;
  optional int32 banner_pos;
}

       
17/03/18 11:20:07 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:20:07 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 11:20:07 INFO CodeGenerator: Code generated in 8.735747 ms
17/03/18 11:20:07 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112007_0003_m_000000_0' to file:/home4/yannick4/tmp/train10k.parquet/_temporary/0/task_20170318112007_0003_m_000000
17/03/18 11:20:07 INFO SparkHadoopMapRedUtil: attempt_20170318112007_0003_m_000000_0: Committed
17/03/18 11:20:07 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 1713 bytes result sent to driver
17/03/18 11:20:07 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 535 ms on localhost (executor driver) (1/1)
17/03/18 11:20:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/18 11:20:07 INFO DAGScheduler: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,536 s
17/03/18 11:20:07 INFO DAGScheduler: Job 3 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,585230 s
17/03/18 11:20:07 INFO FileFormatWriter: Job null committed.
17/03/18 11:20:07 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:20:07 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:07 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:07 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:07 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:20:07 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:20:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:20:28 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:28 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:28 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:28 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:20:28 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:20:28 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:20:28 INFO DAGScheduler: Got job 4 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:20:28 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:59)
17/03/18 11:20:28 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:20:28 INFO DAGScheduler: Missing parents: List()
17/03/18 11:20:28 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[30] at map at utils.scala:56), which has no missing parents
17/03/18 11:20:28 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:20:28 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:20:28 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:20:28 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[30] at map at utils.scala:56)
17/03/18 11:20:28 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/03/18 11:20:28 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6357 bytes)
17/03/18 11:20:28 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/03/18 11:20:28 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1242 bytes result sent to driver
17/03/18 11:20:28 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 9 ms on localhost (executor driver) (1/1)
17/03/18 11:20:28 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/18 11:20:28 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:59) finished in 0,009 s
17/03/18 11:20:28 INFO DAGScheduler: Job 4 finished: collect at utils.scala:59, took 0,015184 s
17/03/18 11:20:28 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:20:28 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:20:28 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:28 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:20:28 INFO DAGScheduler: Missing parents: List()
17/03/18 11:20:28 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[32] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:20:28 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:20:28 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:20:28 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60595 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:20:28 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[32] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:28 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/18 11:20:28 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6220 bytes)
17/03/18 11:20:28 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/03/18 11:20:28 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1836 bytes result sent to driver
17/03/18 11:20:28 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 25 ms on localhost (executor driver) (1/1)
17/03/18 11:20:28 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/18 11:20:28 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,026 s
17/03/18 11:20:28 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,055858 s
17/03/18 11:20:28 INFO SparkSqlParser: Parsing command: train
17/03/18 11:20:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz3`
WHERE (0 = 1)
17/03/18 11:20:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:20:28 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:28 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:28 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:20:28 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:20:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:20:28 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:20:31 INFO SparkSqlParser: Parsing command: SELECT * FROM train10k LIMIT 1000
17/03/18 11:20:31 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:20:31 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:20:31 INFO FileSourceStrategy: Output Data Schema: struct<id: string, hour: string, click: int, banner_pos: int ... 2 more fields>
17/03/18 11:20:31 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:20:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 296.7 KB, free 6.2 GB)
17/03/18 11:20:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 11:20:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60595 (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO SparkContext: Created broadcast 7 from collect at utils.scala:197
17/03/18 11:20:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:20:31 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:20:31 INFO DAGScheduler: Got job 6 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:20:31 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:197)
17/03/18 11:20:31 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:20:31 INFO DAGScheduler: Missing parents: List()
17/03/18 11:20:31 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[37] at collect at utils.scala:197), which has no missing parents
17/03/18 11:20:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.4 KB, free 6.2 GB)
17/03/18 11:20:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.3 KB, free 6.2 GB)
17/03/18 11:20:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60595 (size: 6.3 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[37] at collect at utils.scala:197)
17/03/18 11:20:31 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/03/18 11:20:31 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6494 bytes)
17/03/18 11:20:31 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/03/18 11:20:31 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 101
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 102
17/03/18 11:20:31 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 152
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 153
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 154
17/03/18 11:20:31 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60595 in memory (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:60595 in memory (size: 32.5 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 203
17/03/18 11:20:31 INFO ContextCleaner: Cleaned accumulator 204
17/03/18 11:20:31 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60595 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:20:31 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 21424 bytes result sent to driver
17/03/18 11:20:31 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 22 ms on localhost (executor driver) (1/1)
17/03/18 11:20:31 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/18 11:20:31 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:197) finished in 0,022 s
17/03/18 11:20:31 INFO DAGScheduler: Job 6 finished: collect at utils.scala:197, took 0,132845 s
17/03/18 11:20:31 INFO CodeGenerator: Code generated in 9.352489 ms
17/03/18 11:20:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:20:43 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:20:43 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:20:43 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:20:43 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:20:43 INFO CodeGenerator: Code generated in 11.976637 ms
17/03/18 11:20:43 INFO CodeGenerator: Code generated in 15.260742 ms
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60595 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 9 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:20:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:20:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:20:43 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO DAGScheduler: Got job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:20:43 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/03/18 11:20:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/03/18 11:20:43 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60595 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/03/18 11:20:43 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6637 bytes)
17/03/18 11:20:43 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/03/18 11:20:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-409ba9de-12de-429a-9b65-d0a9cd096f70.snappy.parquet, range: 0-160677, partition values: [empty row]
17/03/18 11:20:43 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2144 bytes result sent to driver
17/03/18 11:20:43 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 61 ms on localhost (executor driver) (1/1)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/18 11:20:43 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0,062 s
17/03/18 11:20:43 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:20:43 INFO DAGScheduler: running: Set()
17/03/18 11:20:43 INFO DAGScheduler: waiting: Set(ResultStage 8)
17/03/18 11:20:43 INFO DAGScheduler: failed: Set()
17/03/18 11:20:43 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60595 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/03/18 11:20:43 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/03/18 11:20:43 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/03/18 11:20:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 11:20:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/03/18 11:20:43 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 2042 bytes result sent to driver
17/03/18 11:20:43 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 37 ms on localhost (executor driver) (1/1)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/18 11:20:43 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0,037 s
17/03/18 11:20:43 INFO DAGScheduler: Job 7 finished: count at NativeMethodAccessorImpl.java:0, took 0,129268 s
17/03/18 11:20:43 INFO CodeGenerator: Code generated in 7.555972 ms
17/03/18 11:20:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:20:43 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:20:43 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:20:43 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:20:43 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60595 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 12 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:20:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:20:43 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:20:43 INFO DAGScheduler: Registering RDD 46 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:20:43 INFO DAGScheduler: Final stage: ResultStage 10 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/03/18 11:20:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
17/03/18 11:20:43 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60595 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:43 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[46] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/03/18 11:20:43 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6639 bytes)
17/03/18 11:20:43 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/03/18 11:20:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-409ba9de-12de-429a-9b65-d0a9cd096f70.snappy.parquet, range: 0-160677, partition values: [empty row]
17/03/18 11:20:43 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2057 bytes result sent to driver
17/03/18 11:20:43 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 8 ms on localhost (executor driver) (1/1)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/18 11:20:43 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0,009 s
17/03/18 11:20:43 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:20:43 INFO DAGScheduler: running: Set()
17/03/18 11:20:43 INFO DAGScheduler: waiting: Set(ResultStage 10)
17/03/18 11:20:43 INFO DAGScheduler: failed: Set()
17/03/18 11:20:43 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60595 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[49] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/03/18 11:20:43 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:20:43 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/03/18 11:20:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 11:20:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:20:43 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2042 bytes result sent to driver
17/03/18 11:20:43 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 4 ms on localhost (executor driver) (1/1)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/18 11:20:43 INFO DAGScheduler: ResultStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0,005 s
17/03/18 11:20:43 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0,023090 s
17/03/18 11:20:43 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
LIMIT 10
17/03/18 11:20:43 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:20:43 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:20:43 INFO FileSourceStrategy: Output Data Schema: struct<id: string, hour: string, click: int, banner_pos: int ... 2 more fields>
17/03/18 11:20:43 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:20:43 INFO CodeGenerator: Code generated in 12.42329 ms
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 297.9 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 24.3 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60595 (size: 24.3 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 15 from collect at utils.scala:197
17/03/18 11:20:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:20:43 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:20:43 INFO DAGScheduler: Got job 9 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:20:43 INFO DAGScheduler: Final stage: ResultStage 11 (collect at utils.scala:197)
17/03/18 11:20:43 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:20:43 INFO DAGScheduler: Missing parents: List()
17/03/18 11:20:43 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[52] at collect at utils.scala:197), which has no missing parents
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 9.5 KB, free 6.2 GB)
17/03/18 11:20:43 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 4.5 KB, free 6.2 GB)
17/03/18 11:20:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60595 (size: 4.5 KB, free: 6.2 GB)
17/03/18 11:20:43 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/03/18 11:20:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[52] at collect at utils.scala:197)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/03/18 11:20:43 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6564 bytes)
17/03/18 11:20:43 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/03/18 11:20:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-409ba9de-12de-429a-9b65-d0a9cd096f70.snappy.parquet, range: 0-160677, partition values: [empty row]
17/03/18 11:20:43 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:20:43 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 1777 bytes result sent to driver
17/03/18 11:20:43 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 24 ms on localhost (executor driver) (1/1)
17/03/18 11:20:43 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/03/18 11:20:43 INFO DAGScheduler: ResultStage 11 (collect at utils.scala:197) finished in 0,025 s
17/03/18 11:20:43 INFO DAGScheduler: Job 9 finished: collect at utils.scala:197, took 0,030260 s
17/03/18 11:21:01 INFO SparkSqlParser: Parsing command: SELECT * FROM train LIMIT 1000
17/03/18 11:21:01 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:21:01 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:21:01 INFO FileSourceStrategy: Output Data Schema: struct<id: string, hour: string, click: int, banner_pos: int ... 2 more fields>
17/03/18 11:21:01 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:21:01 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 297.9 KB, free 6.2 GB)
17/03/18 11:21:01 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 24.3 KB, free 6.2 GB)
17/03/18 11:21:01 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60595 (size: 24.3 KB, free: 6.2 GB)
17/03/18 11:21:01 INFO SparkContext: Created broadcast 17 from collect at utils.scala:197
17/03/18 11:21:01 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:21:01 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:21:01 INFO DAGScheduler: Got job 10 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:21:01 INFO DAGScheduler: Final stage: ResultStage 12 (collect at utils.scala:197)
17/03/18 11:21:01 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:21:01 INFO DAGScheduler: Missing parents: List()
17/03/18 11:21:01 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:197), which has no missing parents
17/03/18 11:21:01 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 9.5 KB, free 6.2 GB)
17/03/18 11:21:01 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.5 KB, free 6.2 GB)
17/03/18 11:21:01 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:60595 (size: 4.5 KB, free: 6.2 GB)
17/03/18 11:21:01 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:01 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[55] at collect at utils.scala:197)
17/03/18 11:21:01 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/03/18 11:21:01 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6564 bytes)
17/03/18 11:21:01 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/03/18 11:21:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-409ba9de-12de-429a-9b65-d0a9cd096f70.snappy.parquet, range: 0-160677, partition values: [empty row]
17/03/18 11:21:01 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 21515 bytes result sent to driver
17/03/18 11:21:01 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 21 ms on localhost (executor driver) (1/1)
17/03/18 11:21:01 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/03/18 11:21:01 INFO DAGScheduler: ResultStage 12 (collect at utils.scala:197) finished in 0,021 s
17/03/18 11:21:01 INFO DAGScheduler: Job 10 finished: collect at utils.scala:197, took 0,027865 s
17/03/18 11:21:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:21:14 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:21:14 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:21:14 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:21:14 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:21:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:21:14 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:21:14 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:21:14 INFO DAGScheduler: Got job 11 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:21:14 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:59)
17/03/18 11:21:14 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:21:14 INFO DAGScheduler: Missing parents: List()
17/03/18 11:21:14 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[61] at map at utils.scala:56), which has no missing parents
17/03/18 11:21:14 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:21:14 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:21:14 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:21:14 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[61] at map at utils.scala:56)
17/03/18 11:21:14 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/03/18 11:21:14 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6410 bytes)
17/03/18 11:21:14 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/03/18 11:21:14 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 1250 bytes result sent to driver
17/03/18 11:21:14 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 5 ms on localhost (executor driver) (1/1)
17/03/18 11:21:14 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/03/18 11:21:14 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:59) finished in 0,006 s
17/03/18 11:21:14 INFO DAGScheduler: Job 11 finished: collect at utils.scala:59, took 0,010499 s
17/03/18 11:21:14 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:21:14 INFO DAGScheduler: Got job 12 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:21:14 INFO DAGScheduler: Final stage: ResultStage 14 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:14 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:21:14 INFO DAGScheduler: Missing parents: List()
17/03/18 11:21:14 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[63] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:21:14 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:21:14 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:21:14 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:60595 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:21:14 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[63] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:14 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/03/18 11:21:14 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6218 bytes)
17/03/18 11:21:14 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/03/18 11:21:14 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 3101 bytes result sent to driver
17/03/18 11:21:14 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 15 ms on localhost (executor driver) (1/1)
17/03/18 11:21:14 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/03/18 11:21:14 INFO DAGScheduler: ResultStage 14 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,015 s
17/03/18 11:21:14 INFO DAGScheduler: Job 12 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,041940 s
17/03/18 11:21:14 INFO SparkSqlParser: Parsing command: train
17/03/18 11:21:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz4`
WHERE (0 = 1)
17/03/18 11:21:14 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:21:14 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:21:14 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:21:14 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:21:14 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:21:14 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:21:14 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:21:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:21:16 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:21:16 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:21:16 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:21:16 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:21:16 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:21:16 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:21:16 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:60595 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:21:16 INFO SparkContext: Created broadcast 21 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:21:16 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:21:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:21:16 INFO DAGScheduler: Registering RDD 68 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:16 INFO DAGScheduler: Got job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:21:16 INFO DAGScheduler: Final stage: ResultStage 16 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 15)
17/03/18 11:21:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 15)
17/03/18 11:21:16 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:21:16 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:21:16 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:21:16 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:60595 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:21:16 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:16 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:16 INFO TaskSchedulerImpl: Adding task set 15.0 with 12 tasks
17/03/18 11:21:16 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 15, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 16, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 17, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 18, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 19, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 20, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 21, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 22, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO Executor: Running task 0.0 in stage 15.0 (TID 15)
17/03/18 11:21:16 INFO Executor: Running task 1.0 in stage 15.0 (TID 16)
17/03/18 11:21:16 INFO Executor: Running task 2.0 in stage 15.0 (TID 17)
17/03/18 11:21:16 INFO Executor: Running task 3.0 in stage 15.0 (TID 18)
17/03/18 11:21:16 INFO Executor: Running task 4.0 in stage 15.0 (TID 19)
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:21:16 INFO Executor: Running task 5.0 in stage 15.0 (TID 20)
17/03/18 11:21:16 INFO Executor: Running task 6.0 in stage 15.0 (TID 21)
17/03/18 11:21:16 INFO Executor: Running task 7.0 in stage 15.0 (TID 22)
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:21:16 INFO Executor: Finished task 1.0 in stage 15.0 (TID 16). 2057 bytes result sent to driver
17/03/18 11:21:16 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 23, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO Executor: Finished task 0.0 in stage 15.0 (TID 15). 2057 bytes result sent to driver
17/03/18 11:21:16 INFO Executor: Running task 8.0 in stage 15.0 (TID 23)
17/03/18 11:21:16 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 16) in 183 ms on localhost (executor driver) (1/12)
17/03/18 11:21:16 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:21:16 INFO Executor: Finished task 4.0 in stage 15.0 (TID 19). 2057 bytes result sent to driver
17/03/18 11:21:16 INFO Executor: Finished task 6.0 in stage 15.0 (TID 21). 2057 bytes result sent to driver
17/03/18 11:21:16 INFO Executor: Finished task 7.0 in stage 15.0 (TID 22). 2057 bytes result sent to driver
17/03/18 11:21:16 INFO Executor: Finished task 5.0 in stage 15.0 (TID 20). 2057 bytes result sent to driver
17/03/18 11:21:16 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 24, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 15) in 188 ms on localhost (executor driver) (2/12)
17/03/18 11:21:16 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 20) in 185 ms on localhost (executor driver) (3/12)
17/03/18 11:21:16 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 25, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:16 INFO Executor: Running task 9.0 in stage 15.0 (TID 24)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 26, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 22) in 186 ms on localhost (executor driver) (4/12)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 19) in 188 ms on localhost (executor driver) (5/12)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 21) in 187 ms on localhost (executor driver) (6/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Running task 11.0 in stage 15.0 (TID 26)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:21:16 INFO Executor: Finished task 3.0 in stage 15.0 (TID 18). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 18) in 190 ms on localhost (executor driver) (7/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Running task 10.0 in stage 15.0 (TID 25)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 2.0 in stage 15.0 (TID 17). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 17) in 199 ms on localhost (executor driver) (8/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 9.0 in stage 15.0 (TID 24). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 24) in 19 ms on localhost (executor driver) (9/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 11.0 in stage 15.0 (TID 26). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:21:17 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 26) in 18 ms on localhost (executor driver) (10/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 8.0 in stage 15.0 (TID 23). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 23) in 26 ms on localhost (executor driver) (11/12)
17/03/18 11:21:17 INFO Executor: Finished task 10.0 in stage 15.0 (TID 25). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 25) in 23 ms on localhost (executor driver) (12/12)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/03/18 11:21:17 INFO DAGScheduler: ShuffleMapStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0,212 s
17/03/18 11:21:17 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:21:17 INFO DAGScheduler: running: Set()
17/03/18 11:21:17 INFO DAGScheduler: waiting: Set(ResultStage 16)
17/03/18 11:21:17 INFO DAGScheduler: failed: Set()
17/03/18 11:21:17 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:21:17 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:60595 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:21:17 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/03/18 11:21:17 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 27, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:21:17 INFO Executor: Running task 0.0 in stage 16.0 (TID 27)
17/03/18 11:21:17 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:21:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:21:17 INFO Executor: Finished task 0.0 in stage 16.0 (TID 27). 2042 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 27) in 4 ms on localhost (executor driver) (1/1)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/03/18 11:21:17 INFO DAGScheduler: ResultStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0,005 s
17/03/18 11:21:17 INFO DAGScheduler: Job 13 finished: count at NativeMethodAccessorImpl.java:0, took 0,226060 s
17/03/18 11:21:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:21:17 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:21:17 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:21:17 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:21:17 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:21:17 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:60595 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:21:17 INFO SparkContext: Created broadcast 24 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:21:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:21:17 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:21:17 INFO DAGScheduler: Registering RDD 74 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:17 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:21:17 INFO DAGScheduler: Final stage: ResultStage 18 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/03/18 11:21:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
17/03/18 11:21:17 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[74] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:21:17 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:60595 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:21:17 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:17 INFO DAGScheduler: Submitting 12 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[74] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Adding task set 17.0 with 12 tasks
17/03/18 11:21:17 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 3.0 in stage 17.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 4.0 in stage 17.0 (TID 32, localhost, executor driver, partition 4, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 5.0 in stage 17.0 (TID 33, localhost, executor driver, partition 5, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 6.0 in stage 17.0 (TID 34, localhost, executor driver, partition 6, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Starting task 7.0 in stage 17.0 (TID 35, localhost, executor driver, partition 7, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO Executor: Running task 3.0 in stage 17.0 (TID 31)
17/03/18 11:21:17 INFO Executor: Running task 2.0 in stage 17.0 (TID 30)
17/03/18 11:21:17 INFO Executor: Running task 7.0 in stage 17.0 (TID 35)
17/03/18 11:21:17 INFO Executor: Running task 5.0 in stage 17.0 (TID 33)
17/03/18 11:21:17 INFO Executor: Running task 6.0 in stage 17.0 (TID 34)
17/03/18 11:21:17 INFO Executor: Running task 0.0 in stage 17.0 (TID 28)
17/03/18 11:21:17 INFO Executor: Running task 4.0 in stage 17.0 (TID 32)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26927686, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26292784, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26519353, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26425695, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26204476, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Running task 1.0 in stage 17.0 (TID 29)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26504349, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26382495, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26576783, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26187595, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26552866, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26170446, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837614, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26530921, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27147210, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26896378, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26337808, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26524578, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 7.0 in stage 17.0 (TID 35). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Starting task 8.0 in stage 17.0 (TID 36, localhost, executor driver, partition 8, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 7.0 in stage 17.0 (TID 35) in 18 ms on localhost (executor driver) (1/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26329915, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26876032, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26798670, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26489468, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 4.0 in stage 17.0 (TID 32). 2144 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Starting task 9.0 in stage 17.0 (TID 37, localhost, executor driver, partition 9, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 4.0 in stage 17.0 (TID 32) in 24 ms on localhost (executor driver) (2/12)
17/03/18 11:21:17 INFO Executor: Running task 9.0 in stage 17.0 (TID 37)
17/03/18 11:21:17 INFO Executor: Running task 8.0 in stage 17.0 (TID 36)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26455596, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 6.0 in stage 17.0 (TID 34). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26098728, partition values: [empty row]
17/03/18 11:21:17 INFO TaskSetManager: Starting task 10.0 in stage 17.0 (TID 38, localhost, executor driver, partition 10, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26719768, partition values: [empty row]
17/03/18 11:21:17 INFO TaskSetManager: Finished task 6.0 in stage 17.0 (TID 34) in 27 ms on localhost (executor driver) (3/12)
17/03/18 11:21:17 INFO Executor: Running task 10.0 in stage 17.0 (TID 38)
17/03/18 11:21:17 INFO Executor: Finished task 5.0 in stage 17.0 (TID 33). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26091382, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26619509, partition values: [empty row]
17/03/18 11:21:17 INFO TaskSetManager: Starting task 11.0 in stage 17.0 (TID 39, localhost, executor driver, partition 11, PROCESS_LOCAL, 7080 bytes)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 5.0 in stage 17.0 (TID 33) in 30 ms on localhost (executor driver) (4/12)
17/03/18 11:21:17 INFO Executor: Running task 11.0 in stage 17.0 (TID 39)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27126285, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26837700, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26136471, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27023239, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25557799, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 2.0 in stage 17.0 (TID 30). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 30) in 36 ms on localhost (executor driver) (5/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26118925, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25366091, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25903069, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25211575, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26103123, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-602384, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25853108, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26984346, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26101456, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-26061970, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27217327, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25724187, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 11.0 in stage 17.0 (TID 39). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO Executor: Finished task 8.0 in stage 17.0 (TID 36). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 11.0 in stage 17.0 (TID 39) in 15 ms on localhost (executor driver) (6/12)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 8.0 in stage 17.0 (TID 36) in 28 ms on localhost (executor driver) (7/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27190189, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 3.0 in stage 17.0 (TID 31). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 3.0 in stage 17.0 (TID 31) in 47 ms on localhost (executor driver) (8/12)
17/03/18 11:21:17 INFO Executor: Finished task 1.0 in stage 17.0 (TID 29). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25644739, partition values: [empty row]
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-25988503, partition values: [empty row]
17/03/18 11:21:17 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 29) in 48 ms on localhost (executor driver) (9/12)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27168979, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 0.0 in stage 17.0 (TID 28). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO Executor: Finished task 9.0 in stage 17.0 (TID 37). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO Executor: Finished task 10.0 in stage 17.0 (TID 38). 2057 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 28) in 53 ms on localhost (executor driver) (10/12)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 9.0 in stage 17.0 (TID 37) in 30 ms on localhost (executor driver) (11/12)
17/03/18 11:21:17 INFO TaskSetManager: Finished task 10.0 in stage 17.0 (TID 38) in 25 ms on localhost (executor driver) (12/12)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/03/18 11:21:17 INFO DAGScheduler: ShuffleMapStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0,054 s
17/03/18 11:21:17 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:21:17 INFO DAGScheduler: running: Set()
17/03/18 11:21:17 INFO DAGScheduler: waiting: Set(ResultStage 18)
17/03/18 11:21:17 INFO DAGScheduler: failed: Set()
17/03/18 11:21:17 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:21:17 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:60595 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:21:17 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[77] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/03/18 11:21:17 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 40, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:21:17 INFO Executor: Running task 0.0 in stage 18.0 (TID 40)
17/03/18 11:21:17 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 12 blocks
17/03/18 11:21:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:21:17 INFO Executor: Finished task 0.0 in stage 18.0 (TID 40). 2042 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 40) in 4 ms on localhost (executor driver) (1/1)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/03/18 11:21:17 INFO DAGScheduler: ResultStage 18 (count at NativeMethodAccessorImpl.java:0) finished in 0,005 s
17/03/18 11:21:17 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0,066818 s
17/03/18 11:21:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
LIMIT 10
17/03/18 11:21:17 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:21:17 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:21:17 INFO FileSourceStrategy: Output Data Schema: struct<id: decimal(20,0), click: int, hour: int, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:21:17 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:21:17 INFO CodeGenerator: Code generated in 22.143378 ms
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 24.9 KB, free 6.2 GB)
17/03/18 11:21:17 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:60595 (size: 24.9 KB, free: 6.2 GB)
17/03/18 11:21:17 INFO SparkContext: Created broadcast 27 from collect at utils.scala:197
17/03/18 11:21:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:21:17 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:21:17 INFO DAGScheduler: Got job 15 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:21:17 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:197)
17/03/18 11:21:17 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:21:17 INFO DAGScheduler: Missing parents: List()
17/03/18 11:21:17 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[80] at collect at utils.scala:197), which has no missing parents
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 18.7 KB, free 6.2 GB)
17/03/18 11:21:17 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 6.4 KB, free 6.2 GB)
17/03/18 11:21:17 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:60595 (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:21:17 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/03/18 11:21:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[80] at collect at utils.scala:197)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/03/18 11:21:17 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 7005 bytes)
17/03/18 11:21:17 INFO Executor: Running task 0.0 in stage 19.0 (TID 41)
17/03/18 11:21:17 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-38ed4bb9-e920-49c4-a051-fc92d56647c7.snappy.parquet, range: 0-27291180, partition values: [empty row]
17/03/18 11:21:17 INFO Executor: Finished task 0.0 in stage 19.0 (TID 41). 2604 bytes result sent to driver
17/03/18 11:21:17 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 41) in 249 ms on localhost (executor driver) (1/1)
17/03/18 11:21:17 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/03/18 11:21:17 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:197) finished in 0,249 s
17/03/18 11:21:17 INFO DAGScheduler: Job 15 finished: collect at utils.scala:197, took 0,255505 s
17/03/18 11:21:17 INFO CodeGenerator: Code generated in 20.810335 ms
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:60595 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:60595 in memory (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 774
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 775
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 776
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 777
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 778
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 779
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 780
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 781
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 782
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 783
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 784
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 785
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 786
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 787
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:60595 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned shuffle 2
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:60595 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:60595 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1148
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1149
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1150
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1151
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1152
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1153
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1154
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1155
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1156
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1157
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1158
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1159
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1160
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 1161
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:60595 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned shuffle 3
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:60595 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:60595 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 353
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 354
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 355
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 356
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 357
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 358
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 359
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 360
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 361
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 362
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 363
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 364
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 365
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 366
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:60595 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned shuffle 0
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:60595 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:60595 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 463
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 464
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 465
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 466
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 467
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 468
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 469
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 470
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 471
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 472
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 473
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 474
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 475
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 476
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:60595 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned shuffle 1
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:60595 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:60595 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:60595 in memory (size: 4.5 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:60595 in memory (size: 4.5 KB, free: 6.2 GB)
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 675
17/03/18 11:21:33 INFO ContextCleaner: Cleaned accumulator 676
17/03/18 11:21:33 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:25:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:25:38 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:38 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:38 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:38 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:25:38 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:25:38 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:25:38 INFO DAGScheduler: Got job 16 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:25:38 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:59)
17/03/18 11:25:38 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:25:38 INFO DAGScheduler: Missing parents: List()
17/03/18 11:25:38 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[86] at map at utils.scala:56), which has no missing parents
17/03/18 11:25:38 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:25:38 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:25:38 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:25:38 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[86] at map at utils.scala:56)
17/03/18 11:25:38 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/03/18 11:25:38 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 6410 bytes)
17/03/18 11:25:38 INFO Executor: Running task 0.0 in stage 20.0 (TID 42)
17/03/18 11:25:38 INFO Executor: Finished task 0.0 in stage 20.0 (TID 42). 1250 bytes result sent to driver
17/03/18 11:25:38 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 42) in 5 ms on localhost (executor driver) (1/1)
17/03/18 11:25:38 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/03/18 11:25:38 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:59) finished in 0,005 s
17/03/18 11:25:38 INFO DAGScheduler: Job 16 finished: collect at utils.scala:59, took 0,009439 s
17/03/18 11:25:38 INFO SparkSqlParser: Parsing command: train10k
17/03/18 11:25:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz5`
WHERE (0 = 1)
17/03/18 11:25:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 11:25:39 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:25:39 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:25:39 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:25:39 INFO FileSourceStrategy: Output Data Schema: struct<id: string, click: int, hour: string, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:25:39 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:25:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:25:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:25:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:25:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:25:39 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 296.7 KB, free 6.2 GB)
17/03/18 11:25:39 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 11:25:39 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:60595 (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:25:39 INFO SparkContext: Created broadcast 30 from parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:25:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:25:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:25:39 INFO DAGScheduler: Got job 17 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:25:39 INFO DAGScheduler: Final stage: ResultStage 21 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:39 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:25:39 INFO DAGScheduler: Missing parents: List()
17/03/18 11:25:39 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[89] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:25:39 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 87.7 KB, free 6.2 GB)
17/03/18 11:25:39 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 33.6 KB, free 6.2 GB)
17/03/18 11:25:39 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:60595 (size: 33.6 KB, free: 6.2 GB)
17/03/18 11:25:39 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[89] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:39 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/03/18 11:25:39 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 43, localhost, executor driver, partition 0, PROCESS_LOCAL, 6589 bytes)
17/03/18 11:25:39 INFO Executor: Running task 0.0 in stage 21.0 (TID 43)
17/03/18 11:25:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:25:39 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:25:39 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:25:39 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:25:39 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:25:39 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:25:39 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 11:25:39 INFO CodeGenerator: Code generated in 14.097353 ms
17/03/18 11:25:39 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112539_0021_m_000000_0' to file:/home4/yannick4/tmp/train10k.parquet/_temporary/0/task_20170318112539_0021_m_000000
17/03/18 11:25:39 INFO SparkHadoopMapRedUtil: attempt_20170318112539_0021_m_000000_0: Committed
17/03/18 11:25:39 INFO Executor: Finished task 0.0 in stage 21.0 (TID 43). 1626 bytes result sent to driver
17/03/18 11:25:39 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 43) in 231 ms on localhost (executor driver) (1/1)
17/03/18 11:25:39 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/03/18 11:25:39 INFO DAGScheduler: ResultStage 21 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,233 s
17/03/18 11:25:39 INFO DAGScheduler: Job 17 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,259319 s
17/03/18 11:25:39 INFO FileFormatWriter: Job null committed.
17/03/18 11:25:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:25:39 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:39 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:25:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:25:44 INFO SparkSqlParser: Parsing command: SELECT * FROM train10k LIMIT 1000
17/03/18 11:25:44 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:25:44 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:25:44 INFO FileSourceStrategy: Output Data Schema: struct<id: string, click: int, hour: string, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:25:44 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:25:44 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 296.7 KB, free 6.2 GB)
17/03/18 11:25:44 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 11:25:44 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:60595 (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:25:44 INFO SparkContext: Created broadcast 32 from collect at utils.scala:197
17/03/18 11:25:44 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:25:44 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:25:44 INFO DAGScheduler: Got job 18 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:25:44 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:197)
17/03/18 11:25:44 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:25:44 INFO DAGScheduler: Missing parents: List()
17/03/18 11:25:44 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[94] at collect at utils.scala:197), which has no missing parents
17/03/18 11:25:44 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 12.4 KB, free 6.2 GB)
17/03/18 11:25:44 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 6.9 KB, free 6.2 GB)
17/03/18 11:25:44 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:60595 (size: 6.9 KB, free: 6.2 GB)
17/03/18 11:25:44 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[94] at collect at utils.scala:197)
17/03/18 11:25:44 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/03/18 11:25:44 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 6495 bytes)
17/03/18 11:25:44 INFO Executor: Running task 0.0 in stage 22.0 (TID 44)
17/03/18 11:25:44 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train10k.csv, range: 0-1559274, partition values: [empty row]
17/03/18 11:25:44 INFO Executor: Finished task 0.0 in stage 22.0 (TID 44). 68453 bytes result sent to driver
17/03/18 11:25:44 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 44) in 17 ms on localhost (executor driver) (1/1)
17/03/18 11:25:44 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/03/18 11:25:44 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:197) finished in 0,017 s
17/03/18 11:25:44 INFO DAGScheduler: Job 18 finished: collect at utils.scala:197, took 0,022218 s
17/03/18 11:25:44 INFO CodeGenerator: Code generated in 22.545353 ms
17/03/18 11:25:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:25:50 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:50 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:25:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:25:50 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:25:50 INFO DAGScheduler: Got job 19 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:25:50 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:59)
17/03/18 11:25:50 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:25:50 INFO DAGScheduler: Missing parents: List()
17/03/18 11:25:50 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[100] at map at utils.scala:56), which has no missing parents
17/03/18 11:25:50 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:25:50 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:25:50 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:25:50 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[100] at map at utils.scala:56)
17/03/18 11:25:50 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/03/18 11:25:50 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 45, localhost, executor driver, partition 0, PROCESS_LOCAL, 6410 bytes)
17/03/18 11:25:50 INFO Executor: Running task 0.0 in stage 23.0 (TID 45)
17/03/18 11:25:50 INFO Executor: Finished task 0.0 in stage 23.0 (TID 45). 1250 bytes result sent to driver
17/03/18 11:25:50 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 45) in 5 ms on localhost (executor driver) (1/1)
17/03/18 11:25:50 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/03/18 11:25:50 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:59) finished in 0,006 s
17/03/18 11:25:50 INFO DAGScheduler: Job 19 finished: collect at utils.scala:59, took 0,009905 s
17/03/18 11:25:50 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:25:50 INFO DAGScheduler: Got job 20 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:25:50 INFO DAGScheduler: Final stage: ResultStage 24 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:50 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:25:50 INFO DAGScheduler: Missing parents: List()
17/03/18 11:25:50 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[102] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:25:50 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:25:50 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:25:50 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:60595 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:25:50 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[102] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:50 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks
17/03/18 11:25:50 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 6221 bytes)
17/03/18 11:25:50 INFO Executor: Running task 0.0 in stage 24.0 (TID 46)
17/03/18 11:25:50 INFO Executor: Finished task 0.0 in stage 24.0 (TID 46). 2603 bytes result sent to driver
17/03/18 11:25:50 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 46) in 10 ms on localhost (executor driver) (1/1)
17/03/18 11:25:50 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/03/18 11:25:50 INFO DAGScheduler: ResultStage 24 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,010 s
17/03/18 11:25:50 INFO DAGScheduler: Job 20 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,032317 s
17/03/18 11:25:50 INFO SparkSqlParser: Parsing command: train
17/03/18 11:25:50 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz6`
WHERE (0 = 1)
17/03/18 11:25:50 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:25:50 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:50 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:25:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:25:50 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:25:50 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:25:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:25:52 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:25:52 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:25:52 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:25:52 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:60595 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 36 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:25:52 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:25:52 INFO DAGScheduler: Registering RDD 107 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO DAGScheduler: Got job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:25:52 INFO DAGScheduler: Final stage: ResultStage 26 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 25)
17/03/18 11:25:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 25)
17/03/18 11:25:52 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[107] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on 127.0.0.1:60595 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[107] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/03/18 11:25:52 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6639 bytes)
17/03/18 11:25:52 INFO Executor: Running task 0.0 in stage 25.0 (TID 47)
17/03/18 11:25:52 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:25:52 INFO Executor: Finished task 0.0 in stage 25.0 (TID 47). 2057 bytes result sent to driver
17/03/18 11:25:52 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 47) in 7 ms on localhost (executor driver) (1/1)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/03/18 11:25:52 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0,009 s
17/03/18 11:25:52 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:25:52 INFO DAGScheduler: running: Set()
17/03/18 11:25:52 INFO DAGScheduler: waiting: Set(ResultStage 26)
17/03/18 11:25:52 INFO DAGScheduler: failed: Set()
17/03/18 11:25:52 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[110] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on 127.0.0.1:60595 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 38 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[110] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/03/18 11:25:52 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 48, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:25:52 INFO Executor: Running task 0.0 in stage 26.0 (TID 48)
17/03/18 11:25:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 11:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:25:52 INFO Executor: Finished task 0.0 in stage 26.0 (TID 48). 2042 bytes result sent to driver
17/03/18 11:25:52 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 48) in 4 ms on localhost (executor driver) (1/1)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/03/18 11:25:52 INFO DAGScheduler: ResultStage 26 (count at NativeMethodAccessorImpl.java:0) finished in 0,004 s
17/03/18 11:25:52 INFO DAGScheduler: Job 21 finished: count at NativeMethodAccessorImpl.java:0, took 0,020465 s
17/03/18 11:25:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:25:52 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:25:52 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:25:52 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:25:52 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on 127.0.0.1:60595 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 39 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:25:52 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:25:52 INFO DAGScheduler: Registering RDD 113 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO DAGScheduler: Got job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:25:52 INFO DAGScheduler: Final stage: ResultStage 28 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 27)
17/03/18 11:25:52 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 27)
17/03/18 11:25:52 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on 127.0.0.1:60595 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/03/18 11:25:52 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6639 bytes)
17/03/18 11:25:52 INFO Executor: Running task 0.0 in stage 27.0 (TID 49)
17/03/18 11:25:52 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:25:52 INFO Executor: Finished task 0.0 in stage 27.0 (TID 49). 2057 bytes result sent to driver
17/03/18 11:25:52 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 49) in 5 ms on localhost (executor driver) (1/1)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/03/18 11:25:52 INFO DAGScheduler: ShuffleMapStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0,006 s
17/03/18 11:25:52 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:25:52 INFO DAGScheduler: running: Set()
17/03/18 11:25:52 INFO DAGScheduler: waiting: Set(ResultStage 28)
17/03/18 11:25:52 INFO DAGScheduler: failed: Set()
17/03/18 11:25:52 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on 127.0.0.1:60595 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 41 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/03/18 11:25:52 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 50, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:25:52 INFO Executor: Running task 0.0 in stage 28.0 (TID 50)
17/03/18 11:25:52 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 11:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:25:52 INFO Executor: Finished task 0.0 in stage 28.0 (TID 50). 2042 bytes result sent to driver
17/03/18 11:25:52 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 50) in 3 ms on localhost (executor driver) (1/1)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/03/18 11:25:52 INFO DAGScheduler: ResultStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0,004 s
17/03/18 11:25:52 INFO DAGScheduler: Job 22 finished: count at NativeMethodAccessorImpl.java:0, took 0,016252 s
17/03/18 11:25:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
LIMIT 10
17/03/18 11:25:52 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:25:52 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:25:52 INFO FileSourceStrategy: Output Data Schema: struct<id: string, click: int, hour: string, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:25:52 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:25:52 INFO CodeGenerator: Code generated in 18.170452 ms
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 24.8 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on 127.0.0.1:60595 (size: 24.8 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 42 from collect at utils.scala:197
17/03/18 11:25:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:25:52 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:25:52 INFO DAGScheduler: Got job 23 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:25:52 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:197)
17/03/18 11:25:52 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:25:52 INFO DAGScheduler: Missing parents: List()
17/03/18 11:25:52 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[119] at collect at utils.scala:197), which has no missing parents
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 18.3 KB, free 6.2 GB)
17/03/18 11:25:52 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 6.2 KB, free 6.2 GB)
17/03/18 11:25:52 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on 127.0.0.1:60595 (size: 6.2 KB, free: 6.2 GB)
17/03/18 11:25:52 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:996
17/03/18 11:25:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[119] at collect at utils.scala:197)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/03/18 11:25:52 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6564 bytes)
17/03/18 11:25:52 INFO Executor: Running task 0.0 in stage 29.0 (TID 51)
17/03/18 11:25:52 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:25:52 INFO Executor: Finished task 0.0 in stage 29.0 (TID 51). 2575 bytes result sent to driver
17/03/18 11:25:52 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 51) in 15 ms on localhost (executor driver) (1/1)
17/03/18 11:25:52 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/03/18 11:25:52 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:197) finished in 0,015 s
17/03/18 11:25:52 INFO DAGScheduler: Job 23 finished: collect at utils.scala:197, took 0,021924 s
17/03/18 11:26:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:26:05 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:26:05 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:26:05 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:26:05 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:26:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:26:05 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:26:05 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:26:05 INFO DAGScheduler: Got job 24 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:26:05 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:59)
17/03/18 11:26:05 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:26:05 INFO DAGScheduler: Missing parents: List()
17/03/18 11:26:05 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[125] at map at utils.scala:56), which has no missing parents
17/03/18 11:26:05 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:26:05 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:26:05 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on 127.0.0.1:60595 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO SparkContext: Created broadcast 44 from broadcast at DAGScheduler.scala:996
17/03/18 11:26:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[125] at map at utils.scala:56)
17/03/18 11:26:05 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/03/18 11:26:05 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 6410 bytes)
17/03/18 11:26:05 INFO Executor: Running task 0.0 in stage 30.0 (TID 52)
17/03/18 11:26:05 INFO Executor: Finished task 0.0 in stage 30.0 (TID 52). 1250 bytes result sent to driver
17/03/18 11:26:05 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 52) in 4 ms on localhost (executor driver) (1/1)
17/03/18 11:26:05 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/03/18 11:26:05 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:59) finished in 0,004 s
17/03/18 11:26:05 INFO DAGScheduler: Job 24 finished: collect at utils.scala:59, took 0,007918 s
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_41_piece0 on 127.0.0.1:60595 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_43_piece0 on 127.0.0.1:60595 in memory (size: 6.2 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 2096
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 2097
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_44_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_33_piece0 on 127.0.0.1:60595 in memory (size: 6.9 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1726
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1727
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_34_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_35_piece0 on 127.0.0.1:60595 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1825
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1826
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1827
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1828
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1829
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1830
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1831
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1832
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1833
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1834
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1835
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1836
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1837
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1838
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_36_piece0 on 127.0.0.1:60595 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned shuffle 4
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_37_piece0 on 127.0.0.1:60595 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_38_piece0 on 127.0.0.1:60595 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1935
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1936
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1937
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1938
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1939
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1940
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1941
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1942
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1943
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1944
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1945
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1946
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1947
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1948
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_39_piece0 on 127.0.0.1:60595 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned shuffle 5
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_40_piece0 on 127.0.0.1:60595 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1573
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1574
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:60595 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1624
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1625
17/03/18 11:26:05 INFO ContextCleaner: Cleaned accumulator 1626
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:60595 in memory (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:60595 in memory (size: 33.6 KB, free: 6.2 GB)
17/03/18 11:26:05 INFO SparkSqlParser: Parsing command: train
17/03/18 11:26:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz7`
WHERE (0 = 1)
17/03/18 11:26:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train`
17/03/18 11:26:06 INFO ParquetFileFormat: Using default output committer for Parquet: org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:26:06 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:26:06 INFO FileSourceStrategy: Output Data Schema: struct<id: string, click: int, hour: string, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:26:06 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 296.7 KB, free 6.2 GB)
17/03/18 11:26:06 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 24.0 KB, free 6.2 GB)
17/03/18 11:26:06 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on 127.0.0.1:60595 (size: 24.0 KB, free: 6.2 GB)
17/03/18 11:26:06 INFO SparkContext: Created broadcast 45 from parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:26:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:26:06 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:26:06 INFO DAGScheduler: Got job 25 (parquet at NativeMethodAccessorImpl.java:0) with 48 output partitions
17/03/18 11:26:06 INFO DAGScheduler: Final stage: ResultStage 31 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:26:06 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:26:06 INFO DAGScheduler: Missing parents: List()
17/03/18 11:26:06 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[128] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:26:06 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 87.7 KB, free 6.2 GB)
17/03/18 11:26:06 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 33.6 KB, free 6.2 GB)
17/03/18 11:26:06 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on 127.0.0.1:60595 (size: 33.6 KB, free: 6.2 GB)
17/03/18 11:26:06 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:996
17/03/18 11:26:06 INFO DAGScheduler: Submitting 48 missing tasks from ResultStage 31 (MapPartitionsRDD[128] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:26:06 INFO TaskSchedulerImpl: Adding task set 31.0 with 48 tasks
17/03/18 11:26:06 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 54, localhost, executor driver, partition 1, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 55, localhost, executor driver, partition 2, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 3.0 in stage 31.0 (TID 56, localhost, executor driver, partition 3, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 4.0 in stage 31.0 (TID 57, localhost, executor driver, partition 4, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 5.0 in stage 31.0 (TID 58, localhost, executor driver, partition 5, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 6.0 in stage 31.0 (TID 59, localhost, executor driver, partition 6, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO TaskSetManager: Starting task 7.0 in stage 31.0 (TID 60, localhost, executor driver, partition 7, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:06 INFO Executor: Running task 0.0 in stage 31.0 (TID 53)
17/03/18 11:26:06 INFO Executor: Running task 1.0 in stage 31.0 (TID 54)
17/03/18 11:26:06 INFO Executor: Running task 2.0 in stage 31.0 (TID 55)
17/03/18 11:26:06 INFO Executor: Running task 7.0 in stage 31.0 (TID 60)
17/03/18 11:26:06 INFO Executor: Running task 3.0 in stage 31.0 (TID 56)
17/03/18 11:26:06 INFO Executor: Running task 5.0 in stage 31.0 (TID 58)
17/03/18 11:26:06 INFO Executor: Running task 6.0 in stage 31.0 (TID 59)
17/03/18 11:26:06 INFO Executor: Running task 4.0 in stage 31.0 (TID 57)
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 805306368-939524096, partition values: [empty row]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 0-134217728, partition values: [empty row]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 402653184-536870912, partition values: [empty row]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 671088640-805306368, partition values: [empty row]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 268435456-402653184, partition values: [empty row]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 536870912-671088640, partition values: [empty row]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 134217728-268435456, partition values: [empty row]
17/03/18 11:26:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 939524096-1073741824, partition values: [empty row]
17/03/18 11:26:08 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:60595 in memory (size: 6.3 KB, free: 6.2 GB)
17/03/18 11:26:18 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000007_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000007
17/03/18 11:26:18 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000007_0: Committed
17/03/18 11:26:18 INFO Executor: Finished task 7.0 in stage 31.0 (TID 60). 1699 bytes result sent to driver
17/03/18 11:26:18 INFO TaskSetManager: Starting task 8.0 in stage 31.0 (TID 61, localhost, executor driver, partition 8, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:18 INFO TaskSetManager: Finished task 7.0 in stage 31.0 (TID 60) in 12622 ms on localhost (executor driver) (1/48)
17/03/18 11:26:18 INFO Executor: Running task 8.0 in stage 31.0 (TID 61)
17/03/18 11:26:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:18 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:18 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:18 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:18 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:18 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:18 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1073741824-1207959552, partition values: [empty row]
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000005_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000005
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000005_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 5.0 in stage 31.0 (TID 58). 1699 bytes result sent to driver
17/03/18 11:26:19 INFO TaskSetManager: Starting task 9.0 in stage 31.0 (TID 62, localhost, executor driver, partition 9, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 5.0 in stage 31.0 (TID 58) in 12943 ms on localhost (executor driver) (2/48)
17/03/18 11:26:19 INFO Executor: Running task 9.0 in stage 31.0 (TID 62)
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1207959552-1342177280, partition values: [empty row]
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000006_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000006
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000006_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 6.0 in stage 31.0 (TID 59). 1786 bytes result sent to driver
17/03/18 11:26:19 INFO TaskSetManager: Starting task 10.0 in stage 31.0 (TID 63, localhost, executor driver, partition 10, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO Executor: Running task 10.0 in stage 31.0 (TID 63)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 6.0 in stage 31.0 (TID 59) in 13011 ms on localhost (executor driver) (3/48)
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000003_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000003
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000003_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 3.0 in stage 31.0 (TID 56). 1699 bytes result sent to driver
17/03/18 11:26:19 INFO TaskSetManager: Starting task 11.0 in stage 31.0 (TID 64, localhost, executor driver, partition 11, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 3.0 in stage 31.0 (TID 56) in 13111 ms on localhost (executor driver) (4/48)
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000000_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000000
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000000_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 0.0 in stage 31.0 (TID 53). 1699 bytes result sent to driver
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1342177280-1476395008, partition values: [empty row]
17/03/18 11:26:19 INFO Executor: Running task 11.0 in stage 31.0 (TID 64)
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO TaskSetManager: Starting task 12.0 in stage 31.0 (TID 65, localhost, executor driver, partition 12, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 53) in 13130 ms on localhost (executor driver) (5/48)
17/03/18 11:26:19 INFO Executor: Running task 12.0 in stage 31.0 (TID 65)
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1476395008-1610612736, partition values: [empty row]
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1610612736-1744830464, partition values: [empty row]
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000002_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000002
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000002_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 2.0 in stage 31.0 (TID 55). 1699 bytes result sent to driver
17/03/18 11:26:19 INFO TaskSetManager: Starting task 13.0 in stage 31.0 (TID 66, localhost, executor driver, partition 13, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO Executor: Running task 13.0 in stage 31.0 (TID 66)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 55) in 13248 ms on localhost (executor driver) (6/48)
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000001_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000001
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000001_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 1.0 in stage 31.0 (TID 54). 1699 bytes result sent to driver
17/03/18 11:26:19 INFO TaskSetManager: Starting task 14.0 in stage 31.0 (TID 67, localhost, executor driver, partition 14, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO Executor: Running task 14.0 in stage 31.0 (TID 67)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 54) in 13339 ms on localhost (executor driver) (7/48)
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1744830464-1879048192, partition values: [empty row]
17/03/18 11:26:19 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112606_0031_m_000004_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112606_0031_m_000004
17/03/18 11:26:19 INFO SparkHadoopMapRedUtil: attempt_20170318112606_0031_m_000004_0: Committed
17/03/18 11:26:19 INFO Executor: Finished task 4.0 in stage 31.0 (TID 57). 1699 bytes result sent to driver
17/03/18 11:26:19 INFO TaskSetManager: Starting task 15.0 in stage 31.0 (TID 68, localhost, executor driver, partition 15, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:19 INFO Executor: Running task 15.0 in stage 31.0 (TID 68)
17/03/18 11:26:19 INFO TaskSetManager: Finished task 4.0 in stage 31.0 (TID 57) in 13381 ms on localhost (executor driver) (8/48)
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 1879048192-2013265920, partition values: [empty row]
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:19 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:19 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:19 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:19 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2013265920-2147483648, partition values: [empty row]
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112618_0031_m_000008_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112618_0031_m_000008
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112618_0031_m_000008_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 8.0 in stage 31.0 (TID 61). 1699 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 16.0 in stage 31.0 (TID 69, localhost, executor driver, partition 16, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO Executor: Running task 16.0 in stage 31.0 (TID 69)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 8.0 in stage 31.0 (TID 61) in 12415 ms on localhost (executor driver) (9/48)
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:31 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:31 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2147483648-2281701376, partition values: [empty row]
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000009_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000009
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000009_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 9.0 in stage 31.0 (TID 62). 1699 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 17.0 in stage 31.0 (TID 70, localhost, executor driver, partition 17, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 9.0 in stage 31.0 (TID 62) in 12373 ms on localhost (executor driver) (10/48)
17/03/18 11:26:31 INFO Executor: Running task 17.0 in stage 31.0 (TID 70)
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:31 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:31 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2281701376-2415919104, partition values: [empty row]
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000012_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000012
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000012_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 12.0 in stage 31.0 (TID 65). 1699 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 18.0 in stage 31.0 (TID 71, localhost, executor driver, partition 18, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 12.0 in stage 31.0 (TID 65) in 12273 ms on localhost (executor driver) (11/48)
17/03/18 11:26:31 INFO Executor: Running task 18.0 in stage 31.0 (TID 71)
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:31 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:31 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2415919104-2550136832, partition values: [empty row]
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000010_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000010
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000010_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 10.0 in stage 31.0 (TID 63). 1699 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 19.0 in stage 31.0 (TID 72, localhost, executor driver, partition 19, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 10.0 in stage 31.0 (TID 63) in 12532 ms on localhost (executor driver) (12/48)
17/03/18 11:26:31 INFO Executor: Running task 19.0 in stage 31.0 (TID 72)
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000011_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000011
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000011_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 11.0 in stage 31.0 (TID 64). 1699 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 20.0 in stage 31.0 (TID 73, localhost, executor driver, partition 20, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO Executor: Running task 20.0 in stage 31.0 (TID 73)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 11.0 in stage 31.0 (TID 64) in 12479 ms on localhost (executor driver) (13/48)
17/03/18 11:26:31 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:31 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2550136832-2684354560, partition values: [empty row]
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:31 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:31 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2684354560-2818572288, partition values: [empty row]
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000013_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000013
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000013_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 13.0 in stage 31.0 (TID 66). 1699 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 21.0 in stage 31.0 (TID 74, localhost, executor driver, partition 21, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO Executor: Running task 21.0 in stage 31.0 (TID 74)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 13.0 in stage 31.0 (TID 66) in 12441 ms on localhost (executor driver) (14/48)
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:31 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000014_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000014
17/03/18 11:26:31 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000014_0: Committed
17/03/18 11:26:31 INFO Executor: Finished task 14.0 in stage 31.0 (TID 67). 1786 bytes result sent to driver
17/03/18 11:26:31 INFO TaskSetManager: Starting task 22.0 in stage 31.0 (TID 75, localhost, executor driver, partition 22, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:31 INFO TaskSetManager: Finished task 14.0 in stage 31.0 (TID 67) in 12378 ms on localhost (executor driver) (15/48)
17/03/18 11:26:31 INFO Executor: Running task 22.0 in stage 31.0 (TID 75)
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:31 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:31 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:32 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:32 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2818572288-2952790016, partition values: [empty row]
17/03/18 11:26:32 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:32 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 2952790016-3087007744, partition values: [empty row]
17/03/18 11:26:32 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112619_0031_m_000015_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112619_0031_m_000015
17/03/18 11:26:32 INFO SparkHadoopMapRedUtil: attempt_20170318112619_0031_m_000015_0: Committed
17/03/18 11:26:32 INFO Executor: Finished task 15.0 in stage 31.0 (TID 68). 1699 bytes result sent to driver
17/03/18 11:26:32 INFO TaskSetManager: Starting task 23.0 in stage 31.0 (TID 76, localhost, executor driver, partition 23, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:32 INFO TaskSetManager: Finished task 15.0 in stage 31.0 (TID 68) in 12788 ms on localhost (executor driver) (16/48)
17/03/18 11:26:32 INFO Executor: Running task 23.0 in stage 31.0 (TID 76)
17/03/18 11:26:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:32 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:32 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:32 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:32 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3087007744-3221225472, partition values: [empty row]
17/03/18 11:26:43 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000016_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000016
17/03/18 11:26:43 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000016_0: Committed
17/03/18 11:26:43 INFO Executor: Finished task 16.0 in stage 31.0 (TID 69). 1699 bytes result sent to driver
17/03/18 11:26:43 INFO TaskSetManager: Starting task 24.0 in stage 31.0 (TID 77, localhost, executor driver, partition 24, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:43 INFO Executor: Running task 24.0 in stage 31.0 (TID 77)
17/03/18 11:26:43 INFO TaskSetManager: Finished task 16.0 in stage 31.0 (TID 69) in 12057 ms on localhost (executor driver) (17/48)
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:43 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:43 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3221225472-3355443200, partition values: [empty row]
17/03/18 11:26:43 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000018_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000018
17/03/18 11:26:43 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000018_0: Committed
17/03/18 11:26:43 INFO Executor: Finished task 18.0 in stage 31.0 (TID 71). 1699 bytes result sent to driver
17/03/18 11:26:43 INFO TaskSetManager: Starting task 25.0 in stage 31.0 (TID 78, localhost, executor driver, partition 25, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:43 INFO TaskSetManager: Finished task 18.0 in stage 31.0 (TID 71) in 11949 ms on localhost (executor driver) (18/48)
17/03/18 11:26:43 INFO Executor: Running task 25.0 in stage 31.0 (TID 78)
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:43 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:43 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3355443200-3489660928, partition values: [empty row]
17/03/18 11:26:43 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000017_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000017
17/03/18 11:26:43 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000017_0: Committed
17/03/18 11:26:43 INFO Executor: Finished task 17.0 in stage 31.0 (TID 70). 1699 bytes result sent to driver
17/03/18 11:26:43 INFO TaskSetManager: Starting task 26.0 in stage 31.0 (TID 79, localhost, executor driver, partition 26, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:43 INFO Executor: Running task 26.0 in stage 31.0 (TID 79)
17/03/18 11:26:43 INFO TaskSetManager: Finished task 17.0 in stage 31.0 (TID 70) in 12079 ms on localhost (executor driver) (19/48)
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:43 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:43 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3489660928-3623878656, partition values: [empty row]
17/03/18 11:26:43 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000020_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000020
17/03/18 11:26:43 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000020_0: Committed
17/03/18 11:26:43 INFO Executor: Finished task 20.0 in stage 31.0 (TID 73). 1699 bytes result sent to driver
17/03/18 11:26:43 INFO TaskSetManager: Starting task 27.0 in stage 31.0 (TID 80, localhost, executor driver, partition 27, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:43 INFO Executor: Running task 27.0 in stage 31.0 (TID 80)
17/03/18 11:26:43 INFO TaskSetManager: Finished task 20.0 in stage 31.0 (TID 73) in 12062 ms on localhost (executor driver) (20/48)
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:43 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:43 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:43 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:43 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3623878656-3758096384, partition values: [empty row]
17/03/18 11:26:44 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000021_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000021
17/03/18 11:26:44 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000021_0: Committed
17/03/18 11:26:44 INFO Executor: Finished task 21.0 in stage 31.0 (TID 74). 1699 bytes result sent to driver
17/03/18 11:26:44 INFO TaskSetManager: Starting task 28.0 in stage 31.0 (TID 81, localhost, executor driver, partition 28, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:44 INFO TaskSetManager: Finished task 21.0 in stage 31.0 (TID 74) in 12238 ms on localhost (executor driver) (21/48)
17/03/18 11:26:44 INFO Executor: Running task 28.0 in stage 31.0 (TID 81)
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:44 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:44 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3758096384-3892314112, partition values: [empty row]
17/03/18 11:26:44 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000019_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000019
17/03/18 11:26:44 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000019_0: Committed
17/03/18 11:26:44 INFO Executor: Finished task 19.0 in stage 31.0 (TID 72). 1699 bytes result sent to driver
17/03/18 11:26:44 INFO TaskSetManager: Starting task 29.0 in stage 31.0 (TID 82, localhost, executor driver, partition 29, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:44 INFO TaskSetManager: Finished task 19.0 in stage 31.0 (TID 72) in 12518 ms on localhost (executor driver) (22/48)
17/03/18 11:26:44 INFO Executor: Running task 29.0 in stage 31.0 (TID 82)
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:44 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:44 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 3892314112-4026531840, partition values: [empty row]
17/03/18 11:26:44 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112631_0031_m_000022_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112631_0031_m_000022
17/03/18 11:26:44 INFO SparkHadoopMapRedUtil: attempt_20170318112631_0031_m_000022_0: Committed
17/03/18 11:26:44 INFO Executor: Finished task 22.0 in stage 31.0 (TID 75). 1699 bytes result sent to driver
17/03/18 11:26:44 INFO TaskSetManager: Starting task 30.0 in stage 31.0 (TID 83, localhost, executor driver, partition 30, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:44 INFO Executor: Running task 30.0 in stage 31.0 (TID 83)
17/03/18 11:26:44 INFO TaskSetManager: Finished task 22.0 in stage 31.0 (TID 75) in 12415 ms on localhost (executor driver) (23/48)
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:44 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:44 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4026531840-4160749568, partition values: [empty row]
17/03/18 11:26:44 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112632_0031_m_000023_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112632_0031_m_000023
17/03/18 11:26:44 INFO SparkHadoopMapRedUtil: attempt_20170318112632_0031_m_000023_0: Committed
17/03/18 11:26:44 INFO Executor: Finished task 23.0 in stage 31.0 (TID 76). 1699 bytes result sent to driver
17/03/18 11:26:44 INFO TaskSetManager: Starting task 31.0 in stage 31.0 (TID 84, localhost, executor driver, partition 31, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:44 INFO Executor: Running task 31.0 in stage 31.0 (TID 84)
17/03/18 11:26:44 INFO TaskSetManager: Finished task 23.0 in stage 31.0 (TID 76) in 12571 ms on localhost (executor driver) (24/48)
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:44 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:44 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:45 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:45 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4160749568-4294967296, partition values: [empty row]
17/03/18 11:26:54 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112643_0031_m_000024_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112643_0031_m_000024
17/03/18 11:26:54 INFO SparkHadoopMapRedUtil: attempt_20170318112643_0031_m_000024_0: Committed
17/03/18 11:26:54 INFO Executor: Finished task 24.0 in stage 31.0 (TID 77). 1699 bytes result sent to driver
17/03/18 11:26:54 INFO TaskSetManager: Starting task 32.0 in stage 31.0 (TID 85, localhost, executor driver, partition 32, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:54 INFO Executor: Running task 32.0 in stage 31.0 (TID 85)
17/03/18 11:26:54 INFO TaskSetManager: Finished task 24.0 in stage 31.0 (TID 77) in 11525 ms on localhost (executor driver) (25/48)
17/03/18 11:26:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:54 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:54 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4294967296-4429185024, partition values: [empty row]
17/03/18 11:26:54 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112643_0031_m_000025_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112643_0031_m_000025
17/03/18 11:26:54 INFO SparkHadoopMapRedUtil: attempt_20170318112643_0031_m_000025_0: Committed
17/03/18 11:26:54 INFO Executor: Finished task 25.0 in stage 31.0 (TID 78). 1699 bytes result sent to driver
17/03/18 11:26:54 INFO TaskSetManager: Starting task 33.0 in stage 31.0 (TID 86, localhost, executor driver, partition 33, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:54 INFO Executor: Running task 33.0 in stage 31.0 (TID 86)
17/03/18 11:26:54 INFO TaskSetManager: Finished task 25.0 in stage 31.0 (TID 78) in 11318 ms on localhost (executor driver) (26/48)
17/03/18 11:26:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:54 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:54 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:54 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:54 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:54 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:54 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4429185024-4563402752, partition values: [empty row]
17/03/18 11:26:55 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112643_0031_m_000026_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112643_0031_m_000026
17/03/18 11:26:55 INFO SparkHadoopMapRedUtil: attempt_20170318112643_0031_m_000026_0: Committed
17/03/18 11:26:55 INFO Executor: Finished task 26.0 in stage 31.0 (TID 79). 1699 bytes result sent to driver
17/03/18 11:26:55 INFO TaskSetManager: Starting task 34.0 in stage 31.0 (TID 87, localhost, executor driver, partition 34, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:55 INFO Executor: Running task 34.0 in stage 31.0 (TID 87)
17/03/18 11:26:55 INFO TaskSetManager: Finished task 26.0 in stage 31.0 (TID 79) in 11411 ms on localhost (executor driver) (27/48)
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:55 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:55 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4563402752-4697620480, partition values: [empty row]
17/03/18 11:26:55 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112643_0031_m_000027_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112643_0031_m_000027
17/03/18 11:26:55 INFO SparkHadoopMapRedUtil: attempt_20170318112643_0031_m_000027_0: Committed
17/03/18 11:26:55 INFO Executor: Finished task 27.0 in stage 31.0 (TID 80). 1699 bytes result sent to driver
17/03/18 11:26:55 INFO TaskSetManager: Starting task 35.0 in stage 31.0 (TID 88, localhost, executor driver, partition 35, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:55 INFO TaskSetManager: Finished task 27.0 in stage 31.0 (TID 80) in 11790 ms on localhost (executor driver) (28/48)
17/03/18 11:26:55 INFO Executor: Running task 35.0 in stage 31.0 (TID 88)
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:55 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:55 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4697620480-4831838208, partition values: [empty row]
17/03/18 11:26:55 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112644_0031_m_000029_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112644_0031_m_000029
17/03/18 11:26:55 INFO SparkHadoopMapRedUtil: attempt_20170318112644_0031_m_000029_0: Committed
17/03/18 11:26:55 INFO Executor: Finished task 29.0 in stage 31.0 (TID 82). 1699 bytes result sent to driver
17/03/18 11:26:55 INFO TaskSetManager: Starting task 36.0 in stage 31.0 (TID 89, localhost, executor driver, partition 36, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:55 INFO Executor: Running task 36.0 in stage 31.0 (TID 89)
17/03/18 11:26:55 INFO TaskSetManager: Finished task 29.0 in stage 31.0 (TID 82) in 11496 ms on localhost (executor driver) (29/48)
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:55 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:55 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4831838208-4966055936, partition values: [empty row]
17/03/18 11:26:55 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112644_0031_m_000030_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112644_0031_m_000030
17/03/18 11:26:55 INFO SparkHadoopMapRedUtil: attempt_20170318112644_0031_m_000030_0: Committed
17/03/18 11:26:55 INFO Executor: Finished task 30.0 in stage 31.0 (TID 83). 1699 bytes result sent to driver
17/03/18 11:26:55 INFO TaskSetManager: Starting task 37.0 in stage 31.0 (TID 90, localhost, executor driver, partition 37, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:55 INFO TaskSetManager: Finished task 30.0 in stage 31.0 (TID 83) in 11515 ms on localhost (executor driver) (30/48)
17/03/18 11:26:55 INFO Executor: Running task 37.0 in stage 31.0 (TID 90)
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:55 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:55 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:55 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:55 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 4966055936-5100273664, partition values: [empty row]
17/03/18 11:26:56 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112644_0031_m_000028_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112644_0031_m_000028
17/03/18 11:26:56 INFO SparkHadoopMapRedUtil: attempt_20170318112644_0031_m_000028_0: Committed
17/03/18 11:26:56 INFO Executor: Finished task 28.0 in stage 31.0 (TID 81). 1699 bytes result sent to driver
17/03/18 11:26:56 INFO TaskSetManager: Starting task 38.0 in stage 31.0 (TID 91, localhost, executor driver, partition 38, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:56 INFO TaskSetManager: Finished task 28.0 in stage 31.0 (TID 81) in 12088 ms on localhost (executor driver) (31/48)
17/03/18 11:26:56 INFO Executor: Running task 38.0 in stage 31.0 (TID 91)
17/03/18 11:26:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:56 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:56 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5100273664-5234491392, partition values: [empty row]
17/03/18 11:26:56 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112644_0031_m_000031_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112644_0031_m_000031
17/03/18 11:26:56 INFO SparkHadoopMapRedUtil: attempt_20170318112644_0031_m_000031_0: Committed
17/03/18 11:26:56 INFO Executor: Finished task 31.0 in stage 31.0 (TID 84). 1699 bytes result sent to driver
17/03/18 11:26:56 INFO TaskSetManager: Starting task 39.0 in stage 31.0 (TID 92, localhost, executor driver, partition 39, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:26:56 INFO Executor: Running task 39.0 in stage 31.0 (TID 92)
17/03/18 11:26:56 INFO TaskSetManager: Finished task 31.0 in stage 31.0 (TID 84) in 11730 ms on localhost (executor driver) (32/48)
17/03/18 11:26:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:56 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:26:56 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:26:56 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:26:56 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:26:56 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5234491392-5368709120, partition values: [empty row]
17/03/18 11:27:06 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112654_0031_m_000032_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112654_0031_m_000032
17/03/18 11:27:06 INFO SparkHadoopMapRedUtil: attempt_20170318112654_0031_m_000032_0: Committed
17/03/18 11:27:06 INFO Executor: Finished task 32.0 in stage 31.0 (TID 85). 1699 bytes result sent to driver
17/03/18 11:27:06 INFO TaskSetManager: Starting task 40.0 in stage 31.0 (TID 93, localhost, executor driver, partition 40, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:06 INFO TaskSetManager: Finished task 32.0 in stage 31.0 (TID 85) in 11534 ms on localhost (executor driver) (33/48)
17/03/18 11:27:06 INFO Executor: Running task 40.0 in stage 31.0 (TID 93)
17/03/18 11:27:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5368709120-5502926848, partition values: [empty row]
17/03/18 11:27:06 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112655_0031_m_000034_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112655_0031_m_000034
17/03/18 11:27:06 INFO SparkHadoopMapRedUtil: attempt_20170318112655_0031_m_000034_0: Committed
17/03/18 11:27:06 INFO Executor: Finished task 34.0 in stage 31.0 (TID 87). 1699 bytes result sent to driver
17/03/18 11:27:06 INFO TaskSetManager: Starting task 41.0 in stage 31.0 (TID 94, localhost, executor driver, partition 41, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:06 INFO TaskSetManager: Finished task 34.0 in stage 31.0 (TID 87) in 11719 ms on localhost (executor driver) (34/48)
17/03/18 11:27:06 INFO Executor: Running task 41.0 in stage 31.0 (TID 94)
17/03/18 11:27:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:06 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:06 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:06 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:06 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:06 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:06 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5502926848-5637144576, partition values: [empty row]
17/03/18 11:27:07 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112654_0031_m_000033_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112654_0031_m_000033
17/03/18 11:27:07 INFO SparkHadoopMapRedUtil: attempt_20170318112654_0031_m_000033_0: Committed
17/03/18 11:27:07 INFO Executor: Finished task 33.0 in stage 31.0 (TID 86). 1699 bytes result sent to driver
17/03/18 11:27:07 INFO TaskSetManager: Starting task 42.0 in stage 31.0 (TID 95, localhost, executor driver, partition 42, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:07 INFO TaskSetManager: Finished task 33.0 in stage 31.0 (TID 86) in 12178 ms on localhost (executor driver) (35/48)
17/03/18 11:27:07 INFO Executor: Running task 42.0 in stage 31.0 (TID 95)
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:07 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:07 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5637144576-5771362304, partition values: [empty row]
17/03/18 11:27:07 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112655_0031_m_000035_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112655_0031_m_000035
17/03/18 11:27:07 INFO SparkHadoopMapRedUtil: attempt_20170318112655_0031_m_000035_0: Committed
17/03/18 11:27:07 INFO Executor: Finished task 35.0 in stage 31.0 (TID 88). 1699 bytes result sent to driver
17/03/18 11:27:07 INFO TaskSetManager: Starting task 43.0 in stage 31.0 (TID 96, localhost, executor driver, partition 43, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:07 INFO TaskSetManager: Finished task 35.0 in stage 31.0 (TID 88) in 11670 ms on localhost (executor driver) (36/48)
17/03/18 11:27:07 INFO Executor: Running task 43.0 in stage 31.0 (TID 96)
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:07 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:07 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5771362304-5905580032, partition values: [empty row]
17/03/18 11:27:07 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112655_0031_m_000036_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112655_0031_m_000036
17/03/18 11:27:07 INFO SparkHadoopMapRedUtil: attempt_20170318112655_0031_m_000036_0: Committed
17/03/18 11:27:07 INFO Executor: Finished task 36.0 in stage 31.0 (TID 89). 1699 bytes result sent to driver
17/03/18 11:27:07 INFO TaskSetManager: Starting task 44.0 in stage 31.0 (TID 97, localhost, executor driver, partition 44, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:07 INFO Executor: Running task 44.0 in stage 31.0 (TID 97)
17/03/18 11:27:07 INFO TaskSetManager: Finished task 36.0 in stage 31.0 (TID 89) in 11715 ms on localhost (executor driver) (37/48)
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:07 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:07 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 5905580032-6039797760, partition values: [empty row]
17/03/18 11:27:07 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112655_0031_m_000037_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112655_0031_m_000037
17/03/18 11:27:07 INFO SparkHadoopMapRedUtil: attempt_20170318112655_0031_m_000037_0: Committed
17/03/18 11:27:07 INFO Executor: Finished task 37.0 in stage 31.0 (TID 90). 1699 bytes result sent to driver
17/03/18 11:27:07 INFO TaskSetManager: Starting task 45.0 in stage 31.0 (TID 98, localhost, executor driver, partition 45, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:07 INFO TaskSetManager: Finished task 37.0 in stage 31.0 (TID 90) in 11782 ms on localhost (executor driver) (38/48)
17/03/18 11:27:07 INFO Executor: Running task 45.0 in stage 31.0 (TID 98)
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:07 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:07 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:07 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:07 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 6039797760-6174015488, partition values: [empty row]
17/03/18 11:27:08 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112656_0031_m_000039_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112656_0031_m_000039
17/03/18 11:27:08 INFO SparkHadoopMapRedUtil: attempt_20170318112656_0031_m_000039_0: Committed
17/03/18 11:27:08 INFO Executor: Finished task 39.0 in stage 31.0 (TID 92). 1699 bytes result sent to driver
17/03/18 11:27:08 INFO TaskSetManager: Starting task 46.0 in stage 31.0 (TID 99, localhost, executor driver, partition 46, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:08 INFO TaskSetManager: Finished task 39.0 in stage 31.0 (TID 92) in 11720 ms on localhost (executor driver) (39/48)
17/03/18 11:27:08 INFO Executor: Running task 46.0 in stage 31.0 (TID 99)
17/03/18 11:27:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:08 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:08 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 6174015488-6308233216, partition values: [empty row]
17/03/18 11:27:08 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112656_0031_m_000038_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112656_0031_m_000038
17/03/18 11:27:08 INFO SparkHadoopMapRedUtil: attempt_20170318112656_0031_m_000038_0: Committed
17/03/18 11:27:08 INFO Executor: Finished task 38.0 in stage 31.0 (TID 91). 1699 bytes result sent to driver
17/03/18 11:27:08 INFO TaskSetManager: Starting task 47.0 in stage 31.0 (TID 100, localhost, executor driver, partition 47, PROCESS_LOCAL, 6586 bytes)
17/03/18 11:27:08 INFO Executor: Running task 47.0 in stage 31.0 (TID 100)
17/03/18 11:27:08 INFO TaskSetManager: Finished task 38.0 in stage 31.0 (TID 91) in 12154 ms on localhost (executor driver) (40/48)
17/03/18 11:27:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:08 INFO SQLHadoopMapReduceCommitProtocol: Using user defined output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:08 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
17/03/18 11:27:08 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.parquet.hadoop.ParquetOutputCommitter
17/03/18 11:27:08 INFO ParquetWriteSupport: Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "click",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "hour",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "banner_pos",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "site_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_domain",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "app_category",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_id",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_ip",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_model",
    "type" : "string",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "device_conn_type",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C14",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C15",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C16",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C17",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C18",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C19",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C20",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  }, {
    "name" : "C21",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional binary id (UTF8);
  optional int32 click;
  optional binary hour (UTF8);
  optional int32 C1;
  optional int32 banner_pos;
  optional binary site_id (UTF8);
  optional binary site_domain (UTF8);
  optional binary site_category (UTF8);
  optional binary app_id (UTF8);
  optional binary app_domain (UTF8);
  optional binary app_category (UTF8);
  optional binary device_id (UTF8);
  optional binary device_ip (UTF8);
  optional binary device_model (UTF8);
  optional int32 device_type;
  optional int32 device_conn_type;
  optional int32 C14;
  optional int32 C15;
  optional int32 C16;
  optional int32 C17;
  optional int32 C18;
  optional int32 C19;
  optional int32 C20;
  optional int32 C21;
}

       
17/03/18 11:27:08 INFO CodecPool: Got brand-new compressor [.snappy]
17/03/18 11:27:08 INFO FileScanRDD: Reading File path: file:///home/yannick/tmp/train.csv, range: 6308233216-6311147778, partition values: [empty row]
17/03/18 11:27:08 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112708_0031_m_000047_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112708_0031_m_000047
17/03/18 11:27:08 INFO SparkHadoopMapRedUtil: attempt_20170318112708_0031_m_000047_0: Committed
17/03/18 11:27:08 INFO Executor: Finished task 47.0 in stage 31.0 (TID 100). 1626 bytes result sent to driver
17/03/18 11:27:08 INFO TaskSetManager: Finished task 47.0 in stage 31.0 (TID 100) in 311 ms on localhost (executor driver) (41/48)
17/03/18 11:27:16 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112706_0031_m_000041_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112706_0031_m_000041
17/03/18 11:27:16 INFO SparkHadoopMapRedUtil: attempt_20170318112706_0031_m_000041_0: Committed
17/03/18 11:27:16 INFO Executor: Finished task 41.0 in stage 31.0 (TID 94). 1699 bytes result sent to driver
17/03/18 11:27:16 INFO TaskSetManager: Finished task 41.0 in stage 31.0 (TID 94) in 10183 ms on localhost (executor driver) (42/48)
17/03/18 11:27:17 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112706_0031_m_000040_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112706_0031_m_000040
17/03/18 11:27:17 INFO SparkHadoopMapRedUtil: attempt_20170318112706_0031_m_000040_0: Committed
17/03/18 11:27:17 INFO Executor: Finished task 40.0 in stage 31.0 (TID 93). 1699 bytes result sent to driver
17/03/18 11:27:17 INFO TaskSetManager: Finished task 40.0 in stage 31.0 (TID 93) in 10708 ms on localhost (executor driver) (43/48)
17/03/18 11:27:17 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112707_0031_m_000042_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112707_0031_m_000042
17/03/18 11:27:17 INFO SparkHadoopMapRedUtil: attempt_20170318112707_0031_m_000042_0: Committed
17/03/18 11:27:17 INFO Executor: Finished task 42.0 in stage 31.0 (TID 95). 1699 bytes result sent to driver
17/03/18 11:27:17 INFO TaskSetManager: Finished task 42.0 in stage 31.0 (TID 95) in 10443 ms on localhost (executor driver) (44/48)
17/03/18 11:27:17 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112707_0031_m_000043_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112707_0031_m_000043
17/03/18 11:27:17 INFO SparkHadoopMapRedUtil: attempt_20170318112707_0031_m_000043_0: Committed
17/03/18 11:27:17 INFO Executor: Finished task 43.0 in stage 31.0 (TID 96). 1699 bytes result sent to driver
17/03/18 11:27:17 INFO TaskSetManager: Finished task 43.0 in stage 31.0 (TID 96) in 10294 ms on localhost (executor driver) (45/48)
17/03/18 11:27:17 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112707_0031_m_000044_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112707_0031_m_000044
17/03/18 11:27:17 INFO SparkHadoopMapRedUtil: attempt_20170318112707_0031_m_000044_0: Committed
17/03/18 11:27:17 INFO Executor: Finished task 44.0 in stage 31.0 (TID 97). 1699 bytes result sent to driver
17/03/18 11:27:17 INFO TaskSetManager: Finished task 44.0 in stage 31.0 (TID 97) in 10502 ms on localhost (executor driver) (46/48)
17/03/18 11:27:18 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112708_0031_m_000046_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112708_0031_m_000046
17/03/18 11:27:18 INFO SparkHadoopMapRedUtil: attempt_20170318112708_0031_m_000046_0: Committed
17/03/18 11:27:18 INFO Executor: Finished task 46.0 in stage 31.0 (TID 99). 1699 bytes result sent to driver
17/03/18 11:27:18 INFO TaskSetManager: Finished task 46.0 in stage 31.0 (TID 99) in 9948 ms on localhost (executor driver) (47/48)
17/03/18 11:27:18 INFO FileOutputCommitter: Saved output of task 'attempt_20170318112707_0031_m_000045_0' to file:/home4/yannick4/tmp/train.parquet/_temporary/0/task_20170318112707_0031_m_000045
17/03/18 11:27:18 INFO SparkHadoopMapRedUtil: attempt_20170318112707_0031_m_000045_0: Committed
17/03/18 11:27:18 INFO Executor: Finished task 45.0 in stage 31.0 (TID 98). 1699 bytes result sent to driver
17/03/18 11:27:18 INFO TaskSetManager: Finished task 45.0 in stage 31.0 (TID 98) in 10704 ms on localhost (executor driver) (48/48)
17/03/18 11:27:18 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/03/18 11:27:18 INFO DAGScheduler: ResultStage 31 (parquet at NativeMethodAccessorImpl.java:0) finished in 72,128 s
17/03/18 11:27:18 INFO DAGScheduler: Job 25 finished: parquet at NativeMethodAccessorImpl.java:0, took 72,158795 s
17/03/18 11:27:18 INFO FileFormatWriter: Job null committed.
17/03/18 11:27:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:27:18 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:18 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:18 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:18 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:27:18 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:27:47 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:27:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:27:47 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 11:27:47 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:27:47 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:27:47 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:27:47 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:27:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:27:47 INFO Utils: Successfully started service 'sparkDriver' on port 60391.
17/03/18 11:27:47 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:27:48 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:27:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:27:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:27:48 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-f54ec170-216f-429e-8e91-fc8a963dd789
17/03/18 11:27:48 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 11:27:48 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:27:48 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/03/18 11:27:48 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/03/18 11:27:48 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/03/18 11:27:48 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:60391/jars/sparklyr-2.1-2.11.jar with timestamp 1489832868268
17/03/18 11:27:48 INFO Executor: Starting executor ID driver on host localhost
17/03/18 11:27:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49760.
17/03/18 11:27:48 INFO NettyBlockTransferService: Server created on 127.0.0.1:49760
17/03/18 11:27:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 11:27:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49760, None)
17/03/18 11:27:48 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49760 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 49760, None)
17/03/18 11:27:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49760, None)
17/03/18 11:27:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49760, None)
17/03/18 11:27:48 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 11:27:48 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 11:27:48 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 11:27:49 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 11:27:49 INFO ObjectStore: ObjectStore, initialize called
17/03/18 11:27:49 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 11:27:49 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 11:27:50 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 11:27:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:27:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:27:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:27:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:27:51 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 11:27:51 INFO ObjectStore: Initialized ObjectStore
17/03/18 11:27:51 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 11:27:51 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 11:27:51 INFO HiveMetaStore: Added admin role in metastore
17/03/18 11:27:51 INFO HiveMetaStore: Added public role in metastore
17/03/18 11:27:51 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 11:27:51 INFO HiveMetaStore: 0: get_all_databases
17/03/18 11:27:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 11:27:52 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 11:27:52 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 11:27:52 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:27:52 INFO SessionState: Created local directory: /tmp/72f2de8b-42f0-4d8c-bc29-88378ff602c5_resources
17/03/18 11:27:52 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/72f2de8b-42f0-4d8c-bc29-88378ff602c5
17/03/18 11:27:52 INFO SessionState: Created local directory: /tmp/yannick/72f2de8b-42f0-4d8c-bc29-88378ff602c5
17/03/18 11:27:52 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/72f2de8b-42f0-4d8c-bc29-88378ff602c5/_tmp_space.db
17/03/18 11:27:52 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 11:27:52 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:52 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:52 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 11:27:52 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 11:27:52 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 11:27:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:27:53 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:53 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:53 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:53 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:53 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:27:53 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:27:54 INFO CodeGenerator: Code generated in 240.220383 ms
17/03/18 11:27:54 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:27:54 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:27:54 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/03/18 11:27:54 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:27:54 INFO DAGScheduler: Missing parents: List()
17/03/18 11:27:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/03/18 11:27:54 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:27:54 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:27:54 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49760 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:27:54 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/18 11:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/03/18 11:27:54 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/18 11:27:54 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/03/18 11:27:54 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/18 11:27:54 INFO Executor: Fetching spark://127.0.0.1:60391/jars/sparklyr-2.1-2.11.jar with timestamp 1489832868268
17/03/18 11:27:54 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60391 after 8 ms (0 ms spent in bootstraps)
17/03/18 11:27:54 INFO Utils: Fetching spark://127.0.0.1:60391/jars/sparklyr-2.1-2.11.jar to /home/yannick/tmp/sparklyr/spark-da172793-11b3-40dd-946f-a0dd52f8743b/userFiles-a9167042-6ee4-477a-b086-acec9f03b0bb/fetchFileTemp1915181026000364574.tmp
17/03/18 11:27:54 INFO Executor: Adding file:/home/yannick/tmp/sparklyr/spark-da172793-11b3-40dd-946f-a0dd52f8743b/userFiles-a9167042-6ee4-477a-b086-acec9f03b0bb/sparklyr-2.1-2.11.jar to class loader
17/03/18 11:27:54 INFO CodeGenerator: Code generated in 10.765867 ms
17/03/18 11:27:54 INFO CodeGenerator: Code generated in 9.540315 ms
17/03/18 11:27:54 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/03/18 11:27:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 175 ms on localhost (executor driver) (1/1)
17/03/18 11:27:54 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/18 11:27:54 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0,189 s
17/03/18 11:27:54 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 0,312654 s
17/03/18 11:27:54 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:27:54 INFO DAGScheduler: Got job 1 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:27:54 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:27:54 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:27:54 INFO DAGScheduler: Missing parents: List()
17/03/18 11:27:54 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:27:54 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:27:54 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:27:54 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49760 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:27:54 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/03/18 11:27:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:27:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/18 11:27:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6217 bytes)
17/03/18 11:27:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/18 11:27:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2690 bytes result sent to driver
17/03/18 11:27:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 116 ms on localhost (executor driver) (1/1)
17/03/18 11:27:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/18 11:27:55 INFO DAGScheduler: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,117 s
17/03/18 11:27:55 INFO DAGScheduler: Job 1 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,148364 s
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: train
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz1`
WHERE (0 = 1)
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:27:55 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:27:55 INFO DAGScheduler: Got job 2 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:27:55 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:59)
17/03/18 11:27:55 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:27:55 INFO DAGScheduler: Missing parents: List()
17/03/18 11:27:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[14] at map at utils.scala:56), which has no missing parents
17/03/18 11:27:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:27:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:27:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49760 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:27:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/03/18 11:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[14] at map at utils.scala:56)
17/03/18 11:27:55 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/18 11:27:55 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6354 bytes)
17/03/18 11:27:55 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/18 11:27:55 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1239 bytes result sent to driver
17/03/18 11:27:55 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 12 ms on localhost (executor driver) (1/1)
17/03/18 11:27:55 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/18 11:27:55 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:59) finished in 0,013 s
17/03/18 11:27:55 INFO DAGScheduler: Job 2 finished: collect at utils.scala:59, took 0,024965 s
17/03/18 11:27:55 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:27:55 INFO DAGScheduler: Got job 3 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:27:55 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:27:55 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:27:55 INFO DAGScheduler: Missing parents: List()
17/03/18 11:27:55 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:27:55 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:27:55 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:27:55 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49760 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:27:55 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/03/18 11:27:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:27:55 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/18 11:27:55 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6220 bytes)
17/03/18 11:27:55 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/18 11:27:55 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2690 bytes result sent to driver
17/03/18 11:27:55 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 20 ms on localhost (executor driver) (1/1)
17/03/18 11:27:55 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/18 11:27:55 INFO DAGScheduler: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,021 s
17/03/18 11:27:55 INFO DAGScheduler: Job 3 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,039942 s
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: train
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz2`
WHERE (0 = 1)
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:27:55 INFO CodeGenerator: Code generated in 10.961189 ms
17/03/18 11:27:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:27:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:27:55 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:28:11 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:28:11 INFO DAGScheduler: Got job 4 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:28:11 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:59)
17/03/18 11:28:11 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:11 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:11 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[25] at map at utils.scala:56), which has no missing parents
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:28:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49760 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[25] at map at utils.scala:56)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/03/18 11:28:11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6354 bytes)
17/03/18 11:28:11 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/03/18 11:28:11 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 1239 bytes result sent to driver
17/03/18 11:28:11 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 10 ms on localhost (executor driver) (1/1)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/18 11:28:11 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:59) finished in 0,011 s
17/03/18 11:28:11 INFO DAGScheduler: Job 4 finished: collect at utils.scala:59, took 0,020914 s
17/03/18 11:28:11 INFO ContextCleaner: Cleaned accumulator 0
17/03/18 11:28:11 INFO ContextCleaner: Cleaned accumulator 1
17/03/18 11:28:11 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49760 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:49760 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO ContextCleaner: Cleaned accumulator 99
17/03/18 11:28:11 INFO ContextCleaner: Cleaned accumulator 100
17/03/18 11:28:11 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49760 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49760 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO ContextCleaner: Cleaned accumulator 198
17/03/18 11:28:11 INFO ContextCleaner: Cleaned accumulator 199
17/03/18 11:28:11 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49760 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:28:11 INFO DAGScheduler: Got job 5 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:28:11 INFO DAGScheduler: Final stage: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:11 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:11 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:11 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:28:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49760 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[27] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/18 11:28:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, executor driver, partition 0, PROCESS_LOCAL, 6217 bytes)
17/03/18 11:28:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/03/18 11:28:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 2603 bytes result sent to driver
17/03/18 11:28:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 17 ms on localhost (executor driver) (1/1)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/18 11:28:11 INFO DAGScheduler: ResultStage 5 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,017 s
17/03/18 11:28:11 INFO DAGScheduler: Job 5 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,033889 s
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: train
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz3`
WHERE (0 = 1)
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:28:11 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:28:11 INFO DAGScheduler: Got job 6 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:28:11 INFO DAGScheduler: Final stage: ResultStage 6 (collect at utils.scala:59)
17/03/18 11:28:11 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:11 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:11 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at map at utils.scala:56), which has no missing parents
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:28:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49760 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at map at utils.scala:56)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
17/03/18 11:28:11 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6354 bytes)
17/03/18 11:28:11 INFO Executor: Running task 0.0 in stage 6.0 (TID 6)
17/03/18 11:28:11 INFO Executor: Finished task 0.0 in stage 6.0 (TID 6). 1239 bytes result sent to driver
17/03/18 11:28:11 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 7 ms on localhost (executor driver) (1/1)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/18 11:28:11 INFO DAGScheduler: ResultStage 6 (collect at utils.scala:59) finished in 0,007 s
17/03/18 11:28:11 INFO DAGScheduler: Job 6 finished: collect at utils.scala:59, took 0,013891 s
17/03/18 11:28:11 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:28:11 INFO DAGScheduler: Got job 7 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:28:11 INFO DAGScheduler: Final stage: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:11 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:11 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:11 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[36] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:28:11 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.3 KB, free 6.2 GB)
17/03/18 11:28:11 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49760 (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:28:11 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[36] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/03/18 11:28:11 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 7, localhost, executor driver, partition 0, PROCESS_LOCAL, 6220 bytes)
17/03/18 11:28:11 INFO Executor: Running task 0.0 in stage 7.0 (TID 7)
17/03/18 11:28:11 INFO Executor: Finished task 0.0 in stage 7.0 (TID 7). 2603 bytes result sent to driver
17/03/18 11:28:11 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 7) in 20 ms on localhost (executor driver) (1/1)
17/03/18 11:28:11 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/18 11:28:11 INFO DAGScheduler: ResultStage 7 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,020 s
17/03/18 11:28:11 INFO DAGScheduler: Job 7 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,032633 s
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: train10k
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz4`
WHERE (0 = 1)
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:28:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:28:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:28:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:28:14 INFO SparkSqlParser: Parsing command: SELECT * FROM train10k LIMIT 1000
17/03/18 11:28:14 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:28:14 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:28:14 INFO FileSourceStrategy: Output Data Schema: struct<id: string, click: int, hour: string, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:28:14 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:28:14 INFO CodeGenerator: Code generated in 68.427015 ms
17/03/18 11:28:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:28:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 24.8 KB, free 6.2 GB)
17/03/18 11:28:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:49760 (size: 24.8 KB, free: 6.2 GB)
17/03/18 11:28:14 INFO SparkContext: Created broadcast 8 from collect at utils.scala:197
17/03/18 11:28:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:28:15 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:28:15 INFO DAGScheduler: Got job 8 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:28:15 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:197)
17/03/18 11:28:15 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:15 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:15 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:197), which has no missing parents
17/03/18 11:28:15 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 18.3 KB, free 6.2 GB)
17/03/18 11:28:15 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.2 KB, free 6.2 GB)
17/03/18 11:28:15 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:49760 (size: 6.2 KB, free: 6.2 GB)
17/03/18 11:28:15 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[42] at collect at utils.scala:197)
17/03/18 11:28:15 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/03/18 11:28:15 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 8, localhost, executor driver, partition 0, PROCESS_LOCAL, 6563 bytes)
17/03/18 11:28:15 INFO Executor: Running task 0.0 in stage 8.0 (TID 8)
17/03/18 11:28:15 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:28:15 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:15 INFO Executor: Finished task 0.0 in stage 8.0 (TID 8). 68544 bytes result sent to driver
17/03/18 11:28:15 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 8) in 230 ms on localhost (executor driver) (1/1)
17/03/18 11:28:15 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/18 11:28:15 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:197) finished in 0,231 s
17/03/18 11:28:15 INFO DAGScheduler: Job 8 finished: collect at utils.scala:197, took 0,248191 s
17/03/18 11:28:15 INFO CodeGenerator: Code generated in 31.79508 ms
17/03/18 11:28:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 11:28:23 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:28:23 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:28:23 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:28:23 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:28:23 INFO CodeGenerator: Code generated in 9.039165 ms
17/03/18 11:28:23 INFO CodeGenerator: Code generated in 9.277368 ms
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:49760 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:28:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:28:23 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:28:23 INFO DAGScheduler: Registering RDD 45 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO DAGScheduler: Got job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:28:23 INFO DAGScheduler: Final stage: ResultStage 10 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9)
17/03/18 11:28:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 9)
17/03/18 11:28:23 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[45] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:49760 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[45] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/03/18 11:28:23 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 9, localhost, executor driver, partition 0, PROCESS_LOCAL, 6638 bytes)
17/03/18 11:28:23 INFO Executor: Running task 0.0 in stage 9.0 (TID 9)
17/03/18 11:28:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:28:23 INFO Executor: Finished task 0.0 in stage 9.0 (TID 9). 2144 bytes result sent to driver
17/03/18 11:28:23 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 9) in 45 ms on localhost (executor driver) (1/1)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/18 11:28:23 INFO DAGScheduler: ShuffleMapStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0,046 s
17/03/18 11:28:23 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:28:23 INFO DAGScheduler: running: Set()
17/03/18 11:28:23 INFO DAGScheduler: waiting: Set(ResultStage 10)
17/03/18 11:28:23 INFO DAGScheduler: failed: Set()
17/03/18 11:28:23 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:49760 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[48] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/03/18 11:28:23 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:49760 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49760 in memory (size: 25.3 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO ContextCleaner: Cleaned accumulator 297
17/03/18 11:28:23 INFO ContextCleaner: Cleaned accumulator 298
17/03/18 11:28:23 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 10, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/03/18 11:28:23 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49760 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO Executor: Running task 0.0 in stage 10.0 (TID 10)
17/03/18 11:28:23 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:49760 in memory (size: 6.2 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO ContextCleaner: Cleaned accumulator 447
17/03/18 11:28:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 11:28:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/03/18 11:28:23 INFO Executor: Finished task 0.0 in stage 10.0 (TID 10). 2042 bytes result sent to driver
17/03/18 11:28:23 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 10) in 29 ms on localhost (executor driver) (1/1)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/18 11:28:23 INFO DAGScheduler: ResultStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0,030 s
17/03/18 11:28:23 INFO DAGScheduler: Job 9 finished: count at NativeMethodAccessorImpl.java:0, took 0,217334 s
17/03/18 11:28:23 INFO CodeGenerator: Code generated in 8.127017 ms
17/03/18 11:28:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
17/03/18 11:28:23 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:28:23 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:28:23 INFO FileSourceStrategy: Output Data Schema: struct<>
17/03/18 11:28:23 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 297.0 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 24.2 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:49760 (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0
17/03/18 11:28:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:28:23 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
17/03/18 11:28:23 INFO DAGScheduler: Registering RDD 51 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:28:23 INFO DAGScheduler: Final stage: ResultStage 12 (count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/03/18 11:28:23 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/03/18 11:28:23 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 10.5 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.3 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:49760 (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:23 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[51] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
17/03/18 11:28:23 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6639 bytes)
17/03/18 11:28:23 INFO Executor: Running task 0.0 in stage 11.0 (TID 11)
17/03/18 11:28:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:28:23 INFO Executor: Finished task 0.0 in stage 11.0 (TID 11). 2057 bytes result sent to driver
17/03/18 11:28:23 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 8 ms on localhost (executor driver) (1/1)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/03/18 11:28:23 INFO DAGScheduler: ShuffleMapStage 11 (count at NativeMethodAccessorImpl.java:0) finished in 0,009 s
17/03/18 11:28:23 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:28:23 INFO DAGScheduler: running: Set()
17/03/18 11:28:23 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/03/18 11:28:23 INFO DAGScheduler: failed: Set()
17/03/18 11:28:23 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:49760 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/03/18 11:28:23 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 12, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/03/18 11:28:23 INFO Executor: Running task 0.0 in stage 12.0 (TID 12)
17/03/18 11:28:23 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/18 11:28:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:28:23 INFO Executor: Finished task 0.0 in stage 12.0 (TID 12). 2042 bytes result sent to driver
17/03/18 11:28:23 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 12) in 5 ms on localhost (executor driver) (1/1)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/03/18 11:28:23 INFO DAGScheduler: ResultStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0,006 s
17/03/18 11:28:23 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0,025527 s
17/03/18 11:28:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k`
LIMIT 10
17/03/18 11:28:23 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:28:23 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:28:23 INFO FileSourceStrategy: Output Data Schema: struct<id: string, click: int, hour: string, C1: int, banner_pos: int ... 22 more fields>
17/03/18 11:28:23 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 303.1 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 24.8 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:49760 (size: 24.8 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 16 from collect at utils.scala:197
17/03/18 11:28:23 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:28:23 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:28:23 INFO DAGScheduler: Got job 11 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:28:23 INFO DAGScheduler: Final stage: ResultStage 13 (collect at utils.scala:197)
17/03/18 11:28:23 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:23 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:23 INFO DAGScheduler: Submitting ResultStage 13 (MapPartitionsRDD[57] at collect at utils.scala:197), which has no missing parents
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.3 KB, free 6.2 GB)
17/03/18 11:28:23 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.2 KB, free 6.2 GB)
17/03/18 11:28:23 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:49760 (size: 6.2 KB, free: 6.2 GB)
17/03/18 11:28:23 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 13 (MapPartitionsRDD[57] at collect at utils.scala:197)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks
17/03/18 11:28:23 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 13, localhost, executor driver, partition 0, PROCESS_LOCAL, 6564 bytes)
17/03/18 11:28:23 INFO Executor: Running task 0.0 in stage 13.0 (TID 13)
17/03/18 11:28:23 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train10k.parquet/part-00000-628dbbac-4fba-4daa-894f-848351616682.snappy.parquet, range: 0-388956, partition values: [empty row]
17/03/18 11:28:23 INFO Executor: Finished task 0.0 in stage 13.0 (TID 13). 2488 bytes result sent to driver
17/03/18 11:28:23 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 13) in 21 ms on localhost (executor driver) (1/1)
17/03/18 11:28:23 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/03/18 11:28:23 INFO DAGScheduler: ResultStage 13 (collect at utils.scala:197) finished in 0,022 s
17/03/18 11:28:23 INFO DAGScheduler: Job 11 finished: collect at utils.scala:197, took 0,031426 s
17/03/18 11:28:39 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM (SELECT *
FROM (SELECT `device_id`, `device_ip`, `int_day`, `int_hour`, `int_hour` - LAG(`int_hour`, 1, NULL) OVER (PARTITION BY `device_id`, `device_ip`, `int_day` ORDER BY "int_hour") AS `dt_hour`
FROM (SELECT `device_id` AS `device_id`, `device_ip` AS `device_ip`, `int_day` AS `int_day`, `int_hour` AS `int_hour`
FROM (SELECT *
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, `int_day`, SUBSTR(`hour`, 7.0, 2.0) AS `int_hour`
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, SUBSTR(`hour`, 5.0, 2.0) AS `int_day`
FROM `train`) `gbyznlbdtw`) `ktpbsddxhe`
ORDER BY `int_hour`) `gnqkleexzg`) `jqwnwmvcaq`) `ijmouahqkx`
WHERE ((`dt_hour`) IS NULL)) `vkaqieqyvj`
17/03/18 11:28:39 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:28:39 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:28:39 INFO FileSourceStrategy: Output Data Schema: struct<hour: string, device_id: string, device_ip: string ... 1 more fields>
17/03/18 11:28:39 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:28:39 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/03/18 11:28:39 INFO CodeGenerator: Code generated in 10.740405 ms
17/03/18 11:28:39 INFO CodeGenerator: Code generated in 10.752677 ms
17/03/18 11:28:39 INFO CodeGenerator: Code generated in 10.572696 ms
17/03/18 11:28:39 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 297.7 KB, free 6.2 GB)
17/03/18 11:28:39 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 24.3 KB, free 6.2 GB)
17/03/18 11:28:39 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:49760 (size: 24.3 KB, free: 6.2 GB)
17/03/18 11:28:39 INFO SparkContext: Created broadcast 18 from collect at utils.scala:197
17/03/18 11:28:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:28:39 INFO CodeGenerator: Code generated in 15.673093 ms
17/03/18 11:28:39 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:28:39 INFO DAGScheduler: Got job 12 (collect at utils.scala:197) with 16 output partitions
17/03/18 11:28:39 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:197)
17/03/18 11:28:39 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:28:39 INFO DAGScheduler: Missing parents: List()
17/03/18 11:28:39 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[62] at collect at utils.scala:197), which has no missing parents
17/03/18 11:28:39 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 10.7 KB, free 6.2 GB)
17/03/18 11:28:39 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 4.9 KB, free 6.2 GB)
17/03/18 11:28:39 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:49760 (size: 4.9 KB, free: 6.2 GB)
17/03/18 11:28:39 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:39 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 14 (MapPartitionsRDD[62] at collect at utils.scala:197)
17/03/18 11:28:39 INFO TaskSchedulerImpl: Adding task set 14.0 with 16 tasks
17/03/18 11:28:39 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 14, localhost, executor driver, partition 0, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 15, localhost, executor driver, partition 1, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 16, localhost, executor driver, partition 2, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 3.0 in stage 14.0 (TID 17, localhost, executor driver, partition 3, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 4.0 in stage 14.0 (TID 18, localhost, executor driver, partition 4, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 5.0 in stage 14.0 (TID 19, localhost, executor driver, partition 5, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 6.0 in stage 14.0 (TID 20, localhost, executor driver, partition 6, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO TaskSetManager: Starting task 7.0 in stage 14.0 (TID 21, localhost, executor driver, partition 7, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:39 INFO Executor: Running task 0.0 in stage 14.0 (TID 14)
17/03/18 11:28:39 INFO Executor: Running task 1.0 in stage 14.0 (TID 15)
17/03/18 11:28:39 INFO Executor: Running task 2.0 in stage 14.0 (TID 16)
17/03/18 11:28:39 INFO Executor: Running task 3.0 in stage 14.0 (TID 17)
17/03/18 11:28:39 INFO Executor: Running task 4.0 in stage 14.0 (TID 18)
17/03/18 11:28:39 INFO Executor: Running task 6.0 in stage 14.0 (TID 20)
17/03/18 11:28:39 INFO Executor: Running task 5.0 in stage 14.0 (TID 19)
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32949915, partition values: [empty row]
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32363934, partition values: [empty row]
17/03/18 11:28:39 INFO Executor: Running task 7.0 in stage 14.0 (TID 21)
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32649993, partition values: [empty row]
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32106576, partition values: [empty row]
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32740461, partition values: [empty row]
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32501332, partition values: [empty row]
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32204489, partition values: [empty row]
17/03/18 11:28:39 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32029174, partition values: [empty row]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:39 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 452
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 718
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 719
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 720
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:49760 in memory (size: 6.2 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:49760 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 557
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 558
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 559
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 560
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 561
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 562
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 563
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 564
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 565
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 566
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 567
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 568
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 569
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 570
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 127.0.0.1:49760 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO ContextCleaner: Cleaned shuffle 1
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:49760 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:49760 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 451
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 450
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 449
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 448
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:49760 in memory (size: 5.3 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO ContextCleaner: Cleaned shuffle 0
17/03/18 11:28:40 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:49760 in memory (size: 24.2 KB, free: 6.2 GB)
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 460
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 459
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 458
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 457
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 456
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 455
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 454
17/03/18 11:28:40 INFO ContextCleaner: Cleaned accumulator 453
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32072404, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31999562, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32717377, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32417617, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32316443, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32151503, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32897976, partition values: [empty row]
17/03/18 11:28:40 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32565291, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32682016, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32049222, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32288085, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32141823, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32523558, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32386451, partition values: [empty row]
17/03/18 11:28:41 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31964726, partition values: [empty row]
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32776335, partition values: [empty row]
17/03/18 11:28:42 INFO Executor: Finished task 1.0 in stage 14.0 (TID 15). 4709 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 8.0 in stage 14.0 (TID 22, localhost, executor driver, partition 8, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO Executor: Running task 8.0 in stage 14.0 (TID 22)
17/03/18 11:28:42 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 15) in 2469 ms on localhost (executor driver) (1/16)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31943445, partition values: [empty row]
17/03/18 11:28:42 INFO Executor: Finished task 5.0 in stage 14.0 (TID 19). 4622 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 9.0 in stage 14.0 (TID 23, localhost, executor driver, partition 9, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO TaskSetManager: Finished task 5.0 in stage 14.0 (TID 19) in 2677 ms on localhost (executor driver) (2/16)
17/03/18 11:28:42 INFO Executor: Running task 9.0 in stage 14.0 (TID 23)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31811845, partition values: [empty row]
17/03/18 11:28:42 INFO Executor: Finished task 4.0 in stage 14.0 (TID 18). 4622 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 10.0 in stage 14.0 (TID 24, localhost, executor driver, partition 10, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO Executor: Running task 10.0 in stage 14.0 (TID 24)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31749906, partition values: [empty row]
17/03/18 11:28:42 INFO TaskSetManager: Finished task 4.0 in stage 14.0 (TID 18) in 2728 ms on localhost (executor driver) (3/16)
17/03/18 11:28:42 INFO Executor: Finished task 6.0 in stage 14.0 (TID 20). 4622 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 11.0 in stage 14.0 (TID 25, localhost, executor driver, partition 11, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO Executor: Running task 11.0 in stage 14.0 (TID 25)
17/03/18 11:28:42 INFO TaskSetManager: Finished task 6.0 in stage 14.0 (TID 20) in 2990 ms on localhost (executor driver) (4/16)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31694773, partition values: [empty row]
17/03/18 11:28:42 INFO Executor: Finished task 2.0 in stage 14.0 (TID 16). 4622 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 12.0 in stage 14.0 (TID 26, localhost, executor driver, partition 12, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 16) in 3040 ms on localhost (executor driver) (5/16)
17/03/18 11:28:42 INFO Executor: Running task 12.0 in stage 14.0 (TID 26)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31652386, partition values: [empty row]
17/03/18 11:28:42 INFO Executor: Finished task 3.0 in stage 14.0 (TID 17). 4709 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 13.0 in stage 14.0 (TID 27, localhost, executor driver, partition 13, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO Executor: Running task 13.0 in stage 14.0 (TID 27)
17/03/18 11:28:42 INFO TaskSetManager: Finished task 3.0 in stage 14.0 (TID 17) in 3174 ms on localhost (executor driver) (6/16)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31502478, partition values: [empty row]
17/03/18 11:28:42 INFO Executor: Finished task 7.0 in stage 14.0 (TID 21). 4622 bytes result sent to driver
17/03/18 11:28:42 INFO TaskSetManager: Starting task 14.0 in stage 14.0 (TID 28, localhost, executor driver, partition 14, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:42 INFO Executor: Running task 14.0 in stage 14.0 (TID 28)
17/03/18 11:28:42 INFO TaskSetManager: Finished task 7.0 in stage 14.0 (TID 21) in 3183 ms on localhost (executor driver) (7/16)
17/03/18 11:28:42 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31219072, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31693702, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31904148, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31776923, partition values: [empty row]
17/03/18 11:28:43 INFO Executor: Finished task 0.0 in stage 14.0 (TID 14). 4622 bytes result sent to driver
17/03/18 11:28:43 INFO TaskSetManager: Starting task 15.0 in stage 14.0 (TID 29, localhost, executor driver, partition 15, PROCESS_LOCAL, 6944 bytes)
17/03/18 11:28:43 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 14) in 3635 ms on localhost (executor driver) (8/16)
17/03/18 11:28:43 INFO Executor: Running task 15.0 in stage 14.0 (TID 29)
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30888717, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31740900, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31617619, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31466713, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31188290, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31754546, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31685098, partition values: [empty row]
17/03/18 11:28:43 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31886681, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30500702, partition values: [empty row]
17/03/18 11:28:44 INFO Executor: Finished task 9.0 in stage 14.0 (TID 23). 4622 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 9.0 in stage 14.0 (TID 23) in 1700 ms on localhost (executor driver) (9/16)
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31503322, partition values: [empty row]
17/03/18 11:28:44 INFO Executor: Finished task 11.0 in stage 14.0 (TID 25). 4622 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 11.0 in stage 14.0 (TID 25) in 1674 ms on localhost (executor driver) (10/16)
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31696456, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31337009, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30943043, partition values: [empty row]
17/03/18 11:28:44 INFO Executor: Finished task 8.0 in stage 14.0 (TID 22). 4622 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 8.0 in stage 14.0 (TID 22) in 2406 ms on localhost (executor driver) (11/16)
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-728067, partition values: [empty row]
17/03/18 11:28:44 INFO Executor: Finished task 15.0 in stage 14.0 (TID 29). 4622 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 15.0 in stage 14.0 (TID 29) in 1340 ms on localhost (executor driver) (12/16)
17/03/18 11:28:44 INFO Executor: Finished task 12.0 in stage 14.0 (TID 26). 4709 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 12.0 in stage 14.0 (TID 26) in 1968 ms on localhost (executor driver) (13/16)
17/03/18 11:28:44 INFO Executor: Finished task 10.0 in stage 14.0 (TID 24). 4622 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 10.0 in stage 14.0 (TID 24) in 2438 ms on localhost (executor driver) (14/16)
17/03/18 11:28:44 INFO Executor: Finished task 14.0 in stage 14.0 (TID 28). 4709 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 14.0 in stage 14.0 (TID 28) in 1988 ms on localhost (executor driver) (15/16)
17/03/18 11:28:44 INFO Executor: Finished task 13.0 in stage 14.0 (TID 27). 4622 bytes result sent to driver
17/03/18 11:28:44 INFO TaskSetManager: Finished task 13.0 in stage 14.0 (TID 27) in 2003 ms on localhost (executor driver) (16/16)
17/03/18 11:28:44 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/03/18 11:28:44 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:197) finished in 5,179 s
17/03/18 11:28:44 INFO DAGScheduler: Job 12 finished: collect at utils.scala:197, took 5,183560 s
17/03/18 11:28:44 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:28:44 INFO DAGScheduler: Registering RDD 63 (collect at utils.scala:197)
17/03/18 11:28:44 INFO DAGScheduler: Registering RDD 66 (collect at utils.scala:197)
17/03/18 11:28:44 INFO DAGScheduler: Registering RDD 71 (collect at utils.scala:197)
17/03/18 11:28:44 INFO DAGScheduler: Got job 13 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:28:44 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:197)
17/03/18 11:28:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
17/03/18 11:28:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 17)
17/03/18 11:28:44 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[63] at collect at utils.scala:197), which has no missing parents
17/03/18 11:28:44 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 13.9 KB, free 6.2 GB)
17/03/18 11:28:44 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.4 KB, free 6.2 GB)
17/03/18 11:28:44 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:49760 (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:28:44 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:44 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[63] at collect at utils.scala:197)
17/03/18 11:28:44 INFO TaskSchedulerImpl: Adding task set 15.0 with 16 tasks
17/03/18 11:28:44 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 30, localhost, executor driver, partition 0, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 31, localhost, executor driver, partition 1, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 32, localhost, executor driver, partition 2, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 33, localhost, executor driver, partition 3, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 34, localhost, executor driver, partition 4, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 35, localhost, executor driver, partition 5, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 36, localhost, executor driver, partition 6, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 37, localhost, executor driver, partition 7, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:44 INFO Executor: Running task 0.0 in stage 15.0 (TID 30)
17/03/18 11:28:44 INFO Executor: Running task 1.0 in stage 15.0 (TID 31)
17/03/18 11:28:44 INFO Executor: Running task 5.0 in stage 15.0 (TID 35)
17/03/18 11:28:44 INFO Executor: Running task 6.0 in stage 15.0 (TID 36)
17/03/18 11:28:44 INFO Executor: Running task 2.0 in stage 15.0 (TID 32)
17/03/18 11:28:44 INFO Executor: Running task 7.0 in stage 15.0 (TID 37)
17/03/18 11:28:44 INFO Executor: Running task 4.0 in stage 15.0 (TID 34)
17/03/18 11:28:44 INFO Executor: Running task 3.0 in stage 15.0 (TID 33)
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32649993, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32106576, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32501332, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32363934, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32740461, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32204489, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32949915, partition values: [empty row]
17/03/18 11:28:44 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32029174, partition values: [empty row]
17/03/18 11:28:45 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:49760 in memory (size: 4.9 KB, free: 6.2 GB)
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32151503, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32072404, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31999562, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32417617, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32897976, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32717377, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32565291, partition values: [empty row]
17/03/18 11:28:46 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32316443, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32049222, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32141823, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32386451, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31964726, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32288085, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32776335, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32682016, partition values: [empty row]
17/03/18 11:28:47 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32523558, partition values: [empty row]
17/03/18 11:28:48 INFO Executor: Finished task 5.0 in stage 15.0 (TID 35). 1979 bytes result sent to driver
17/03/18 11:28:48 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 38, localhost, executor driver, partition 8, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:48 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 35) in 3427 ms on localhost (executor driver) (1/16)
17/03/18 11:28:48 INFO Executor: Running task 8.0 in stage 15.0 (TID 38)
17/03/18 11:28:48 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31943445, partition values: [empty row]
17/03/18 11:28:49 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31904148, partition values: [empty row]
17/03/18 11:28:49 INFO Executor: Finished task 6.0 in stage 15.0 (TID 36). 1979 bytes result sent to driver
17/03/18 11:28:49 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 39, localhost, executor driver, partition 9, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:49 INFO Executor: Running task 9.0 in stage 15.0 (TID 39)
17/03/18 11:28:49 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 36) in 4516 ms on localhost (executor driver) (2/16)
17/03/18 11:28:49 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31811845, partition values: [empty row]
17/03/18 11:28:49 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31886681, partition values: [empty row]
17/03/18 11:28:49 INFO Executor: Finished task 3.0 in stage 15.0 (TID 33). 1979 bytes result sent to driver
17/03/18 11:28:49 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 40, localhost, executor driver, partition 10, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:49 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 33) in 4886 ms on localhost (executor driver) (3/16)
17/03/18 11:28:49 INFO Executor: Running task 10.0 in stage 15.0 (TID 40)
17/03/18 11:28:49 INFO Executor: Finished task 7.0 in stage 15.0 (TID 37). 1979 bytes result sent to driver
17/03/18 11:28:49 INFO TaskSetManager: Starting task 11.0 in stage 15.0 (TID 41, localhost, executor driver, partition 11, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:49 INFO Executor: Running task 11.0 in stage 15.0 (TID 41)
17/03/18 11:28:49 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 37) in 4888 ms on localhost (executor driver) (4/16)
17/03/18 11:28:49 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31749906, partition values: [empty row]
17/03/18 11:28:49 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31694773, partition values: [empty row]
17/03/18 11:28:49 INFO Executor: Finished task 4.0 in stage 15.0 (TID 34). 1979 bytes result sent to driver
17/03/18 11:28:49 INFO TaskSetManager: Starting task 12.0 in stage 15.0 (TID 42, localhost, executor driver, partition 12, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:49 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 34) in 4920 ms on localhost (executor driver) (5/16)
17/03/18 11:28:49 INFO Executor: Running task 12.0 in stage 15.0 (TID 42)
17/03/18 11:28:49 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31652386, partition values: [empty row]
17/03/18 11:28:50 INFO Executor: Finished task 2.0 in stage 15.0 (TID 32). 1979 bytes result sent to driver
17/03/18 11:28:50 INFO TaskSetManager: Starting task 13.0 in stage 15.0 (TID 43, localhost, executor driver, partition 13, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:50 INFO Executor: Running task 13.0 in stage 15.0 (TID 43)
17/03/18 11:28:50 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 32) in 5171 ms on localhost (executor driver) (6/16)
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31502478, partition values: [empty row]
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31776923, partition values: [empty row]
17/03/18 11:28:50 INFO Executor: Finished task 1.0 in stage 15.0 (TID 31). 1979 bytes result sent to driver
17/03/18 11:28:50 INFO TaskSetManager: Starting task 14.0 in stage 15.0 (TID 44, localhost, executor driver, partition 14, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:50 INFO Executor: Running task 14.0 in stage 15.0 (TID 44)
17/03/18 11:28:50 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 31) in 5188 ms on localhost (executor driver) (7/16)
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31219072, partition values: [empty row]
17/03/18 11:28:50 INFO Executor: Finished task 0.0 in stage 15.0 (TID 30). 1979 bytes result sent to driver
17/03/18 11:28:50 INFO TaskSetManager: Starting task 15.0 in stage 15.0 (TID 45, localhost, executor driver, partition 15, PROCESS_LOCAL, 6932 bytes)
17/03/18 11:28:50 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 30) in 5224 ms on localhost (executor driver) (8/16)
17/03/18 11:28:50 INFO Executor: Running task 15.0 in stage 15.0 (TID 45)
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30888717, partition values: [empty row]
17/03/18 11:28:50 INFO Executor: Finished task 8.0 in stage 15.0 (TID 38). 1979 bytes result sent to driver
17/03/18 11:28:50 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 38) in 2270 ms on localhost (executor driver) (9/16)
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31617619, partition values: [empty row]
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31740900, partition values: [empty row]
17/03/18 11:28:50 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31693702, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31188290, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30500702, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31503322, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31754546, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31466713, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31696456, partition values: [empty row]
17/03/18 11:28:51 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30943043, partition values: [empty row]
17/03/18 11:28:52 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-728067, partition values: [empty row]
17/03/18 11:28:52 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31685098, partition values: [empty row]
17/03/18 11:28:52 INFO Executor: Finished task 15.0 in stage 15.0 (TID 45). 2066 bytes result sent to driver
17/03/18 11:28:52 INFO TaskSetManager: Finished task 15.0 in stage 15.0 (TID 45) in 2263 ms on localhost (executor driver) (10/16)
17/03/18 11:28:52 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31337009, partition values: [empty row]
17/03/18 11:28:52 INFO Executor: Finished task 12.0 in stage 15.0 (TID 42). 1979 bytes result sent to driver
17/03/18 11:28:52 INFO TaskSetManager: Finished task 12.0 in stage 15.0 (TID 42) in 2967 ms on localhost (executor driver) (11/16)
17/03/18 11:28:53 INFO Executor: Finished task 9.0 in stage 15.0 (TID 39). 1979 bytes result sent to driver
17/03/18 11:28:53 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 39) in 3653 ms on localhost (executor driver) (12/16)
17/03/18 11:28:53 INFO Executor: Finished task 11.0 in stage 15.0 (TID 41). 1979 bytes result sent to driver
17/03/18 11:28:53 INFO TaskSetManager: Finished task 11.0 in stage 15.0 (TID 41) in 3492 ms on localhost (executor driver) (13/16)
17/03/18 11:28:53 INFO Executor: Finished task 14.0 in stage 15.0 (TID 44). 1979 bytes result sent to driver
17/03/18 11:28:53 INFO TaskSetManager: Finished task 14.0 in stage 15.0 (TID 44) in 3196 ms on localhost (executor driver) (14/16)
17/03/18 11:28:53 INFO Executor: Finished task 10.0 in stage 15.0 (TID 40). 1979 bytes result sent to driver
17/03/18 11:28:53 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 40) in 3503 ms on localhost (executor driver) (15/16)
17/03/18 11:28:53 INFO Executor: Finished task 13.0 in stage 15.0 (TID 43). 1979 bytes result sent to driver
17/03/18 11:28:53 INFO TaskSetManager: Finished task 13.0 in stage 15.0 (TID 43) in 3433 ms on localhost (executor driver) (16/16)
17/03/18 11:28:53 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/03/18 11:28:53 INFO DAGScheduler: ShuffleMapStage 15 (collect at utils.scala:197) finished in 8,605 s
17/03/18 11:28:53 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:28:53 INFO DAGScheduler: running: Set()
17/03/18 11:28:53 INFO DAGScheduler: waiting: Set(ShuffleMapStage 16, ShuffleMapStage 17, ResultStage 18)
17/03/18 11:28:53 INFO DAGScheduler: failed: Set()
17/03/18 11:28:53 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[66] at collect at utils.scala:197), which has no missing parents
17/03/18 11:28:53 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 14.8 KB, free 6.2 GB)
17/03/18 11:28:53 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.4 KB, free 6.2 GB)
17/03/18 11:28:53 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:49760 (size: 7.4 KB, free: 6.2 GB)
17/03/18 11:28:53 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/03/18 11:28:53 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[66] at collect at utils.scala:197)
17/03/18 11:28:53 INFO TaskSchedulerImpl: Adding task set 16.0 with 8 tasks
17/03/18 11:28:53 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 46, localhost, executor driver, partition 0, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 47, localhost, executor driver, partition 1, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 48, localhost, executor driver, partition 2, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 49, localhost, executor driver, partition 3, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 4.0 in stage 16.0 (TID 50, localhost, executor driver, partition 4, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 5.0 in stage 16.0 (TID 51, localhost, executor driver, partition 5, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 6.0 in stage 16.0 (TID 52, localhost, executor driver, partition 6, ANY, 5936 bytes)
17/03/18 11:28:53 INFO TaskSetManager: Starting task 7.0 in stage 16.0 (TID 53, localhost, executor driver, partition 7, ANY, 5936 bytes)
17/03/18 11:28:53 INFO Executor: Running task 2.0 in stage 16.0 (TID 48)
17/03/18 11:28:53 INFO Executor: Running task 3.0 in stage 16.0 (TID 49)
17/03/18 11:28:53 INFO Executor: Running task 4.0 in stage 16.0 (TID 50)
17/03/18 11:28:53 INFO Executor: Running task 5.0 in stage 16.0 (TID 51)
17/03/18 11:28:53 INFO Executor: Running task 0.0 in stage 16.0 (TID 46)
17/03/18 11:28:53 INFO Executor: Running task 6.0 in stage 16.0 (TID 52)
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/18 11:28:53 INFO Executor: Running task 7.0 in stage 16.0 (TID 53)
17/03/18 11:28:53 INFO Executor: Running task 1.0 in stage 16.0 (TID 47)
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 16 blocks
17/03/18 11:28:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:28:53 INFO CodeGenerator: Code generated in 21.027845 ms
17/03/18 11:28:53 INFO CodeGenerator: Code generated in 23.494437 ms
17/03/18 11:29:47 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:29:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:29:47 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 11:29:47 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:29:47 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:29:47 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:29:47 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:29:47 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:29:47 INFO Utils: Successfully started service 'sparkDriver' on port 58843.
17/03/18 11:29:47 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:29:47 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:29:47 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:29:47 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:29:47 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-f265dcc3-b360-4708-9375-2e2363174a4c
17/03/18 11:29:47 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 11:29:47 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:29:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/03/18 11:29:47 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/03/18 11:29:47 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/03/18 11:29:47 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:58843/jars/sparklyr-2.1-2.11.jar with timestamp 1489832987956
17/03/18 11:29:48 INFO Executor: Starting executor ID driver on host localhost
17/03/18 11:29:48 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40837.
17/03/18 11:29:48 INFO NettyBlockTransferService: Server created on 127.0.0.1:40837
17/03/18 11:29:48 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 11:29:48 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 40837, None)
17/03/18 11:29:48 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:40837 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 40837, None)
17/03/18 11:29:48 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 40837, None)
17/03/18 11:29:48 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 40837, None)
17/03/18 11:29:48 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 11:29:48 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 11:29:48 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 11:29:48 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 11:29:48 INFO ObjectStore: ObjectStore, initialize called
17/03/18 11:29:49 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 11:29:49 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 11:29:49 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 11:29:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:29:50 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:29:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:29:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:29:51 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 11:29:51 INFO ObjectStore: Initialized ObjectStore
17/03/18 11:29:51 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 11:29:51 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 11:29:51 INFO HiveMetaStore: Added admin role in metastore
17/03/18 11:29:51 INFO HiveMetaStore: Added public role in metastore
17/03/18 11:29:51 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 11:29:51 INFO HiveMetaStore: 0: get_all_databases
17/03/18 11:29:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 11:29:51 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 11:29:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 11:29:51 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:29:51 INFO SessionState: Created local directory: /tmp/643d1646-49ea-4b44-84ff-dc4c2b66fb64_resources
17/03/18 11:29:51 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/643d1646-49ea-4b44-84ff-dc4c2b66fb64
17/03/18 11:29:51 INFO SessionState: Created local directory: /tmp/yannick/643d1646-49ea-4b44-84ff-dc4c2b66fb64
17/03/18 11:29:51 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/643d1646-49ea-4b44-84ff-dc4c2b66fb64/_tmp_space.db
17/03/18 11:29:51 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 11:29:51 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:29:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:29:51 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 11:29:51 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 11:29:51 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 11:29:54 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 11:29:54 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/03/18 11:29:54 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 11:29:54 INFO MemoryStore: MemoryStore cleared
17/03/18 11:29:54 INFO BlockManager: BlockManager stopped
17/03/18 11:29:54 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 11:29:54 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 11:29:54 INFO SparkContext: Successfully stopped SparkContext
17/03/18 11:29:54 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:29:54 INFO ShutdownHookManager: Deleting directory /home/yannick/tmp/sparklyr/spark-43b76f9f-349d-4e9e-aef6-39dddd74f982
17/03/18 11:30:07 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:30:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:30:07 WARN SparkConf: In Spark 1.0 and later spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone and LOCAL_DIRS in YARN).
17/03/18 11:30:07 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:30:07 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:30:07 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:30:07 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:30:07 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:30:07 INFO Utils: Successfully started service 'sparkDriver' on port 36401.
17/03/18 11:30:07 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:30:07 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:30:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:30:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:30:07 INFO DiskBlockManager: Created local directory at /home/yannick/tmp/sparklyr/blockmgr-17638f0c-983d-47f6-aba9-28b809e21455
17/03/18 11:30:07 INFO MemoryStore: MemoryStore started with capacity 6.2 GB
17/03/18 11:30:07 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:30:08 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/03/18 11:30:08 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/03/18 11:30:08 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/03/18 11:30:08 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:36401/jars/sparklyr-2.1-2.11.jar with timestamp 1489833008143
17/03/18 11:30:08 INFO Executor: Starting executor ID driver on host localhost
17/03/18 11:30:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58023.
17/03/18 11:30:08 INFO NettyBlockTransferService: Server created on 127.0.0.1:58023
17/03/18 11:30:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 11:30:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 58023, None)
17/03/18 11:30:08 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:58023 with 6.2 GB RAM, BlockManagerId(driver, 127.0.0.1, 58023, None)
17/03/18 11:30:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 58023, None)
17/03/18 11:30:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 58023, None)
17/03/18 11:30:08 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 11:30:08 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 11:30:08 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 11:30:09 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 11:30:09 INFO ObjectStore: ObjectStore, initialize called
17/03/18 11:30:09 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 11:30:09 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 11:30:10 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 11:30:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:30:10 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:30:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:30:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:30:11 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 11:30:11 INFO ObjectStore: Initialized ObjectStore
17/03/18 11:30:11 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 11:30:11 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 11:30:11 INFO HiveMetaStore: Added admin role in metastore
17/03/18 11:30:11 INFO HiveMetaStore: Added public role in metastore
17/03/18 11:30:11 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 11:30:11 INFO HiveMetaStore: 0: get_all_databases
17/03/18 11:30:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 11:30:11 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 11:30:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 11:30:11 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:30:11 INFO SessionState: Created local directory: /tmp/534b1052-e113-4880-969f-f2de98d9df79_resources
17/03/18 11:30:11 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/534b1052-e113-4880-969f-f2de98d9df79
17/03/18 11:30:11 INFO SessionState: Created local directory: /tmp/yannick/534b1052-e113-4880-969f-f2de98d9df79
17/03/18 11:30:11 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/534b1052-e113-4880-969f-f2de98d9df79/_tmp_space.db
17/03/18 11:30:11 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 11:30:11 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:11 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 11:30:11 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 11:30:11 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 11:30:26 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 11:30:26 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/03/18 11:30:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 11:30:26 INFO MemoryStore: MemoryStore cleared
17/03/18 11:30:26 INFO BlockManager: BlockManager stopped
17/03/18 11:30:26 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 11:30:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 11:30:26 INFO SparkContext: Successfully stopped SparkContext
17/03/18 11:30:26 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:30:26 INFO ShutdownHookManager: Deleting directory /home/yannick/tmp/sparklyr/spark-18ee6ccc-398d-415f-b542-ecdea0925428
17/03/18 11:30:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:30:36 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:36 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:36 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:30:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:30:37 INFO CodeGenerator: Code generated in 212.43293 ms
17/03/18 11:30:37 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:30:37 INFO DAGScheduler: Got job 0 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:30:37 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:59)
17/03/18 11:30:37 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:30:37 INFO DAGScheduler: Missing parents: List()
17/03/18 11:30:37 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56), which has no missing parents
17/03/18 11:30:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:30:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:30:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:58023 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:30:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/03/18 11:30:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:56)
17/03/18 11:30:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/03/18 11:30:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/03/18 11:30:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/18 11:30:37 INFO Executor: Fetching spark://127.0.0.1:36401/jars/sparklyr-2.1-2.11.jar with timestamp 1489833008143
17/03/18 11:30:37 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:36401 after 9 ms (0 ms spent in bootstraps)
17/03/18 11:30:37 INFO Utils: Fetching spark://127.0.0.1:36401/jars/sparklyr-2.1-2.11.jar to /home/yannick/tmp/sparklyr/spark-94fc4a98-20fe-409d-af88-f19f79430f0e/userFiles-2dcf7d06-2a97-4f2d-b69c-2fe6021dd98f/fetchFileTemp3861458596441862680.tmp
17/03/18 11:30:37 INFO Executor: Adding file:/home/yannick/tmp/sparklyr/spark-94fc4a98-20fe-409d-af88-f19f79430f0e/userFiles-2dcf7d06-2a97-4f2d-b69c-2fe6021dd98f/sparklyr-2.1-2.11.jar to class loader
17/03/18 11:30:37 INFO CodeGenerator: Code generated in 11.339144 ms
17/03/18 11:30:37 INFO CodeGenerator: Code generated in 13.087354 ms
17/03/18 11:30:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/03/18 11:30:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 192 ms on localhost (executor driver) (1/1)
17/03/18 11:30:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/18 11:30:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:59) finished in 0,206 s
17/03/18 11:30:37 INFO DAGScheduler: Job 0 finished: collect at utils.scala:59, took 0,318782 s
17/03/18 11:30:37 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:30:37 INFO DAGScheduler: Got job 1 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:30:37 INFO DAGScheduler: Final stage: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:30:37 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:30:37 INFO DAGScheduler: Missing parents: List()
17/03/18 11:30:37 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:30:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:30:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 6.2 GB)
17/03/18 11:30:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:58023 (size: 25.4 KB, free: 6.2 GB)
17/03/18 11:30:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:996
17/03/18 11:30:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:30:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/18 11:30:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6217 bytes)
17/03/18 11:30:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/03/18 11:30:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2690 bytes result sent to driver
17/03/18 11:30:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 137 ms on localhost (executor driver) (1/1)
17/03/18 11:30:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/18 11:30:37 INFO DAGScheduler: ResultStage 1 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,137 s
17/03/18 11:30:37 INFO DAGScheduler: Job 1 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,169673 s
17/03/18 11:30:37 INFO SparkSqlParser: Parsing command: train
17/03/18 11:30:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train` AS `zzz1`
WHERE (0 = 1)
17/03/18 11:30:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:30:38 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:38 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:38 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:38 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:30:38 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:30:38 INFO CodeGenerator: Code generated in 12.034537 ms
17/03/18 11:30:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:30:39 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:39 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:30:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:30:39 INFO SparkContext: Starting job: collect at utils.scala:59
17/03/18 11:30:39 INFO DAGScheduler: Got job 2 (collect at utils.scala:59) with 1 output partitions
17/03/18 11:30:39 INFO DAGScheduler: Final stage: ResultStage 2 (collect at utils.scala:59)
17/03/18 11:30:39 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:30:39 INFO DAGScheduler: Missing parents: List()
17/03/18 11:30:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at map at utils.scala:56), which has no missing parents
17/03/18 11:30:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.7 KB, free 6.2 GB)
17/03/18 11:30:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.6 KB, free 6.2 GB)
17/03/18 11:30:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:58023 (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:30:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/03/18 11:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at map at utils.scala:56)
17/03/18 11:30:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/18 11:30:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 6354 bytes)
17/03/18 11:30:39 INFO ContextCleaner: Cleaned accumulator 0
17/03/18 11:30:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
17/03/18 11:30:39 INFO ContextCleaner: Cleaned accumulator 1
17/03/18 11:30:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:58023 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:30:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 1239 bytes result sent to driver
17/03/18 11:30:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 11 ms on localhost (executor driver) (1/1)
17/03/18 11:30:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/18 11:30:39 INFO DAGScheduler: ResultStage 2 (collect at utils.scala:59) finished in 0,011 s
17/03/18 11:30:39 INFO DAGScheduler: Job 2 finished: collect at utils.scala:59, took 0,041607 s
17/03/18 11:30:39 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 127.0.0.1:58023 in memory (size: 25.4 KB, free: 6.2 GB)
17/03/18 11:30:39 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
17/03/18 11:30:39 INFO DAGScheduler: Got job 3 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/03/18 11:30:39 INFO DAGScheduler: Final stage: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:30:39 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:30:39 INFO DAGScheduler: Missing parents: List()
17/03/18 11:30:39 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
17/03/18 11:30:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 70.9 KB, free 6.2 GB)
17/03/18 11:30:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.4 KB, free 6.2 GB)
17/03/18 11:30:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:58023 (size: 25.4 KB, free: 6.2 GB)
17/03/18 11:30:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/03/18 11:30:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at parquet at NativeMethodAccessorImpl.java:0)
17/03/18 11:30:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/18 11:30:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, localhost, executor driver, partition 0, PROCESS_LOCAL, 6220 bytes)
17/03/18 11:30:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
17/03/18 11:30:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2603 bytes result sent to driver
17/03/18 11:30:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 24 ms on localhost (executor driver) (1/1)
17/03/18 11:30:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/18 11:30:39 INFO DAGScheduler: ResultStage 3 (parquet at NativeMethodAccessorImpl.java:0) finished in 0,025 s
17/03/18 11:30:39 INFO DAGScheduler: Job 3 finished: parquet at NativeMethodAccessorImpl.java:0, took 0,061705 s
17/03/18 11:30:39 INFO SparkSqlParser: Parsing command: train10k
17/03/18 11:30:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `train10k` AS `zzz2`
WHERE (0 = 1)
17/03/18 11:30:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/03/18 11:30:39 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:39 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:30:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:30:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/03/18 11:30:39 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/03/18 11:30:57 INFO SparkSqlParser: Parsing command: SELECT count(*) AS `n`
FROM (SELECT *
FROM (SELECT `device_id`, `device_ip`, `int_day`, `int_hour`, `int_hour` - LAG(`int_hour`, 1, NULL) OVER (PARTITION BY `device_id`, `device_ip`, `int_day` ORDER BY "int_hour") AS `dt_hour`
FROM (SELECT `device_id` AS `device_id`, `device_ip` AS `device_ip`, `int_day` AS `int_day`, `int_hour` AS `int_hour`
FROM (SELECT *
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, `int_day`, SUBSTR(`hour`, 7.0, 2.0) AS `int_hour`
FROM (SELECT `id`, `click`, `hour`, `C1`, `banner_pos`, `site_id`, `site_domain`, `site_category`, `app_id`, `app_domain`, `app_category`, `device_id`, `device_ip`, `device_model`, `device_type`, `device_conn_type`, `C14`, `C15`, `C16`, `C17`, `C18`, `C19`, `C20`, `C21`, SUBSTR(`hour`, 5.0, 2.0) AS `int_day`
FROM `train`) `gkcninltgq`) `zpicqcpdkw`
ORDER BY `int_hour`) `koeknkjhll`) `wgcetjolnl`) `heulnaftnw`
WHERE ((`dt_hour`) IS NULL)) `tokhfsmojx`
17/03/18 11:30:58 INFO FileSourceStrategy: Pruning directories with: 
17/03/18 11:30:58 INFO FileSourceStrategy: Post-Scan Filters: 
17/03/18 11:30:58 INFO FileSourceStrategy: Output Data Schema: struct<hour: string, device_id: string, device_ip: string ... 1 more fields>
17/03/18 11:30:58 INFO FileSourceStrategy: Pushed Filters: 
17/03/18 11:30:58 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/03/18 11:30:58 INFO CodeGenerator: Code generated in 15.897468 ms
17/03/18 11:30:58 INFO CodeGenerator: Code generated in 19.060436 ms
17/03/18 11:30:58 INFO CodeGenerator: Code generated in 15.598497 ms
17/03/18 11:30:58 INFO CodeGenerator: Code generated in 23.597482 ms
17/03/18 11:30:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 297.7 KB, free 6.2 GB)
17/03/18 11:30:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 24.3 KB, free 6.2 GB)
17/03/18 11:30:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:58023 (size: 24.3 KB, free: 6.2 GB)
17/03/18 11:30:58 INFO SparkContext: Created broadcast 4 from collect at utils.scala:197
17/03/18 11:30:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 134217728 bytes, open cost is considered as scanning 4194304 bytes.
17/03/18 11:30:58 INFO CodeGenerator: Code generated in 18.120834 ms
17/03/18 11:30:58 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:30:58 INFO DAGScheduler: Got job 4 (collect at utils.scala:197) with 16 output partitions
17/03/18 11:30:58 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:197)
17/03/18 11:30:58 INFO DAGScheduler: Parents of final stage: List()
17/03/18 11:30:58 INFO DAGScheduler: Missing parents: List()
17/03/18 11:30:58 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:197), which has no missing parents
17/03/18 11:30:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 10.7 KB, free 6.2 GB)
17/03/18 11:30:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.9 KB, free 6.2 GB)
17/03/18 11:30:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:58023 (size: 4.9 KB, free: 6.2 GB)
17/03/18 11:30:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/03/18 11:30:58 INFO DAGScheduler: Submitting 16 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:197)
17/03/18 11:30:58 INFO TaskSchedulerImpl: Adding task set 4.0 with 16 tasks
17/03/18 11:30:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, localhost, executor driver, partition 0, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 5, localhost, executor driver, partition 1, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 6, localhost, executor driver, partition 2, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 7, localhost, executor driver, partition 3, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 8, localhost, executor driver, partition 4, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 9, localhost, executor driver, partition 5, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 10, localhost, executor driver, partition 6, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 11, localhost, executor driver, partition 7, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:30:58 INFO Executor: Running task 0.0 in stage 4.0 (TID 4)
17/03/18 11:30:58 INFO Executor: Running task 1.0 in stage 4.0 (TID 5)
17/03/18 11:30:58 INFO Executor: Running task 2.0 in stage 4.0 (TID 6)
17/03/18 11:30:58 INFO Executor: Running task 3.0 in stage 4.0 (TID 7)
17/03/18 11:30:58 INFO Executor: Running task 4.0 in stage 4.0 (TID 8)
17/03/18 11:30:58 INFO Executor: Running task 5.0 in stage 4.0 (TID 9)
17/03/18 11:30:58 INFO Executor: Running task 6.0 in stage 4.0 (TID 10)
17/03/18 11:30:58 INFO Executor: Running task 7.0 in stage 4.0 (TID 11)
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32204489, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32363934, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32949915, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32029174, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32649993, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32501332, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32740461, partition values: [empty row]
17/03/18 11:30:58 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32106576, partition values: [empty row]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:58 INFO CodecPool: Got brand-new decompressor [.snappy]
17/03/18 11:30:59 INFO ContextCleaner: Cleaned accumulator 100
17/03/18 11:30:59 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:58023 in memory (size: 4.6 KB, free: 6.2 GB)
17/03/18 11:30:59 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:58023 in memory (size: 25.4 KB, free: 6.2 GB)
17/03/18 11:30:59 INFO ContextCleaner: Cleaned accumulator 198
17/03/18 11:30:59 INFO ContextCleaner: Cleaned accumulator 199
17/03/18 11:30:59 INFO ContextCleaner: Cleaned accumulator 200
17/03/18 11:30:59 INFO ContextCleaner: Cleaned accumulator 99
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32072404, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32565291, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32316443, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32717377, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31999562, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32897976, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32151503, partition values: [empty row]
17/03/18 11:31:00 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32417617, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32682016, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32288085, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32523558, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31964726, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32049222, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32141823, partition values: [empty row]
17/03/18 11:31:01 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32386451, partition values: [empty row]
17/03/18 11:31:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32776335, partition values: [empty row]
17/03/18 11:31:02 INFO Executor: Finished task 2.0 in stage 4.0 (TID 6). 4709 bytes result sent to driver
17/03/18 11:31:02 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 12, localhost, executor driver, partition 8, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:02 INFO Executor: Running task 8.0 in stage 4.0 (TID 12)
17/03/18 11:31:02 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 6) in 3662 ms on localhost (executor driver) (1/16)
17/03/18 11:31:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31943445, partition values: [empty row]
17/03/18 11:31:02 INFO Executor: Finished task 7.0 in stage 4.0 (TID 11). 4622 bytes result sent to driver
17/03/18 11:31:02 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 13, localhost, executor driver, partition 9, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:02 INFO Executor: Running task 9.0 in stage 4.0 (TID 13)
17/03/18 11:31:02 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 11) in 3922 ms on localhost (executor driver) (2/16)
17/03/18 11:31:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31811845, partition values: [empty row]
17/03/18 11:31:02 INFO Executor: Finished task 1.0 in stage 4.0 (TID 5). 4622 bytes result sent to driver
17/03/18 11:31:02 INFO TaskSetManager: Starting task 10.0 in stage 4.0 (TID 14, localhost, executor driver, partition 10, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:02 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 5) in 4002 ms on localhost (executor driver) (3/16)
17/03/18 11:31:02 INFO Executor: Running task 10.0 in stage 4.0 (TID 14)
17/03/18 11:31:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31749906, partition values: [empty row]
17/03/18 11:31:02 INFO Executor: Finished task 6.0 in stage 4.0 (TID 10). 4709 bytes result sent to driver
17/03/18 11:31:02 INFO TaskSetManager: Starting task 11.0 in stage 4.0 (TID 15, localhost, executor driver, partition 11, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:02 INFO Executor: Running task 11.0 in stage 4.0 (TID 15)
17/03/18 11:31:02 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 10) in 4403 ms on localhost (executor driver) (4/16)
17/03/18 11:31:02 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31694773, partition values: [empty row]
17/03/18 11:31:03 INFO Executor: Finished task 4.0 in stage 4.0 (TID 8). 4622 bytes result sent to driver
17/03/18 11:31:03 INFO TaskSetManager: Starting task 12.0 in stage 4.0 (TID 16, localhost, executor driver, partition 12, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:03 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 8) in 4516 ms on localhost (executor driver) (5/16)
17/03/18 11:31:03 INFO Executor: Running task 12.0 in stage 4.0 (TID 16)
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31652386, partition values: [empty row]
17/03/18 11:31:03 INFO Executor: Finished task 3.0 in stage 4.0 (TID 7). 4709 bytes result sent to driver
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31904148, partition values: [empty row]
17/03/18 11:31:03 INFO TaskSetManager: Starting task 13.0 in stage 4.0 (TID 17, localhost, executor driver, partition 13, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:03 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 7) in 4586 ms on localhost (executor driver) (6/16)
17/03/18 11:31:03 INFO Executor: Running task 13.0 in stage 4.0 (TID 17)
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31502478, partition values: [empty row]
17/03/18 11:31:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 4). 4622 bytes result sent to driver
17/03/18 11:31:03 INFO TaskSetManager: Starting task 14.0 in stage 4.0 (TID 18, localhost, executor driver, partition 14, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:03 INFO Executor: Running task 14.0 in stage 4.0 (TID 18)
17/03/18 11:31:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 4629 ms on localhost (executor driver) (7/16)
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31219072, partition values: [empty row]
17/03/18 11:31:03 INFO Executor: Finished task 5.0 in stage 4.0 (TID 9). 4622 bytes result sent to driver
17/03/18 11:31:03 INFO TaskSetManager: Starting task 15.0 in stage 4.0 (TID 19, localhost, executor driver, partition 15, PROCESS_LOCAL, 6942 bytes)
17/03/18 11:31:03 INFO Executor: Running task 15.0 in stage 4.0 (TID 19)
17/03/18 11:31:03 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 9) in 4711 ms on localhost (executor driver) (8/16)
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30888717, partition values: [empty row]
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31776923, partition values: [empty row]
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31740900, partition values: [empty row]
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31693702, partition values: [empty row]
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31466713, partition values: [empty row]
17/03/18 11:31:03 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31886681, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31188290, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31617619, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31754546, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30500702, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31685098, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31337009, partition values: [empty row]
17/03/18 11:31:04 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31696456, partition values: [empty row]
17/03/18 11:31:04 INFO Executor: Finished task 8.0 in stage 4.0 (TID 12). 4622 bytes result sent to driver
17/03/18 11:31:04 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 12) in 2826 ms on localhost (executor driver) (9/16)
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-728067, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30943043, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31503322, partition values: [empty row]
17/03/18 11:31:05 INFO Executor: Finished task 9.0 in stage 4.0 (TID 13). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 13) in 3044 ms on localhost (executor driver) (10/16)
17/03/18 11:31:05 INFO Executor: Finished task 15.0 in stage 4.0 (TID 19). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 15.0 in stage 4.0 (TID 19) in 2393 ms on localhost (executor driver) (11/16)
17/03/18 11:31:05 INFO Executor: Finished task 11.0 in stage 4.0 (TID 15). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 11.0 in stage 4.0 (TID 15) in 2706 ms on localhost (executor driver) (12/16)
17/03/18 11:31:05 INFO Executor: Finished task 13.0 in stage 4.0 (TID 17). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 13.0 in stage 4.0 (TID 17) in 2619 ms on localhost (executor driver) (13/16)
17/03/18 11:31:05 INFO Executor: Finished task 10.0 in stage 4.0 (TID 14). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 10.0 in stage 4.0 (TID 14) in 3223 ms on localhost (executor driver) (14/16)
17/03/18 11:31:05 INFO Executor: Finished task 14.0 in stage 4.0 (TID 18). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 14.0 in stage 4.0 (TID 18) in 2676 ms on localhost (executor driver) (15/16)
17/03/18 11:31:05 INFO Executor: Finished task 12.0 in stage 4.0 (TID 16). 4622 bytes result sent to driver
17/03/18 11:31:05 INFO TaskSetManager: Finished task 12.0 in stage 4.0 (TID 16) in 2793 ms on localhost (executor driver) (16/16)
17/03/18 11:31:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/18 11:31:05 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:197) finished in 7,313 s
17/03/18 11:31:05 INFO DAGScheduler: Job 4 finished: collect at utils.scala:197, took 7,322977 s
17/03/18 11:31:05 INFO SparkContext: Starting job: collect at utils.scala:197
17/03/18 11:31:05 INFO DAGScheduler: Registering RDD 25 (collect at utils.scala:197)
17/03/18 11:31:05 INFO DAGScheduler: Registering RDD 28 (collect at utils.scala:197)
17/03/18 11:31:05 INFO DAGScheduler: Registering RDD 33 (collect at utils.scala:197)
17/03/18 11:31:05 INFO DAGScheduler: Got job 5 (collect at utils.scala:197) with 1 output partitions
17/03/18 11:31:05 INFO DAGScheduler: Final stage: ResultStage 8 (collect at utils.scala:197)
17/03/18 11:31:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
17/03/18 11:31:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 7)
17/03/18 11:31:05 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[25] at collect at utils.scala:197), which has no missing parents
17/03/18 11:31:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 13.9 KB, free 6.2 GB)
17/03/18 11:31:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KB, free 6.2 GB)
17/03/18 11:31:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:58023 (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:31:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/03/18 11:31:05 INFO DAGScheduler: Submitting 16 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[25] at collect at utils.scala:197)
17/03/18 11:31:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 16 tasks
17/03/18 11:31:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 20, localhost, executor driver, partition 0, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 21, localhost, executor driver, partition 1, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 22, localhost, executor driver, partition 2, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 23, localhost, executor driver, partition 3, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 24, localhost, executor driver, partition 4, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 25, localhost, executor driver, partition 5, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 26, localhost, executor driver, partition 6, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 27, localhost, executor driver, partition 7, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:05 INFO Executor: Running task 1.0 in stage 5.0 (TID 21)
17/03/18 11:31:05 INFO Executor: Running task 0.0 in stage 5.0 (TID 20)
17/03/18 11:31:05 INFO Executor: Running task 2.0 in stage 5.0 (TID 22)
17/03/18 11:31:05 INFO Executor: Running task 4.0 in stage 5.0 (TID 24)
17/03/18 11:31:05 INFO Executor: Running task 3.0 in stage 5.0 (TID 23)
17/03/18 11:31:05 INFO Executor: Running task 6.0 in stage 5.0 (TID 26)
17/03/18 11:31:05 INFO Executor: Running task 7.0 in stage 5.0 (TID 27)
17/03/18 11:31:05 INFO Executor: Running task 5.0 in stage 5.0 (TID 25)
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00009-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32363934, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00001-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32204489, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00040-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32501332, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00029-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32740461, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00025-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32029174, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00010-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32649993, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00012-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32106576, partition values: [empty row]
17/03/18 11:31:05 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00041-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32949915, partition values: [empty row]
17/03/18 11:31:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00024-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32072404, partition values: [empty row]
17/03/18 11:31:06 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00027-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32151503, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00005-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32417617, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00044-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32316443, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00030-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32717377, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00021-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31999562, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00031-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32565291, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00004-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32897976, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00011-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32049222, partition values: [empty row]
17/03/18 11:31:07 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00013-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32386451, partition values: [empty row]
17/03/18 11:31:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:58023 in memory (size: 4.9 KB, free: 6.2 GB)
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00039-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32141823, partition values: [empty row]
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00019-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32288085, partition values: [empty row]
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00026-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31964726, partition values: [empty row]
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00002-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32682016, partition values: [empty row]
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00028-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32523558, partition values: [empty row]
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00003-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-32776335, partition values: [empty row]
17/03/18 11:31:08 INFO Executor: Finished task 6.0 in stage 5.0 (TID 26). 2066 bytes result sent to driver
17/03/18 11:31:08 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 28, localhost, executor driver, partition 8, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:08 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 26) in 2815 ms on localhost (executor driver) (1/16)
17/03/18 11:31:08 INFO Executor: Running task 8.0 in stage 5.0 (TID 28)
17/03/18 11:31:08 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00020-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31943445, partition values: [empty row]
17/03/18 11:31:09 INFO Executor: Finished task 3.0 in stage 5.0 (TID 23). 1979 bytes result sent to driver
17/03/18 11:31:09 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 29, localhost, executor driver, partition 9, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:09 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 23) in 3133 ms on localhost (executor driver) (2/16)
17/03/18 11:31:09 INFO Executor: Running task 9.0 in stage 5.0 (TID 29)
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00023-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31811845, partition values: [empty row]
17/03/18 11:31:09 INFO Executor: Finished task 5.0 in stage 5.0 (TID 25). 1979 bytes result sent to driver
17/03/18 11:31:09 INFO TaskSetManager: Starting task 10.0 in stage 5.0 (TID 30, localhost, executor driver, partition 10, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:09 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 25) in 3341 ms on localhost (executor driver) (3/16)
17/03/18 11:31:09 INFO Executor: Running task 10.0 in stage 5.0 (TID 30)
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00017-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31749906, partition values: [empty row]
17/03/18 11:31:09 INFO Executor: Finished task 4.0 in stage 5.0 (TID 24). 1979 bytes result sent to driver
17/03/18 11:31:09 INFO TaskSetManager: Starting task 11.0 in stage 5.0 (TID 31, localhost, executor driver, partition 11, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:09 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 24) in 3469 ms on localhost (executor driver) (4/16)
17/03/18 11:31:09 INFO Executor: Running task 11.0 in stage 5.0 (TID 31)
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00043-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31694773, partition values: [empty row]
17/03/18 11:31:09 INFO Executor: Finished task 1.0 in stage 5.0 (TID 21). 1979 bytes result sent to driver
17/03/18 11:31:09 INFO TaskSetManager: Starting task 12.0 in stage 5.0 (TID 32, localhost, executor driver, partition 12, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:09 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 21) in 3630 ms on localhost (executor driver) (5/16)
17/03/18 11:31:09 INFO Executor: Running task 12.0 in stage 5.0 (TID 32)
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00000-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31652386, partition values: [empty row]
17/03/18 11:31:09 INFO Executor: Finished task 2.0 in stage 5.0 (TID 22). 1979 bytes result sent to driver
17/03/18 11:31:09 INFO TaskSetManager: Starting task 13.0 in stage 5.0 (TID 33, localhost, executor driver, partition 13, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:09 INFO Executor: Running task 13.0 in stage 5.0 (TID 33)
17/03/18 11:31:09 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 22) in 3758 ms on localhost (executor driver) (6/16)
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00046-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31502478, partition values: [empty row]
17/03/18 11:31:09 INFO Executor: Finished task 7.0 in stage 5.0 (TID 27). 1979 bytes result sent to driver
17/03/18 11:31:09 INFO TaskSetManager: Starting task 14.0 in stage 5.0 (TID 34, localhost, executor driver, partition 14, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:09 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 27) in 4004 ms on localhost (executor driver) (7/16)
17/03/18 11:31:09 INFO Executor: Running task 14.0 in stage 5.0 (TID 34)
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00016-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31219072, partition values: [empty row]
17/03/18 11:31:09 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00036-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31776923, partition values: [empty row]
17/03/18 11:31:10 INFO Executor: Finished task 0.0 in stage 5.0 (TID 20). 1979 bytes result sent to driver
17/03/18 11:31:10 INFO TaskSetManager: Starting task 15.0 in stage 5.0 (TID 35, localhost, executor driver, partition 15, PROCESS_LOCAL, 6930 bytes)
17/03/18 11:31:10 INFO Executor: Running task 15.0 in stage 5.0 (TID 35)
17/03/18 11:31:10 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 20) in 4135 ms on localhost (executor driver) (8/16)
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00008-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30888717, partition values: [empty row]
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00015-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31904148, partition values: [empty row]
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00032-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31617619, partition values: [empty row]
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00014-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31693702, partition values: [empty row]
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00006-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31740900, partition values: [empty row]
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00022-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31466713, partition values: [empty row]
17/03/18 11:31:10 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00018-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31188290, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00035-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31886681, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00045-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31754546, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00033-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31503322, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00037-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31696456, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00007-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30500702, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00038-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31685098, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00034-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-31337009, partition values: [empty row]
17/03/18 11:31:11 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00042-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-30943043, partition values: [empty row]
17/03/18 11:31:12 INFO FileScanRDD: Reading File path: file:///home4/yannick4/tmp/train.parquet/part-00047-48177821-f9a6-42a8-be97-9b4fd7d36be9.snappy.parquet, range: 0-728067, partition values: [empty row]
17/03/18 11:31:12 INFO Executor: Finished task 15.0 in stage 5.0 (TID 35). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 15.0 in stage 5.0 (TID 35) in 2100 ms on localhost (executor driver) (9/16)
17/03/18 11:31:12 INFO Executor: Finished task 9.0 in stage 5.0 (TID 29). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 29) in 3163 ms on localhost (executor driver) (10/16)
17/03/18 11:31:12 INFO Executor: Finished task 12.0 in stage 5.0 (TID 32). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 12.0 in stage 5.0 (TID 32) in 2764 ms on localhost (executor driver) (11/16)
17/03/18 11:31:12 INFO Executor: Finished task 8.0 in stage 5.0 (TID 28). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 28) in 3603 ms on localhost (executor driver) (12/16)
17/03/18 11:31:12 INFO Executor: Finished task 10.0 in stage 5.0 (TID 30). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 10.0 in stage 5.0 (TID 30) in 3107 ms on localhost (executor driver) (13/16)
17/03/18 11:31:12 INFO Executor: Finished task 11.0 in stage 5.0 (TID 31). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 11.0 in stage 5.0 (TID 31) in 3038 ms on localhost (executor driver) (14/16)
17/03/18 11:31:12 INFO Executor: Finished task 14.0 in stage 5.0 (TID 34). 2066 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 14.0 in stage 5.0 (TID 34) in 2559 ms on localhost (executor driver) (15/16)
17/03/18 11:31:12 INFO Executor: Finished task 13.0 in stage 5.0 (TID 33). 1979 bytes result sent to driver
17/03/18 11:31:12 INFO TaskSetManager: Finished task 13.0 in stage 5.0 (TID 33) in 2891 ms on localhost (executor driver) (16/16)
17/03/18 11:31:12 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/18 11:31:12 INFO DAGScheduler: ShuffleMapStage 5 (collect at utils.scala:197) finished in 6,650 s
17/03/18 11:31:12 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:31:12 INFO DAGScheduler: running: Set()
17/03/18 11:31:12 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
17/03/18 11:31:12 INFO DAGScheduler: failed: Set()
17/03/18 11:31:12 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[28] at collect at utils.scala:197), which has no missing parents
17/03/18 11:31:12 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.8 KB, free 6.2 GB)
17/03/18 11:31:12 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.4 KB, free 6.2 GB)
17/03/18 11:31:12 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:58023 (size: 7.4 KB, free: 6.2 GB)
17/03/18 11:31:12 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:996
17/03/18 11:31:12 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[28] at collect at utils.scala:197)
17/03/18 11:31:12 INFO TaskSchedulerImpl: Adding task set 6.0 with 8 tasks
17/03/18 11:31:12 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 36, localhost, executor driver, partition 0, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 37, localhost, executor driver, partition 1, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 38, localhost, executor driver, partition 2, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 39, localhost, executor driver, partition 3, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 40, localhost, executor driver, partition 4, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 5.0 in stage 6.0 (TID 41, localhost, executor driver, partition 5, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 6.0 in stage 6.0 (TID 42, localhost, executor driver, partition 6, ANY, 5934 bytes)
17/03/18 11:31:12 INFO TaskSetManager: Starting task 7.0 in stage 6.0 (TID 43, localhost, executor driver, partition 7, ANY, 5934 bytes)
17/03/18 11:31:12 INFO Executor: Running task 1.0 in stage 6.0 (TID 37)
17/03/18 11:31:12 INFO Executor: Running task 0.0 in stage 6.0 (TID 36)
17/03/18 11:31:12 INFO Executor: Running task 4.0 in stage 6.0 (TID 40)
17/03/18 11:31:12 INFO Executor: Running task 5.0 in stage 6.0 (TID 41)
17/03/18 11:31:12 INFO Executor: Running task 6.0 in stage 6.0 (TID 42)
17/03/18 11:31:12 INFO Executor: Running task 7.0 in stage 6.0 (TID 43)
17/03/18 11:31:12 INFO Executor: Running task 3.0 in stage 6.0 (TID 39)
17/03/18 11:31:12 INFO Executor: Running task 2.0 in stage 6.0 (TID 38)
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 11 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Getting 12 non-empty blocks out of 16 blocks
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/18 11:31:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/18 11:31:12 INFO CodeGenerator: Code generated in 7.904163 ms
17/03/18 11:31:12 INFO CodeGenerator: Code generated in 9.292103 ms
17/03/18 11:31:15 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:58023 in memory (size: 6.4 KB, free: 6.2 GB)
17/03/18 11:31:16 INFO UnsafeExternalSorter: Thread 124 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 11:31:16 INFO UnsafeExternalSorter: Thread 120 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 11:31:16 INFO UnsafeExternalSorter: Thread 121 spilling sort data of 544.0 MB to disk (0  time so far)
17/03/18 11:31:18 INFO Executor: Finished task 2.0 in stage 6.0 (TID 38). 2911 bytes result sent to driver
17/03/18 11:31:18 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 38) in 5576 ms on localhost (executor driver) (1/8)
17/03/18 11:31:18 INFO Executor: Finished task 5.0 in stage 6.0 (TID 41). 2911 bytes result sent to driver
17/03/18 11:31:18 INFO TaskSetManager: Finished task 5.0 in stage 6.0 (TID 41) in 5577 ms on localhost (executor driver) (2/8)
17/03/18 11:31:18 INFO Executor: Finished task 6.0 in stage 6.0 (TID 42). 2911 bytes result sent to driver
17/03/18 11:31:18 INFO TaskSetManager: Finished task 6.0 in stage 6.0 (TID 42) in 6071 ms on localhost (executor driver) (3/8)
17/03/18 11:31:18 INFO Executor: Finished task 4.0 in stage 6.0 (TID 40). 2911 bytes result sent to driver
17/03/18 11:31:18 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 40) in 6120 ms on localhost (executor driver) (4/8)
17/03/18 11:31:18 INFO Executor: Finished task 7.0 in stage 6.0 (TID 43). 2911 bytes result sent to driver
17/03/18 11:31:18 INFO TaskSetManager: Finished task 7.0 in stage 6.0 (TID 43) in 6163 ms on localhost (executor driver) (5/8)
17/03/18 11:31:20 INFO Executor: Finished task 1.0 in stage 6.0 (TID 37). 2993 bytes result sent to driver
17/03/18 11:31:20 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 37) in 8032 ms on localhost (executor driver) (6/8)
17/03/18 11:31:21 INFO Executor: Finished task 0.0 in stage 6.0 (TID 36). 2993 bytes result sent to driver
17/03/18 11:31:21 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 36) in 8519 ms on localhost (executor driver) (7/8)
17/03/18 11:31:21 INFO Executor: Finished task 3.0 in stage 6.0 (TID 39). 2993 bytes result sent to driver
17/03/18 11:31:21 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 39) in 8711 ms on localhost (executor driver) (8/8)
17/03/18 11:31:21 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/18 11:31:21 INFO DAGScheduler: ShuffleMapStage 6 (collect at utils.scala:197) finished in 8,714 s
17/03/18 11:31:21 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:31:21 INFO DAGScheduler: running: Set()
17/03/18 11:31:21 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
17/03/18 11:31:21 INFO DAGScheduler: failed: Set()
17/03/18 11:31:21 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[33] at collect at utils.scala:197), which has no missing parents
17/03/18 11:31:21 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 22.9 KB, free 6.2 GB)
17/03/18 11:31:21 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 10.1 KB, free 6.2 GB)
17/03/18 11:31:21 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:58023 (size: 10.1 KB, free: 6.2 GB)
17/03/18 11:31:21 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/03/18 11:31:21 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[33] at collect at utils.scala:197)
17/03/18 11:31:21 INFO TaskSchedulerImpl: Adding task set 7.0 with 8 tasks
17/03/18 11:31:21 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 44, localhost, executor driver, partition 0, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 45, localhost, executor driver, partition 1, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 46, localhost, executor driver, partition 2, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 47, localhost, executor driver, partition 3, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 48, localhost, executor driver, partition 4, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 5.0 in stage 7.0 (TID 49, localhost, executor driver, partition 5, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 6.0 in stage 7.0 (TID 50, localhost, executor driver, partition 6, ANY, 5934 bytes)
17/03/18 11:31:21 INFO TaskSetManager: Starting task 7.0 in stage 7.0 (TID 51, localhost, executor driver, partition 7, ANY, 5934 bytes)
17/03/18 11:31:21 INFO Executor: Running task 1.0 in stage 7.0 (TID 45)
17/03/18 11:31:21 INFO Executor: Running task 6.0 in stage 7.0 (TID 50)
17/03/18 11:31:21 INFO Executor: Running task 3.0 in stage 7.0 (TID 47)
17/03/18 11:31:21 INFO Executor: Running task 7.0 in stage 7.0 (TID 51)
17/03/18 11:31:21 INFO Executor: Running task 2.0 in stage 7.0 (TID 46)
17/03/18 11:31:21 INFO Executor: Running task 4.0 in stage 7.0 (TID 48)
17/03/18 11:31:21 INFO Executor: Running task 0.0 in stage 7.0 (TID 44)
17/03/18 11:31:21 INFO Executor: Running task 5.0 in stage 7.0 (TID 49)
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:21 INFO CodeGenerator: Code generated in 11.702201 ms
17/03/18 11:31:21 INFO CodeGenerator: Code generated in 7.600996 ms
17/03/18 11:31:21 INFO CodeGenerator: Code generated in 7.441841 ms
17/03/18 11:31:21 INFO CodeGenerator: Code generated in 6.434224 ms
17/03/18 11:31:24 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 127.0.0.1:58023 in memory (size: 7.4 KB, free: 6.2 GB)
17/03/18 11:31:35 INFO CodeGenerator: Code generated in 13.47217 ms
17/03/18 11:31:35 INFO CodeGenerator: Code generated in 7.254531 ms
17/03/18 11:31:41 INFO Executor: Finished task 2.0 in stage 7.0 (TID 46). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 46) in 20155 ms on localhost (executor driver) (1/8)
17/03/18 11:31:41 INFO Executor: Finished task 6.0 in stage 7.0 (TID 50). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 6.0 in stage 7.0 (TID 50) in 20161 ms on localhost (executor driver) (2/8)
17/03/18 11:31:41 INFO Executor: Finished task 5.0 in stage 7.0 (TID 49). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 5.0 in stage 7.0 (TID 49) in 20220 ms on localhost (executor driver) (3/8)
17/03/18 11:31:41 INFO Executor: Finished task 7.0 in stage 7.0 (TID 51). 3758 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 7.0 in stage 7.0 (TID 51) in 20232 ms on localhost (executor driver) (4/8)
17/03/18 11:31:41 INFO Executor: Finished task 4.0 in stage 7.0 (TID 48). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 48) in 20415 ms on localhost (executor driver) (5/8)
17/03/18 11:31:41 INFO Executor: Finished task 3.0 in stage 7.0 (TID 47). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 47) in 20425 ms on localhost (executor driver) (6/8)
17/03/18 11:31:41 INFO Executor: Finished task 0.0 in stage 7.0 (TID 44). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 44) in 20551 ms on localhost (executor driver) (7/8)
17/03/18 11:31:41 INFO Executor: Finished task 1.0 in stage 7.0 (TID 45). 3671 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 45) in 20598 ms on localhost (executor driver) (8/8)
17/03/18 11:31:41 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/18 11:31:41 INFO DAGScheduler: ShuffleMapStage 7 (collect at utils.scala:197) finished in 20,599 s
17/03/18 11:31:41 INFO DAGScheduler: looking for newly runnable stages
17/03/18 11:31:41 INFO DAGScheduler: running: Set()
17/03/18 11:31:41 INFO DAGScheduler: waiting: Set(ResultStage 8)
17/03/18 11:31:41 INFO DAGScheduler: failed: Set()
17/03/18 11:31:41 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[36] at collect at utils.scala:197), which has no missing parents
17/03/18 11:31:41 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 6.2 GB)
17/03/18 11:31:41 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 6.2 GB)
17/03/18 11:31:41 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:58023 (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:31:41 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/03/18 11:31:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[36] at collect at utils.scala:197)
17/03/18 11:31:41 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
17/03/18 11:31:41 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 52, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/03/18 11:31:41 INFO Executor: Running task 0.0 in stage 8.0 (TID 52)
17/03/18 11:31:41 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 8 blocks
17/03/18 11:31:41 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/18 11:31:41 INFO Executor: Finished task 0.0 in stage 8.0 (TID 52). 2042 bytes result sent to driver
17/03/18 11:31:41 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 52) in 6 ms on localhost (executor driver) (1/1)
17/03/18 11:31:41 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/18 11:31:41 INFO DAGScheduler: ResultStage 8 (collect at utils.scala:197) finished in 0,008 s
17/03/18 11:31:41 INFO DAGScheduler: Job 5 finished: collect at utils.scala:197, took 36,017871 s
17/03/18 11:31:41 INFO CodeGenerator: Code generated in 6.136907 ms
17/03/18 11:31:43 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:58023 in memory (size: 3.7 KB, free: 6.2 GB)
17/03/18 11:32:54 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:32:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:32:54 WARN Utils: Your hostname, patty resolves to a loopback address: 127.0.1.1; using 192.168.1.64 instead (on interface eth0)
17/03/18 11:32:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
17/03/18 11:32:54 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:32:54 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:32:54 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:32:54 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:32:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:32:55 INFO Utils: Successfully started service 'sparkDriver' on port 46610.
17/03/18 11:32:55 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:32:55 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:32:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:32:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:32:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e5c7eeab-b385-4c1f-bcfd-ef00152958ab
17/03/18 11:32:55 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/03/18 11:32:55 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:32:55 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/18 11:32:55 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.64:4040
17/03/18 11:32:55 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://192.168.1.64:46610/jars/sparklyr-2.1-2.11.jar with timestamp 1489833175397
17/03/18 11:32:55 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://local:7077...
17/03/18 11:32:55 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master local:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:100)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:108)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to local:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:205)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1226)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:970)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:215)
	at io.netty.bootstrap.Bootstrap$2.run(Bootstrap.java:166)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
17/03/18 11:33:15 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://local:7077...
17/03/18 11:33:15 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master local:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:100)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:108)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to local:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:205)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1226)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:970)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:215)
	at io.netty.bootstrap.Bootstrap$2.run(Bootstrap.java:166)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
17/03/18 11:33:35 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://local:7077...
17/03/18 11:33:35 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master local:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:100)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:108)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to local:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:205)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1226)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:970)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:215)
	at io.netty.bootstrap.Bootstrap$2.run(Bootstrap.java:166)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
17/03/18 11:33:55 ERROR StandaloneSchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.
17/03/18 11:33:55 WARN StandaloneSchedulerBackend: Application ID is not initialized yet.
17/03/18 11:33:55 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51172.
17/03/18 11:33:55 INFO NettyBlockTransferService: Server created on 192.168.1.64:51172
17/03/18 11:33:55 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 11:33:55 INFO SparkUI: Stopped Spark web UI at http://192.168.1.64:4040
17/03/18 11:33:55 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 192.168.1.64, 51172, None)
17/03/18 11:33:55 INFO StandaloneSchedulerBackend: Shutting down all executors
17/03/18 11:33:55 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.1.64:51172 with 366.3 MB RAM, BlockManagerId(driver, 192.168.1.64, 51172, None)
17/03/18 11:33:55 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 192.168.1.64, 51172, None)
17/03/18 11:33:55 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 192.168.1.64, 51172, None)
17/03/18 11:33:55 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
17/03/18 11:33:55 WARN StandaloneAppClient$ClientEndpoint: Drop UnregisterApplication(null) because has not yet connected to master
17/03/18 11:33:55 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 11:33:55 INFO MemoryStore: MemoryStore cleared
17/03/18 11:33:55 INFO BlockManager: BlockManager stopped
17/03/18 11:33:55 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 11:33:55 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 11:33:55 ERROR SparkContext: Error initializing SparkContext.
java.lang.IllegalArgumentException: requirement failed: Can only call getServletHandlers on a running MetricsSystem
	at scala.Predef$.require(Predef.scala:224)
	at org.apache.spark.metrics.MetricsSystem.getServletHandlers(MetricsSystem.scala:91)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:524)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2313)
	at org.apache.spark.SparkContext.getOrCreate(SparkContext.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sparklyr.Invoke$.invoke(invoke.scala:94)
	at sparklyr.StreamHandler$.handleMethodCall(stream.scala:89)
	at sparklyr.StreamHandler$.read(stream.scala:55)
	at sparklyr.BackendHandler.channelRead0(handler.scala:49)
	at sparklyr.BackendHandler.channelRead0(handler.scala:14)
	at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293)
	at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:346)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1294)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:367)
	at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:353)
	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:652)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:575)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:489)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:451)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	at java.lang.Thread.run(Thread.java:745)
17/03/18 11:33:55 INFO SparkContext: SparkContext already stopped.
17/03/18 11:33:55 INFO SparkContext: Successfully stopped SparkContext
17/03/18 11:37:32 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:37:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:37:32 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:37:32 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:37:32 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:37:32 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:37:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:37:32 INFO Utils: Successfully started service 'sparkDriver' on port 38476.
17/03/18 11:37:32 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:37:32 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:37:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:37:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:37:32 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e019b51c-6cff-4dbc-b98e-672c11da92d0
17/03/18 11:37:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/03/18 11:37:32 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:37:32 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/03/18 11:37:32 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/03/18 11:37:32 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:38476/jars/sparklyr-2.1-2.11.jar with timestamp 1489833452794
17/03/18 11:37:32 INFO Executor: Starting executor ID driver on host localhost
17/03/18 11:37:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45120.
17/03/18 11:37:32 INFO NettyBlockTransferService: Server created on 127.0.0.1:45120
17/03/18 11:37:32 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/03/18 11:37:32 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 45120, None)
17/03/18 11:37:32 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:45120 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 45120, None)
17/03/18 11:37:32 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 45120, None)
17/03/18 11:37:32 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 45120, None)
17/03/18 11:37:33 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/03/18 11:37:33 INFO SharedState: Warehouse path is 'file:/home/yannick/Work/github/db_bench/spark/spark-warehouse'.
17/03/18 11:37:33 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/03/18 11:37:33 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/03/18 11:37:33 INFO ObjectStore: ObjectStore, initialize called
17/03/18 11:37:33 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/03/18 11:37:33 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/03/18 11:37:34 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/03/18 11:37:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:37:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:37:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:37:35 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:37:35 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/03/18 11:37:35 INFO ObjectStore: Initialized ObjectStore
17/03/18 11:37:36 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/03/18 11:37:36 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/03/18 11:37:36 INFO HiveMetaStore: Added admin role in metastore
17/03/18 11:37:36 INFO HiveMetaStore: Added public role in metastore
17/03/18 11:37:36 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/03/18 11:37:36 INFO HiveMetaStore: 0: get_all_databases
17/03/18 11:37:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_all_databases	
17/03/18 11:37:36 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/03/18 11:37:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/03/18 11:37:36 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/03/18 11:37:36 INFO SessionState: Created local directory: /tmp/7ce382be-6783-4714-aaff-3b3d699fa8c1_resources
17/03/18 11:37:36 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/7ce382be-6783-4714-aaff-3b3d699fa8c1
17/03/18 11:37:36 INFO SessionState: Created local directory: /tmp/yannick/7ce382be-6783-4714-aaff-3b3d699fa8c1
17/03/18 11:37:36 INFO SessionState: Created HDFS directory: /tmp/hive/yannick/7ce382be-6783-4714-aaff-3b3d699fa8c1/_tmp_space.db
17/03/18 11:37:36 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is file:/home/yannick/Work/github/db_bench/spark/spark-warehouse
17/03/18 11:37:36 INFO HiveMetaStore: 0: get_database: default
17/03/18 11:37:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: default	
17/03/18 11:37:36 INFO HiveMetaStore: 0: get_database: global_temp
17/03/18 11:37:36 INFO audit: ugi=yannick	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/03/18 11:37:36 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/03/18 11:37:40 INFO SparkContext: Running Spark version 2.1.0
17/03/18 11:37:40 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/18 11:37:40 WARN Utils: Your hostname, patty resolves to a loopback address: 127.0.1.1; using 192.168.1.64 instead (on interface eth0)
17/03/18 11:37:40 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
17/03/18 11:37:40 INFO SecurityManager: Changing view acls to: yannick
17/03/18 11:37:40 INFO SecurityManager: Changing modify acls to: yannick
17/03/18 11:37:40 INFO SecurityManager: Changing view acls groups to: 
17/03/18 11:37:40 INFO SecurityManager: Changing modify acls groups to: 
17/03/18 11:37:40 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(yannick); groups with view permissions: Set(); users  with modify permissions: Set(yannick); groups with modify permissions: Set()
17/03/18 11:37:40 INFO Utils: Successfully started service 'sparkDriver' on port 42985.
17/03/18 11:37:41 INFO SparkEnv: Registering MapOutputTracker
17/03/18 11:37:41 INFO SparkEnv: Registering BlockManagerMaster
17/03/18 11:37:41 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/03/18 11:37:41 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/03/18 11:37:41 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-71b6c817-419a-4d82-9463-8f4329d5afc5
17/03/18 11:37:41 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/03/18 11:37:41 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/18 11:37:41 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/03/18 11:37:41 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
17/03/18 11:37:41 INFO Utils: Successfully started service 'SparkUI' on port 4042.
17/03/18 11:37:41 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://192.168.1.64:4042
17/03/18 11:37:41 INFO SparkContext: Added JAR file:/home/yannick/R/x86_64-pc-linux-gnu-library/3.3/sparklyr/java/sparklyr-2.1-2.11.jar at spark://192.168.1.64:42985/jars/sparklyr-2.1-2.11.jar with timestamp 1489833461272
17/03/18 11:37:41 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://local:7077...
17/03/18 11:37:41 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master local:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:100)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:108)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to local:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:205)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1226)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:970)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:215)
	at io.netty.bootstrap.Bootstrap$2.run(Bootstrap.java:166)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
17/03/18 11:38:01 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://local:7077...
17/03/18 11:38:01 WARN StandaloneAppClient$ClientEndpoint: Failed to connect to master local:7077
org.apache.spark.SparkException: Exception thrown in awaitResult
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:77)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$1.applyOrElse(RpcTimeout.scala:75)
	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at org.apache.spark.rpc.RpcTimeout$$anonfun$addMessageIfTimeout$1.applyOrElse(RpcTimeout.scala:59)
	at scala.PartialFunction$OrElse.apply(PartialFunction.scala:167)
	at org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:83)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRefByURI(RpcEnv.scala:100)
	at org.apache.spark.rpc.RpcEnv.setupEndpointRef(RpcEnv.scala:108)
	at org.apache.spark.deploy.client.StandaloneAppClient$ClientEndpoint$$anonfun$tryRegisterAllMasters$1$$anon$1.run(StandaloneAppClient.scala:106)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.IOException: Failed to connect to local:7077
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:228)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:179)
	at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:197)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:191)
	at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)
	... 4 more
Caused by: java.nio.channels.UnresolvedAddressException
	at sun.nio.ch.Net.checkAddress(Net.java:101)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:622)
	at io.netty.channel.socket.nio.NioSocketChannel.doConnect(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.connect(AbstractNioChannel.java:205)
	at io.netty.channel.DefaultChannelPipeline$HeadContext.connect(DefaultChannelPipeline.java:1226)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelOutboundHandlerAdapter.connect(ChannelOutboundHandlerAdapter.java:47)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.ChannelDuplexHandler.connect(ChannelDuplexHandler.java:50)
	at io.netty.channel.AbstractChannelHandlerContext.invokeConnect(AbstractChannelHandlerContext.java:550)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:535)
	at io.netty.channel.AbstractChannelHandlerContext.connect(AbstractChannelHandlerContext.java:517)
	at io.netty.channel.DefaultChannelPipeline.connect(DefaultChannelPipeline.java:970)
	at io.netty.channel.AbstractChannel.connect(AbstractChannel.java:215)
	at io.netty.bootstrap.Bootstrap$2.run(Bootstrap.java:166)
	at io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:408)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:455)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:140)
	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144)
	... 1 more
17/03/18 11:38:15 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 11:38:15 INFO DiskBlockManager: Shutdown hook called
17/03/18 11:38:15 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:38:15 INFO SparkContext: Invoking stop() from shutdown hook
17/03/18 11:38:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-a76c6832-c6ef-4cee-bf2e-d466040e794b
17/03/18 11:38:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/03/18 11:38:15 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:38:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-50b51b6a-2b74-4a18-bfd2-ec16f6db303b/userFiles-149eb454-89d2-42c0-a066-5c650a8167b6
17/03/18 11:38:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-50b51b6a-2b74-4a18-bfd2-ec16f6db303b
17/03/18 11:38:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 11:38:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/03/18 11:38:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/18 11:38:15 INFO MemoryStore: MemoryStore cleared
17/03/18 11:38:15 INFO BlockManager: BlockManager stopped
17/03/18 11:38:15 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 11:38:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 11:38:15 INFO SparkContext: Successfully stopped SparkContext
17/03/18 11:38:15 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:38:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-0e37f3d9-9890-4695-b83f-61d122e488dc
17/03/18 11:38:15 INFO MemoryStore: MemoryStore cleared
17/03/18 11:38:15 INFO BlockManager: BlockManager stopped
17/03/18 11:38:15 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/18 11:38:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/18 11:38:15 INFO SparkContext: Successfully stopped SparkContext
17/03/18 11:38:15 INFO ShutdownHookManager: Shutdown hook called
17/03/18 11:38:15 INFO ShutdownHookManager: Deleting directory /home/yannick/tmp/sparklyr/spark-94fc4a98-20fe-409d-af88-f19f79430f0e
